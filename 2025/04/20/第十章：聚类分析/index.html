<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liujunblog.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="CHAPTER10聚类分析基本概念和方法PPT课件.pptx K-均值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import pandas as pdimport">
<meta property="og:type" content="article">
<meta property="og:title" content="第十章：聚类分析">
<meta property="og:url" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:description" content="CHAPTER10聚类分析基本概念和方法PPT课件.pptx K-均值1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import pandas as pdimport">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/K_%E5%9D%87%E5%80%BC.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/%E5%8A%A8%E6%80%81%E5%9B%BE.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/AMP.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/pam_animation.gif">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/cwngci.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/BIRCH.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/birch_33.gif">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/cengcigailv.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/DBSCN-17482501533272.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/suijiDBSCAN.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/OPTICS.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/OPTICS_2.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/suijiOPTICS.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/suijiOPTICS_2.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/suijiOP.png">
<meta property="og:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/suijiOP_2.png">
<meta property="article:published_time" content="2025-04-20T08:18:32.000Z">
<meta property="article:modified_time" content="2025-05-27T03:24:35.657Z">
<meta property="article:author" content="LiuJun">
<meta property="article:tag" content="第十章：聚类分析">
<meta property="article:tag" content="大作业">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/images/K_%E5%9D%87%E5%80%BC.png">


<link rel="canonical" href="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/","path":"2025/04/20/第十章：聚类分析/","title":"第十章：聚类分析"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>第十章：聚类分析 | Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Blog</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#K-%E5%9D%87%E5%80%BC"><span class="nav-number">1.</span> <span class="nav-text">K-均值</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E6%88%AA%E5%9B%BE%E5%A6%82%E4%B8%8B"><span class="nav-number">1.0.0.1.</span> <span class="nav-text">运行截图如下</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E5%9B%BE"><span class="nav-number">1.0.0.2.</span> <span class="nav-text">动态图</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%AD%E4%BB%A3%E6%95%B0%E6%8D%AE"><span class="nav-number">1.1.</span> <span class="nav-text">迭代数据</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#k-%E4%B8%AD%E5%BF%83%E7%82%B9%EF%BC%88AMP%EF%BC%89"><span class="nav-number">2.</span> <span class="nav-text">k-中心点（AMP）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE"><span class="nav-number">2.1.</span> <span class="nav-text">运行结果图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E5%9B%BE-1"><span class="nav-number">2.2.</span> <span class="nav-text">动态图</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-number">3.</span> <span class="nav-text">层次聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-1"><span class="nav-number">3.1.</span> <span class="nav-text">运行结果图</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E7%9A%84BIRCH%E7%AE%97%E6%B3%95"><span class="nav-number">4.</span> <span class="nav-text">层次聚类的BIRCH算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-2"><span class="nav-number">4.1.</span> <span class="nav-text">运行结果图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8A%A8%E6%80%81%E5%9B%BE-2"><span class="nav-number">4.2.</span> <span class="nav-text">动态图</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A6%82%E7%8E%87%E5%B1%82%E6%AC%A1%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-number">5.</span> <span class="nav-text">概率层次聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-3"><span class="nav-number">5.1.</span> <span class="nav-text">运行结果图</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AF%86%E5%BA%A6DBSCAN%E7%AE%97%E6%B3%95"><span class="nav-number">6.</span> <span class="nav-text">密度DBSCAN算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-4"><span class="nav-number">6.1.</span> <span class="nav-text">运行结果图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="nav-number">6.2.</span> <span class="nav-text">随机数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-5"><span class="nav-number">6.3.</span> <span class="nav-text">运行结果图</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%AF%86%E5%BA%A6OPTICS%E7%AE%97%E6%B3%95"><span class="nav-number">7.</span> <span class="nav-text">密度OPTICS算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-6"><span class="nav-number">7.1.</span> <span class="nav-text">运行结果图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE%E9%9B%86-1"><span class="nav-number">7.2.</span> <span class="nav-text">随机数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-7"><span class="nav-number">7.3.</span> <span class="nav-text">运行结果图</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E7%AC%A6%E5%90%88%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%95%B0%E6%8D%AE"><span class="nav-number">7.4.</span> <span class="nav-text">最符合的随机数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E5%9B%BE-8"><span class="nav-number">7.5.</span> <span class="nav-text">运行结果图</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiuJun"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">LiuJun</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="第十章：聚类分析 | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          第十章：聚类分析
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-20 16:18:32" itemprop="dateCreated datePublished" datetime="2025-04-20T16:18:32+08:00">2025-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-27 11:24:35" itemprop="dateModified" datetime="2025-05-27T11:24:35+08:00">2025-05-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><a href="./File/CHAPTER10聚类分析基本概念和方法PPT课件.pptx">CHAPTER10聚类分析基本概念和方法PPT课件.pptx</a></p>
<h1 id="K-均值"><a href="#K-均值" class="headerlink" title="K-均值"></a>K-均值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据并预处理</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;iris.csv&#x27;</span>)</span><br><span class="line">X = data.iloc[:, [<span class="number">2</span>, <span class="number">3</span>]].values  <span class="comment"># 使用鸢尾花花瓣长度和宽度</span></span><br><span class="line">species = data[<span class="string">&#x27;Species&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">k_means</span>(<span class="params">X, k, max_iters=<span class="number">100</span></span>):</span><br><span class="line">    <span class="comment"># 随机选择k个初始中心</span></span><br><span class="line">    centers = X[np.random.choice(X.shape[<span class="number">0</span>], k, replace=<span class="literal">False</span>)] <span class="comment"># 随机选择 k 个样本作为初始簇中心</span></span><br><span class="line">    clusters = np.zeros(X.shape[<span class="number">0</span>], dtype=<span class="built_in">int</span>)<span class="comment"># 初始化每个点所属簇的编号为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_iters):</span><br><span class="line">        <span class="comment"># 计算每个点到中心的欧氏距离</span></span><br><span class="line">        diff = X[:, np.newaxis, :] - centers  <span class="comment"># 形状 (n_samples, k, n_features)</span></span><br><span class="line">        distances = np.<span class="built_in">sum</span>(diff ** <span class="number">2</span>, axis=<span class="number">2</span>)  <span class="comment"># 平方欧氏距离</span></span><br><span class="line">        new_clusters = np.argmin(distances, axis=<span class="number">1</span>)<span class="comment">#对每个数据点，找到其最近的簇中心，并返回所属簇的编号（0 到 k-1）组成的数组</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检查簇是否稳定</span></span><br><span class="line">        <span class="keyword">if</span> np.array_equal(new_clusters, clusters):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        clusters = new_clusters</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新簇中心</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):<span class="comment">#循环遍历每一个簇（从 0 到 k-1），准备更新每个簇的新中心点</span></span><br><span class="line">            cluster_points = X[clusters == i]<span class="comment"># 提取属于第 i 个簇的所有样本点</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(cluster_points) == <span class="number">0</span>:  <span class="comment"># 处理空簇</span></span><br><span class="line">                centers[i] = X[np.random.choice(X.shape[<span class="number">0</span>], <span class="number">1</span>)]<span class="comment">#如果是空簇，就随机选择一个样本点作为新的中心点</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                centers[i] = cluster_points.mean(axis=<span class="number">0</span>)<span class="comment"># 如果簇中有成员，就取这些点的“平均值”作为新的中心点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> clusters, centers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行K-means聚类</span></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">clusters, centers = k_means(X, k)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始数据分布图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">species_types = species.unique()</span><br><span class="line">colors = [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i, specie <span class="keyword">in</span> <span class="built_in">enumerate</span>(species_types):</span><br><span class="line">    plt.scatter(X[species == specie, <span class="number">0</span>], X[species == specie, <span class="number">1</span>],</span><br><span class="line">                label=specie, c=colors[i], alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据分布&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度（厘米）&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度（厘米）&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类结果图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">cluster_colors = [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;purple&#x27;</span>, <span class="string">&#x27;brown&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    plt.scatter(X[clusters == i, <span class="number">0</span>], X[clusters == i, <span class="number">1</span>],</span><br><span class="line">                label=<span class="string">f&#x27;簇 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&#x27;</span>, c=cluster_colors[i], alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">&#x27;*&#x27;</span>,</span><br><span class="line">            c=<span class="string">&#x27;red&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>, label=<span class="string">&#x27;簇中心&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;K-means 聚类结果&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度（厘米）&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度（厘米）&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="运行截图如下"><a href="#运行截图如下" class="headerlink" title="运行截图如下"></a>运行截图如下</h4><p><img src="images/K_%E5%9D%87%E5%80%BC.png" alt=""></p>
<h4 id="动态图"><a href="#动态图" class="headerlink" title="动态图"></a>动态图</h4><p><img src="images/%E5%8A%A8%E6%80%81%E5%9B%BE.png" alt=""></p>
<h2 id="迭代数据"><a href="#迭代数据" class="headerlink" title="迭代数据"></a>迭代数据</h2><p><a href="./File/kmeans_iterations.csv">kmeans_iterations.csv</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>iteration</th>
<th>point_index</th>
<th>petal_length</th>
<th>petal_width</th>
<th>assigned_cluster</th>
<th>distance_0</th>
<th>distance_1</th>
<th>distance_2</th>
</tr>
</thead>
<tbody>
<tr>
<td>迭代参数</td>
<td>数据编号</td>
<td>花瓣长度</td>
<td>花瓣宽度</td>
<td>分配到的簇编号</td>
<td>点到簇中心0的欧氏距离</td>
<td>点到簇中心1的欧氏距离</td>
<td>点到簇中心2的欧氏距离</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.35</td>
<td>3.20</td>
<td>0.41</td>
</tr>
<tr>
<td>1</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.51</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.49</td>
<td>0.28</td>
</tr>
<tr>
<td>1</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.58</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>5.02</td>
<td>3.86</td>
<td>0.28</td>
</tr>
<tr>
<td>1</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.73</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.38</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.72</td>
<td>3.57</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.51</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.39</td>
<td>3.23</td>
<td>0.40</td>
</tr>
<tr>
<td>1</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.42</td>
<td>0.20</td>
</tr>
<tr>
<td>1</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>3.27</td>
<td>0.41</td>
</tr>
<tr>
<td>1</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.38</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.07</td>
<td>3.92</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.31</td>
<td>3.16</td>
<td>0.45</td>
</tr>
<tr>
<td>1</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.25</td>
<td>3.09</td>
<td>0.61</td>
</tr>
<tr>
<td>1</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>3.29</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.38</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.49</td>
<td>0.28</td>
</tr>
<tr>
<td>1</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.73</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.58</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.61</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.61</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.37</td>
<td>3.23</td>
<td>0.42</td>
</tr>
<tr>
<td>1</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.16</td>
<td>3.01</td>
<td>0.61</td>
</tr>
<tr>
<td>1</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.51</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.22</td>
<td>0.10</td>
<td>3.57</td>
</tr>
<tr>
<td>1</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1</td>
<td>0.20</td>
<td>3.79</td>
</tr>
<tr>
<td>1</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.88</td>
<td>0.73</td>
<td>2.88</td>
</tr>
<tr>
<td>1</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.10</td>
<td>3.51</td>
</tr>
<tr>
<td>1</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.44</td>
<td>0.28</td>
<td>3.35</td>
</tr>
<tr>
<td>1</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.12</td>
<td>0.10</td>
<td>3.64</td>
</tr>
<tr>
<td>1</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.64</td>
<td>1.49</td>
<td>2.12</td>
</tr>
<tr>
<td>1</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.36</td>
<td>0.22</td>
<td>3.45</td>
</tr>
<tr>
<td>1</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.93</td>
<td>0.81</td>
<td>2.82</td>
</tr>
<tr>
<td>1</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.46</td>
<td>1.30</td>
<td>2.31</td>
</tr>
<tr>
<td>1</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.62</td>
<td>0.50</td>
<td>3.14</td>
</tr>
<tr>
<td>1</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>2.02</td>
<td>0.86</td>
<td>2.79</td>
</tr>
<tr>
<td>1</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.22</td>
<td>0.10</td>
<td>3.57</td>
</tr>
<tr>
<td>1</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.25</td>
<td>1.12</td>
<td>2.51</td>
</tr>
<tr>
<td>1</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.48</td>
<td>0.32</td>
<td>3.29</td>
</tr>
<tr>
<td>1</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.94</td>
<td>0.78</td>
<td>2.89</td>
</tr>
<tr>
<td>1</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2.06</td>
<td>0.89</td>
<td>2.72</td>
</tr>
<tr>
<td>1</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.95</td>
<td>0.32</td>
<td>3.81</td>
</tr>
<tr>
<td>1</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.88</td>
<td>0.73</td>
<td>2.88</td>
</tr>
<tr>
<td>1</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1</td>
<td>0.20</td>
<td>3.79</td>
</tr>
<tr>
<td>1</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.35</td>
<td>0.30</td>
<td>3.52</td>
</tr>
<tr>
<td>1</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.45</td>
<td>3.16</td>
</tr>
<tr>
<td>1</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.48</td>
<td>0.32</td>
<td>3.29</td>
</tr>
<tr>
<td>1</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.14</td>
<td>0.14</td>
<td>3.67</td>
</tr>
<tr>
<td>1</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>1</td>
<td>0.81</td>
<td>0.36</td>
<td>3.96</td>
</tr>
<tr>
<td>1</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.46</td>
<td>1.30</td>
<td>2.31</td>
</tr>
<tr>
<td>1</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.15</td>
<td>0.98</td>
<td>2.62</td>
</tr>
<tr>
<td>1</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.28</td>
<td>1.12</td>
<td>2.50</td>
</tr>
<tr>
<td>1</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>2.01</td>
<td>0.85</td>
<td>2.75</td>
</tr>
<tr>
<td>1</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>1</td>
<td>0.78</td>
<td>0.41</td>
<td>4.02</td>
</tr>
<tr>
<td>1</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.30</td>
<td>0.22</td>
<td>3.45</td>
</tr>
<tr>
<td>1</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.17</td>
<td>0</td>
<td>3.61</td>
</tr>
<tr>
<td>1</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.53</td>
<td>0.36</td>
<td>3.26</td>
</tr>
<tr>
<td>1</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.63</td>
<td>2.97</td>
</tr>
<tr>
<td>1</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.88</td>
<td>0.73</td>
<td>2.88</td>
</tr>
<tr>
<td>1</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.58</td>
<td>0.42</td>
<td>3.23</td>
</tr>
<tr>
<td>1</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.30</td>
<td>0.14</td>
<td>3.48</td>
</tr>
<tr>
<td>1</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.92</td>
<td>0.76</td>
<td>2.85</td>
</tr>
<tr>
<td>1</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.64</td>
<td>1.49</td>
<td>2.12</td>
</tr>
<tr>
<td>1</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.54</td>
<td>3.07</td>
</tr>
<tr>
<td>1</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.75</td>
<td>0.58</td>
<td>3.04</td>
</tr>
<tr>
<td>1</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.54</td>
<td>3.07</td>
</tr>
<tr>
<td>1</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.45</td>
<td>3.16</td>
</tr>
<tr>
<td>1</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.88</td>
<td>1.75</td>
<td>1.88</td>
</tr>
<tr>
<td>1</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.63</td>
<td>2.97</td>
</tr>
<tr>
<td>1</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.50</td>
<td>1.64</td>
<td>5.19</td>
</tr>
<tr>
<td>1</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>1</td>
<td>0.63</td>
<td>0.57</td>
<td>4.12</td>
</tr>
<tr>
<td>1</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1.34</td>
<td>4.94</td>
</tr>
<tr>
<td>1</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.32</td>
<td>0.95</td>
<td>4.55</td>
</tr>
<tr>
<td>1</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.14</td>
<td>1.30</td>
<td>4.88</td>
</tr>
<tr>
<td>1</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.90</td>
<td>1.99</td>
<td>5.60</td>
</tr>
<tr>
<td>1</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.26</td>
<td>0.28</td>
<td>3.49</td>
</tr>
<tr>
<td>1</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.67</td>
<td>1.63</td>
<td>5.22</td>
</tr>
<tr>
<td>1</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.32</td>
<td>1.14</td>
<td>4.74</td>
</tr>
<tr>
<td>1</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.57</td>
<td>1.72</td>
<td>5.28</td>
</tr>
<tr>
<td>1</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.61</td>
<td>0.64</td>
<td>4.16</td>
</tr>
<tr>
<td>1</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.45</td>
<td>0.72</td>
<td>4.31</td>
</tr>
<tr>
<td>1</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1</td>
<td>4.57</td>
</tr>
<tr>
<td>1</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>1</td>
<td>0.71</td>
<td>0.58</td>
<td>4.07</td>
</tr>
<tr>
<td>1</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.67</td>
<td>0.98</td>
<td>4.34</td>
</tr>
<tr>
<td>1</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1</td>
<td>4.47</td>
</tr>
<tr>
<td>1</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.36</td>
<td>0.85</td>
<td>4.46</td>
</tr>
<tr>
<td>1</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1</td>
<td>2.12</td>
<td>5.72</td>
</tr>
<tr>
<td>1</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.22</td>
<td>2.34</td>
<td>5.95</td>
</tr>
<tr>
<td>1</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.92</td>
<td>0.30</td>
<td>3.89</td>
</tr>
<tr>
<td>1</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.20</td>
<td>1.28</td>
<td>4.83</td>
</tr>
<tr>
<td>1</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>1</td>
<td>0.81</td>
<td>0.54</td>
<td>3.98</td>
</tr>
<tr>
<td>1</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>2.06</td>
<td>5.66</td>
</tr>
<tr>
<td>1</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.36</td>
<td>3.90</td>
</tr>
<tr>
<td>1</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0</td>
<td>1.17</td>
<td>4.75</td>
</tr>
<tr>
<td>1</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.42</td>
<td>1.33</td>
<td>4.93</td>
</tr>
<tr>
<td>1</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.95</td>
<td>0.32</td>
<td>3.81</td>
</tr>
<tr>
<td>1</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.36</td>
<td>3.90</td>
</tr>
<tr>
<td>1</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.10</td>
<td>1.08</td>
<td>4.66</td>
</tr>
<tr>
<td>1</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.51</td>
<td>1.10</td>
<td>4.68</td>
</tr>
<tr>
<td>1</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.45</td>
<td>1.46</td>
<td>5.06</td>
</tr>
<tr>
<td>1</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.71</td>
<td>1.77</td>
<td>5.38</td>
</tr>
<tr>
<td>1</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.14</td>
<td>1.14</td>
<td>4.70</td>
</tr>
<tr>
<td>1</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.85</td>
<td>0.40</td>
<td>3.98</td>
</tr>
<tr>
<td>1</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.71</td>
<td>0.91</td>
<td>4.44</td>
</tr>
<tr>
<td>1</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1.61</td>
<td>5.20</td>
</tr>
<tr>
<td>1</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.32</td>
<td>1.27</td>
<td>4.79</td>
</tr>
<tr>
<td>1</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.36</td>
<td>0.85</td>
<td>4.46</td>
</tr>
<tr>
<td>1</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.95</td>
<td>0.32</td>
<td>3.81</td>
</tr>
<tr>
<td>1</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.30</td>
<td>0.92</td>
<td>4.48</td>
</tr>
<tr>
<td>1</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.32</td>
<td>1.27</td>
<td>4.79</td>
</tr>
<tr>
<td>1</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.63</td>
<td>0.89</td>
<td>4.29</td>
</tr>
<tr>
<td>1</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>1</td>
<td>0.63</td>
<td>0.57</td>
<td>4.12</td>
</tr>
<tr>
<td>1</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.28</td>
<td>1.44</td>
<td>5.02</td>
</tr>
<tr>
<td>1</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.40</td>
<td>1.41</td>
<td>4.92</td>
</tr>
<tr>
<td>1</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.54</td>
<td>0.94</td>
<td>4.38</td>
</tr>
<tr>
<td>1</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>1</td>
<td>0.73</td>
<td>0.50</td>
<td>4.03</td>
</tr>
<tr>
<td>1</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.51</td>
<td>0.71</td>
<td>4.25</td>
</tr>
<tr>
<td>1</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.36</td>
<td>1.06</td>
<td>4.56</td>
</tr>
<tr>
<td>1</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>1</td>
<td>0.67</td>
<td>0.50</td>
<td>4.09</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.41</td>
<td>2.89</td>
<td>0.28</td>
</tr>
<tr>
<td>2</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.73</td>
<td>3.20</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.72</td>
<td>3.19</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.81</td>
<td>3.28</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>5.08</td>
<td>3.56</td>
<td>0.39</td>
</tr>
<tr>
<td>2</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.95</td>
<td>3.43</td>
<td>0.27</td>
</tr>
<tr>
<td>2</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.60</td>
<td>3.08</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.78</td>
<td>3.26</td>
<td>0.22</td>
</tr>
<tr>
<td>2</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.73</td>
<td>3.20</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.45</td>
<td>2.92</td>
<td>0.24</td>
</tr>
<tr>
<td>2</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.63</td>
<td>3.11</td>
<td>0.07</td>
</tr>
<tr>
<td>2</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.49</td>
<td>2.96</td>
<td>0.24</td>
</tr>
<tr>
<td>2</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.60</td>
<td>3.08</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.13</td>
<td>3.61</td>
<td>0.46</td>
</tr>
<tr>
<td>2</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.37</td>
<td>2.85</td>
<td>0.35</td>
</tr>
<tr>
<td>2</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.31</td>
<td>2.78</td>
<td>0.44</td>
</tr>
<tr>
<td>2</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.50</td>
<td>2.98</td>
<td>0.21</td>
</tr>
<tr>
<td>2</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.60</td>
<td>3.08</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.72</td>
<td>3.19</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.95</td>
<td>3.43</td>
<td>0.27</td>
</tr>
<tr>
<td>2</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.81</td>
<td>3.28</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.82</td>
<td>3.30</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.82</td>
<td>3.30</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.43</td>
<td>2.92</td>
<td>0.38</td>
</tr>
<tr>
<td>2</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.23</td>
<td>2.70</td>
<td>0.46</td>
</tr>
<tr>
<td>2</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.73</td>
<td>3.20</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.28</td>
<td>0.30</td>
<td>3.44</td>
</tr>
<tr>
<td>2</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1.06</td>
<td>0.51</td>
<td>3.66</td>
</tr>
<tr>
<td>2</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.94</td>
<td>0.42</td>
<td>2.75</td>
</tr>
<tr>
<td>2</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.32</td>
<td>0.21</td>
<td>3.38</td>
</tr>
<tr>
<td>2</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.50</td>
<td>0.16</td>
<td>3.22</td>
</tr>
<tr>
<td>2</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.18</td>
<td>0.35</td>
<td>3.51</td>
</tr>
<tr>
<td>2</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.70</td>
<td>1.18</td>
<td>1.99</td>
</tr>
<tr>
<td>2</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.42</td>
<td>0.24</td>
<td>3.31</td>
</tr>
<tr>
<td>2</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>2</td>
<td>0.50</td>
<td>2.70</td>
</tr>
<tr>
<td>2</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.52</td>
<td>0.99</td>
<td>2.17</td>
</tr>
<tr>
<td>2</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.68</td>
<td>0.21</td>
<td>3.01</td>
</tr>
<tr>
<td>2</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>2.08</td>
<td>0.58</td>
<td>2.65</td>
</tr>
<tr>
<td>2</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.28</td>
<td>0.30</td>
<td>3.44</td>
</tr>
<tr>
<td>2</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.31</td>
<td>0.81</td>
<td>2.38</td>
</tr>
<tr>
<td>2</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.54</td>
<td>0.02</td>
<td>3.16</td>
</tr>
<tr>
<td>2</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>0.52</td>
<td>2.74</td>
</tr>
<tr>
<td>2</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2.12</td>
<td>0.60</td>
<td>2.58</td>
</tr>
<tr>
<td>2</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>1.01</td>
<td>0.55</td>
<td>3.68</td>
</tr>
<tr>
<td>2</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.94</td>
<td>0.42</td>
<td>2.75</td>
</tr>
<tr>
<td>2</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1.06</td>
<td>0.51</td>
<td>3.66</td>
</tr>
<tr>
<td>2</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.40</td>
<td>0.37</td>
<td>3.38</td>
</tr>
<tr>
<td>2</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.67</td>
<td>0.16</td>
<td>3.03</td>
</tr>
<tr>
<td>2</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.54</td>
<td>0.02</td>
<td>3.16</td>
</tr>
<tr>
<td>2</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.20</td>
<td>0.40</td>
<td>3.53</td>
</tr>
<tr>
<td>2</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>1</td>
<td>0.87</td>
<td>0.66</td>
<td>3.83</td>
</tr>
<tr>
<td>2</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.52</td>
<td>0.99</td>
<td>2.17</td>
</tr>
<tr>
<td>2</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.21</td>
<td>0.68</td>
<td>2.49</td>
</tr>
<tr>
<td>2</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.34</td>
<td>0.82</td>
<td>2.36</td>
</tr>
<tr>
<td>2</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>2.08</td>
<td>0.55</td>
<td>2.62</td>
</tr>
<tr>
<td>2</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>1</td>
<td>0.84</td>
<td>0.72</td>
<td>3.88</td>
</tr>
<tr>
<td>2</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.36</td>
<td>0.20</td>
<td>3.33</td>
</tr>
<tr>
<td>2</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.23</td>
<td>0.31</td>
<td>3.47</td>
</tr>
<tr>
<td>2</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.59</td>
<td>0.12</td>
<td>3.12</td>
</tr>
<tr>
<td>2</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.85</td>
<td>0.32</td>
<td>2.84</td>
</tr>
<tr>
<td>2</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.94</td>
<td>0.42</td>
<td>2.75</td>
</tr>
<tr>
<td>2</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.64</td>
<td>0.22</td>
<td>3.09</td>
</tr>
<tr>
<td>2</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.36</td>
<td>0.20</td>
<td>3.34</td>
</tr>
<tr>
<td>2</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.99</td>
<td>0.46</td>
<td>2.71</td>
</tr>
<tr>
<td>2</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.70</td>
<td>1.18</td>
<td>1.99</td>
</tr>
<tr>
<td>2</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.76</td>
<td>0.24</td>
<td>2.93</td>
</tr>
<tr>
<td>2</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.81</td>
<td>0.30</td>
<td>2.90</td>
</tr>
<tr>
<td>2</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.76</td>
<td>0.24</td>
<td>2.93</td>
</tr>
<tr>
<td>2</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.67</td>
<td>0.16</td>
<td>3.03</td>
</tr>
<tr>
<td>2</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.94</td>
<td>1.44</td>
<td>1.76</td>
</tr>
<tr>
<td>2</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.85</td>
<td>0.32</td>
<td>2.84</td>
</tr>
<tr>
<td>2</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.46</td>
<td>1.93</td>
<td>5.07</td>
</tr>
<tr>
<td>2</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.70</td>
<td>0.85</td>
<td>4</td>
</tr>
<tr>
<td>2</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.13</td>
<td>1.65</td>
<td>4.81</td>
</tr>
<tr>
<td>2</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.35</td>
<td>1.26</td>
<td>4.42</td>
</tr>
<tr>
<td>2</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.10</td>
<td>1.60</td>
<td>4.76</td>
</tr>
<tr>
<td>2</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.83</td>
<td>2.30</td>
<td>5.46</td>
</tr>
<tr>
<td>2</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.33</td>
<td>0.29</td>
<td>3.37</td>
</tr>
<tr>
<td>2</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.61</td>
<td>1.94</td>
<td>5.08</td>
</tr>
<tr>
<td>2</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.45</td>
<td>4.61</td>
</tr>
<tr>
<td>2</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.52</td>
<td>2.01</td>
<td>5.16</td>
</tr>
<tr>
<td>2</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.68</td>
<td>0.91</td>
<td>4.04</td>
</tr>
<tr>
<td>2</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.51</td>
<td>1.02</td>
<td>4.18</td>
</tr>
<tr>
<td>2</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.27</td>
<td>1.29</td>
<td>4.44</td>
</tr>
<tr>
<td>2</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.77</td>
<td>0.83</td>
<td>3.95</td>
</tr>
<tr>
<td>2</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.73</td>
<td>1.20</td>
<td>4.23</td>
</tr>
<tr>
<td>2</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.51</td>
<td>1.26</td>
<td>4.35</td>
</tr>
<tr>
<td>2</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.41</td>
<td>1.16</td>
<td>4.33</td>
</tr>
<tr>
<td>2</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>0.94</td>
<td>2.43</td>
<td>5.59</td>
</tr>
<tr>
<td>2</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.15</td>
<td>2.65</td>
<td>5.81</td>
</tr>
<tr>
<td>2</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.98</td>
<td>0.60</td>
<td>3.75</td>
</tr>
<tr>
<td>2</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.21</td>
<td>1.57</td>
<td>4.71</td>
</tr>
<tr>
<td>2</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>1</td>
<td>0.87</td>
<td>0.76</td>
<td>3.86</td>
</tr>
<tr>
<td>2</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>0.94</td>
<td>2.37</td>
<td>5.52</td>
</tr>
<tr>
<td>2</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.92</td>
<td>0.63</td>
<td>3.77</td>
</tr>
<tr>
<td>2</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.07</td>
<td>1.47</td>
<td>4.63</td>
</tr>
<tr>
<td>2</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.38</td>
<td>1.64</td>
<td>4.80</td>
</tr>
<tr>
<td>2</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>1.01</td>
<td>0.55</td>
<td>3.68</td>
</tr>
<tr>
<td>2</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.92</td>
<td>0.63</td>
<td>3.77</td>
</tr>
<tr>
<td>2</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.17</td>
<td>1.38</td>
<td>4.53</td>
</tr>
<tr>
<td>2</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.51</td>
<td>1.41</td>
<td>4.54</td>
</tr>
<tr>
<td>2</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.39</td>
<td>1.77</td>
<td>4.92</td>
</tr>
<tr>
<td>2</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.64</td>
<td>2.08</td>
<td>5.24</td>
</tr>
<tr>
<td>2</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.19</td>
<td>1.43</td>
<td>4.58</td>
</tr>
<tr>
<td>2</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.90</td>
<td>0.70</td>
<td>3.85</td>
</tr>
<tr>
<td>2</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.73</td>
<td>1.20</td>
<td>4.30</td>
</tr>
<tr>
<td>2</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.39</td>
<td>1.91</td>
<td>5.07</td>
</tr>
<tr>
<td>2</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.55</td>
<td>4.67</td>
</tr>
<tr>
<td>2</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.41</td>
<td>1.16</td>
<td>4.33</td>
</tr>
<tr>
<td>2</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>1.01</td>
<td>0.55</td>
<td>3.68</td>
</tr>
<tr>
<td>2</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.37</td>
<td>1.21</td>
<td>4.35</td>
</tr>
<tr>
<td>2</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.55</td>
<td>4.67</td>
</tr>
<tr>
<td>2</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.70</td>
<td>1.12</td>
<td>4.18</td>
</tr>
<tr>
<td>2</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.70</td>
<td>0.85</td>
<td>4</td>
</tr>
<tr>
<td>2</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.24</td>
<td>1.74</td>
<td>4.89</td>
</tr>
<tr>
<td>2</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.40</td>
<td>1.69</td>
<td>4.80</td>
</tr>
<tr>
<td>2</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.60</td>
<td>1.19</td>
<td>4.27</td>
</tr>
<tr>
<td>2</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>1</td>
<td>0.79</td>
<td>0.77</td>
<td>3.91</td>
</tr>
<tr>
<td>2</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.58</td>
<td>0.99</td>
<td>4.13</td>
</tr>
<tr>
<td>2</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.42</td>
<td>1.33</td>
<td>4.44</td>
</tr>
<tr>
<td>2</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.73</td>
<td>0.79</td>
<td>3.96</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.34</td>
<td>2.83</td>
<td>0.28</td>
</tr>
<tr>
<td>3</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.15</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.13</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.22</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>5.01</td>
<td>3.50</td>
<td>0.39</td>
</tr>
<tr>
<td>3</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.37</td>
<td>0.27</td>
</tr>
<tr>
<td>3</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.02</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.71</td>
<td>3.21</td>
<td>0.22</td>
</tr>
<tr>
<td>3</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.15</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.38</td>
<td>2.87</td>
<td>0.24</td>
</tr>
<tr>
<td>3</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.56</td>
<td>3.06</td>
<td>0.07</td>
</tr>
<tr>
<td>3</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.42</td>
<td>2.91</td>
<td>0.24</td>
</tr>
<tr>
<td>3</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.02</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.06</td>
<td>3.56</td>
<td>0.46</td>
</tr>
<tr>
<td>3</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.30</td>
<td>2.80</td>
<td>0.35</td>
</tr>
<tr>
<td>3</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.24</td>
<td>2.73</td>
<td>0.44</td>
</tr>
<tr>
<td>3</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.21</td>
</tr>
<tr>
<td>3</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.02</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.13</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.37</td>
<td>0.27</td>
</tr>
<tr>
<td>3</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.22</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.36</td>
<td>2.87</td>
<td>0.38</td>
</tr>
<tr>
<td>3</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.16</td>
<td>2.65</td>
<td>0.46</td>
</tr>
<tr>
<td>3</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.15</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.21</td>
<td>0.35</td>
<td>3.44</td>
</tr>
<tr>
<td>3</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.99</td>
<td>0.56</td>
<td>3.66</td>
</tr>
<tr>
<td>3</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.87</td>
<td>0.37</td>
<td>2.75</td>
</tr>
<tr>
<td>3</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.27</td>
<td>3.38</td>
</tr>
<tr>
<td>3</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.43</td>
<td>0.17</td>
<td>3.22</td>
</tr>
<tr>
<td>3</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.11</td>
<td>0.40</td>
<td>3.51</td>
</tr>
<tr>
<td>3</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.63</td>
<td>1.12</td>
<td>1.99</td>
</tr>
<tr>
<td>3</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.35</td>
<td>0.26</td>
<td>3.31</td>
</tr>
<tr>
<td>3</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.93</td>
<td>0.45</td>
<td>2.70</td>
</tr>
<tr>
<td>3</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.45</td>
<td>0.94</td>
<td>2.17</td>
</tr>
<tr>
<td>3</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.61</td>
<td>0.19</td>
<td>3.01</td>
</tr>
<tr>
<td>3</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>2.02</td>
<td>0.53</td>
<td>2.65</td>
</tr>
<tr>
<td>3</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.21</td>
<td>0.35</td>
<td>3.44</td>
</tr>
<tr>
<td>3</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.24</td>
<td>0.76</td>
<td>2.38</td>
</tr>
<tr>
<td>3</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.47</td>
<td>0.05</td>
<td>3.16</td>
</tr>
<tr>
<td>3</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.93</td>
<td>0.47</td>
<td>2.74</td>
</tr>
<tr>
<td>3</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2.05</td>
<td>0.54</td>
<td>2.58</td>
</tr>
<tr>
<td>3</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.68</td>
</tr>
<tr>
<td>3</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.87</td>
<td>0.37</td>
<td>2.75</td>
</tr>
<tr>
<td>3</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.99</td>
<td>0.56</td>
<td>3.66</td>
</tr>
<tr>
<td>3</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.34</td>
<td>0.40</td>
<td>3.38</td>
</tr>
<tr>
<td>3</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>3.03</td>
</tr>
<tr>
<td>3</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.47</td>
<td>0.05</td>
<td>3.16</td>
</tr>
<tr>
<td>3</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.13</td>
<td>0.45</td>
<td>3.53</td>
</tr>
<tr>
<td>3</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>1</td>
<td>0.80</td>
<td>0.72</td>
<td>3.83</td>
</tr>
<tr>
<td>3</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.45</td>
<td>0.94</td>
<td>2.17</td>
</tr>
<tr>
<td>3</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.14</td>
<td>0.63</td>
<td>2.49</td>
</tr>
<tr>
<td>3</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.28</td>
<td>0.76</td>
<td>2.36</td>
</tr>
<tr>
<td>3</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>2.01</td>
<td>0.49</td>
<td>2.62</td>
</tr>
<tr>
<td>3</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.77</td>
<td>0.77</td>
<td>3.88</td>
</tr>
<tr>
<td>3</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.29</td>
<td>0.25</td>
<td>3.33</td>
</tr>
<tr>
<td>3</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.16</td>
<td>0.36</td>
<td>3.47</td>
</tr>
<tr>
<td>3</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.52</td>
<td>0.10</td>
<td>3.12</td>
</tr>
<tr>
<td>3</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.78</td>
<td>0.27</td>
<td>2.84</td>
</tr>
<tr>
<td>3</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.87</td>
<td>0.37</td>
<td>2.75</td>
</tr>
<tr>
<td>3</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.57</td>
<td>0.20</td>
<td>3.09</td>
</tr>
<tr>
<td>3</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.30</td>
<td>0.25</td>
<td>3.34</td>
</tr>
<tr>
<td>3</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.92</td>
<td>0.40</td>
<td>2.71</td>
</tr>
<tr>
<td>3</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.63</td>
<td>1.12</td>
<td>1.99</td>
</tr>
<tr>
<td>3</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.69</td>
<td>0.18</td>
<td>2.93</td>
</tr>
<tr>
<td>3</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.74</td>
<td>0.25</td>
<td>2.90</td>
</tr>
<tr>
<td>3</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.69</td>
<td>0.18</td>
<td>2.93</td>
</tr>
<tr>
<td>3</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>3.03</td>
</tr>
<tr>
<td>3</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.87</td>
<td>1.39</td>
<td>1.76</td>
</tr>
<tr>
<td>3</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.78</td>
<td>0.27</td>
<td>2.84</td>
</tr>
<tr>
<td>3</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.51</td>
<td>1.98</td>
<td>5.07</td>
</tr>
<tr>
<td>3</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.63</td>
<td>0.90</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1.70</td>
<td>4.81</td>
</tr>
<tr>
<td>3</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.30</td>
<td>1.31</td>
<td>4.42</td>
</tr>
<tr>
<td>3</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.66</td>
<td>4.76</td>
</tr>
<tr>
<td>3</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.90</td>
<td>2.35</td>
<td>5.46</td>
</tr>
<tr>
<td>3</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.26</td>
<td>0.34</td>
<td>3.37</td>
</tr>
<tr>
<td>3</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.66</td>
<td>1.99</td>
<td>5.08</td>
</tr>
<tr>
<td>3</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.30</td>
<td>1.50</td>
<td>4.61</td>
</tr>
<tr>
<td>3</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.58</td>
<td>2.07</td>
<td>5.16</td>
</tr>
<tr>
<td>3</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.61</td>
<td>0.96</td>
<td>4.04</td>
</tr>
<tr>
<td>3</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.44</td>
<td>1.07</td>
<td>4.18</td>
</tr>
<tr>
<td>3</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1.35</td>
<td>4.44</td>
</tr>
<tr>
<td>3</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.71</td>
<td>0.89</td>
<td>3.95</td>
</tr>
<tr>
<td>3</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.68</td>
<td>1.25</td>
<td>4.23</td>
</tr>
<tr>
<td>3</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1.31</td>
<td>4.35</td>
</tr>
<tr>
<td>3</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.35</td>
<td>1.22</td>
<td>4.33</td>
</tr>
<tr>
<td>3</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.01</td>
<td>2.48</td>
<td>5.59</td>
</tr>
<tr>
<td>3</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.22</td>
<td>2.70</td>
<td>5.81</td>
</tr>
<tr>
<td>3</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.91</td>
<td>0.65</td>
<td>3.75</td>
</tr>
<tr>
<td>3</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.21</td>
<td>1.62</td>
<td>4.71</td>
</tr>
<tr>
<td>3</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.80</td>
<td>0.82</td>
<td>3.86</td>
</tr>
<tr>
<td>3</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>2.42</td>
<td>5.52</td>
</tr>
<tr>
<td>3</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.68</td>
<td>3.77</td>
</tr>
<tr>
<td>3</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.01</td>
<td>1.52</td>
<td>4.63</td>
</tr>
<tr>
<td>3</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.41</td>
<td>1.70</td>
<td>4.80</td>
</tr>
<tr>
<td>3</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.68</td>
</tr>
<tr>
<td>3</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.68</td>
<td>3.77</td>
</tr>
<tr>
<td>3</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.10</td>
<td>1.43</td>
<td>4.53</td>
</tr>
<tr>
<td>3</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.50</td>
<td>1.46</td>
<td>4.54</td>
</tr>
<tr>
<td>3</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.44</td>
<td>1.82</td>
<td>4.92</td>
</tr>
<tr>
<td>3</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.71</td>
<td>2.13</td>
<td>5.24</td>
</tr>
<tr>
<td>3</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.49</td>
<td>4.58</td>
</tr>
<tr>
<td>3</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.84</td>
<td>0.75</td>
<td>3.85</td>
</tr>
<tr>
<td>3</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.69</td>
<td>1.25</td>
<td>4.30</td>
</tr>
<tr>
<td>3</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1.97</td>
<td>5.07</td>
</tr>
<tr>
<td>3</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.33</td>
<td>1.60</td>
<td>4.67</td>
</tr>
<tr>
<td>3</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.35</td>
<td>1.22</td>
<td>4.33</td>
</tr>
<tr>
<td>3</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.68</td>
</tr>
<tr>
<td>3</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.30</td>
<td>1.26</td>
<td>4.35</td>
</tr>
<tr>
<td>3</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.33</td>
<td>1.60</td>
<td>4.67</td>
</tr>
<tr>
<td>3</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.64</td>
<td>1.18</td>
<td>4.18</td>
</tr>
<tr>
<td>3</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.63</td>
<td>0.90</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.29</td>
<td>1.79</td>
<td>4.89</td>
</tr>
<tr>
<td>3</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.41</td>
<td>1.74</td>
<td>4.80</td>
</tr>
<tr>
<td>3</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.54</td>
<td>1.24</td>
<td>4.27</td>
</tr>
<tr>
<td>3</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.72</td>
<td>0.82</td>
<td>3.91</td>
</tr>
<tr>
<td>3</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.51</td>
<td>1.04</td>
<td>4.13</td>
</tr>
<tr>
<td>3</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.37</td>
<td>1.39</td>
<td>4.44</td>
</tr>
<tr>
<td>3</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.66</td>
<td>0.85</td>
<td>3.96</td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.29</td>
<td>2.79</td>
<td>0.28</td>
</tr>
<tr>
<td>4</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.61</td>
<td>3.11</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.69</td>
<td>3.18</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>4.96</td>
<td>3.46</td>
<td>0.39</td>
</tr>
<tr>
<td>4</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.83</td>
<td>3.33</td>
<td>0.27</td>
</tr>
<tr>
<td>4</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.47</td>
<td>2.98</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.66</td>
<td>3.17</td>
<td>0.22</td>
</tr>
<tr>
<td>4</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.61</td>
<td>3.11</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.33</td>
<td>2.83</td>
<td>0.24</td>
</tr>
<tr>
<td>4</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.51</td>
<td>3.02</td>
<td>0.07</td>
</tr>
<tr>
<td>4</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.37</td>
<td>2.87</td>
<td>0.24</td>
</tr>
<tr>
<td>4</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.47</td>
<td>2.98</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.01</td>
<td>3.52</td>
<td>0.46</td>
</tr>
<tr>
<td>4</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.25</td>
<td>2.76</td>
<td>0.35</td>
</tr>
<tr>
<td>4</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.19</td>
<td>2.69</td>
<td>0.44</td>
</tr>
<tr>
<td>4</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.38</td>
<td>2.89</td>
<td>0.21</td>
</tr>
<tr>
<td>4</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.47</td>
<td>2.98</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.83</td>
<td>3.33</td>
<td>0.27</td>
</tr>
<tr>
<td>4</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.69</td>
<td>3.18</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.70</td>
<td>3.20</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.70</td>
<td>3.20</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.31</td>
<td>2.83</td>
<td>0.38</td>
</tr>
<tr>
<td>4</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.11</td>
<td>2.61</td>
<td>0.46</td>
</tr>
<tr>
<td>4</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.61</td>
<td>3.11</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.16</td>
<td>0.38</td>
<td>3.44</td>
</tr>
<tr>
<td>4</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.66</td>
</tr>
<tr>
<td>4</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.82</td>
<td>0.33</td>
<td>2.75</td>
</tr>
<tr>
<td>4</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.20</td>
<td>0.31</td>
<td>3.38</td>
</tr>
<tr>
<td>4</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.38</td>
<td>0.19</td>
<td>3.22</td>
</tr>
<tr>
<td>4</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.06</td>
<td>0.45</td>
<td>3.51</td>
</tr>
<tr>
<td>4</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.58</td>
<td>1.08</td>
<td>1.99</td>
</tr>
<tr>
<td>4</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.30</td>
<td>0.29</td>
<td>3.31</td>
</tr>
<tr>
<td>4</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.88</td>
<td>0.42</td>
<td>2.70</td>
</tr>
<tr>
<td>4</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.40</td>
<td>0.90</td>
<td>2.17</td>
</tr>
<tr>
<td>4</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.56</td>
<td>0.18</td>
<td>3.01</td>
</tr>
<tr>
<td>4</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1.97</td>
<td>0.49</td>
<td>2.65</td>
</tr>
<tr>
<td>4</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.16</td>
<td>0.38</td>
<td>3.44</td>
</tr>
<tr>
<td>4</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.19</td>
<td>0.72</td>
<td>2.38</td>
</tr>
<tr>
<td>4</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.42</td>
<td>0.09</td>
<td>3.16</td>
</tr>
<tr>
<td>4</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.88</td>
<td>0.43</td>
<td>2.74</td>
</tr>
<tr>
<td>4</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2</td>
<td>0.50</td>
<td>2.58</td>
</tr>
<tr>
<td>4</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.89</td>
<td>0.65</td>
<td>3.68</td>
</tr>
<tr>
<td>4</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.82</td>
<td>0.33</td>
<td>2.75</td>
</tr>
<tr>
<td>4</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.66</td>
</tr>
<tr>
<td>4</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.29</td>
<td>0.42</td>
<td>3.38</td>
</tr>
<tr>
<td>4</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.56</td>
<td>0.07</td>
<td>3.03</td>
</tr>
<tr>
<td>4</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.42</td>
<td>0.09</td>
<td>3.16</td>
</tr>
<tr>
<td>4</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.08</td>
<td>0.48</td>
<td>3.53</td>
</tr>
<tr>
<td>4</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>0</td>
<td>0.75</td>
<td>0.76</td>
<td>3.83</td>
</tr>
<tr>
<td>4</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.40</td>
<td>0.90</td>
<td>2.17</td>
</tr>
<tr>
<td>4</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.09</td>
<td>0.58</td>
<td>2.49</td>
</tr>
<tr>
<td>4</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.23</td>
<td>0.72</td>
<td>2.36</td>
</tr>
<tr>
<td>4</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>1.96</td>
<td>0.45</td>
<td>2.62</td>
</tr>
<tr>
<td>4</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.72</td>
<td>0.81</td>
<td>3.88</td>
</tr>
<tr>
<td>4</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.24</td>
<td>0.29</td>
<td>3.33</td>
</tr>
<tr>
<td>4</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.11</td>
<td>0.40</td>
<td>3.47</td>
</tr>
<tr>
<td>4</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.47</td>
<td>0.11</td>
<td>3.12</td>
</tr>
<tr>
<td>4</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.73</td>
<td>0.23</td>
<td>2.84</td>
</tr>
<tr>
<td>4</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.82</td>
<td>0.33</td>
<td>2.75</td>
</tr>
<tr>
<td>4</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.52</td>
<td>0.19</td>
<td>3.09</td>
</tr>
<tr>
<td>4</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.25</td>
<td>0.28</td>
<td>3.34</td>
</tr>
<tr>
<td>4</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.87</td>
<td>0.36</td>
<td>2.71</td>
</tr>
<tr>
<td>4</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.58</td>
<td>1.08</td>
<td>1.99</td>
</tr>
<tr>
<td>4</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.64</td>
<td>0.14</td>
<td>2.93</td>
</tr>
<tr>
<td>4</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.69</td>
<td>0.21</td>
<td>2.90</td>
</tr>
<tr>
<td>4</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.64</td>
<td>0.14</td>
<td>2.93</td>
</tr>
<tr>
<td>4</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.56</td>
<td>0.07</td>
<td>3.03</td>
</tr>
<tr>
<td>4</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.82</td>
<td>1.35</td>
<td>1.76</td>
</tr>
<tr>
<td>4</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.73</td>
<td>0.23</td>
<td>2.84</td>
</tr>
<tr>
<td>4</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.55</td>
<td>2.03</td>
<td>5.07</td>
</tr>
<tr>
<td>4</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.58</td>
<td>0.94</td>
<td>4</td>
</tr>
<tr>
<td>4</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.25</td>
<td>1.74</td>
<td>4.81</td>
</tr>
<tr>
<td>4</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.27</td>
<td>1.35</td>
<td>4.42</td>
</tr>
<tr>
<td>4</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.20</td>
<td>1.70</td>
<td>4.76</td>
</tr>
<tr>
<td>4</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.95</td>
<td>2.40</td>
<td>5.46</td>
</tr>
<tr>
<td>4</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.21</td>
<td>0.38</td>
<td>3.37</td>
</tr>
<tr>
<td>4</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.70</td>
<td>2.03</td>
<td>5.08</td>
</tr>
<tr>
<td>4</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.54</td>
<td>4.61</td>
</tr>
<tr>
<td>4</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.62</td>
<td>2.11</td>
<td>5.16</td>
</tr>
<tr>
<td>4</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.56</td>
<td>1</td>
<td>4.04</td>
</tr>
<tr>
<td>4</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.39</td>
<td>1.12</td>
<td>4.18</td>
</tr>
<tr>
<td>4</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.16</td>
<td>1.39</td>
<td>4.44</td>
</tr>
<tr>
<td>4</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.66</td>
<td>0.93</td>
<td>3.95</td>
</tr>
<tr>
<td>4</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.64</td>
<td>1.29</td>
<td>4.23</td>
</tr>
<tr>
<td>4</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.42</td>
<td>1.35</td>
<td>4.35</td>
</tr>
<tr>
<td>4</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.26</td>
<td>4.33</td>
</tr>
<tr>
<td>4</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.06</td>
<td>2.52</td>
<td>5.59</td>
</tr>
<tr>
<td>4</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.27</td>
<td>2.74</td>
<td>5.81</td>
</tr>
<tr>
<td>4</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.87</td>
<td>0.69</td>
<td>3.75</td>
</tr>
<tr>
<td>4</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.24</td>
<td>1.67</td>
<td>4.71</td>
</tr>
<tr>
<td>4</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.76</td>
<td>0.86</td>
<td>3.86</td>
</tr>
<tr>
<td>4</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1.05</td>
<td>2.46</td>
<td>5.52</td>
</tr>
<tr>
<td>4</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.80</td>
<td>0.72</td>
<td>3.77</td>
</tr>
<tr>
<td>4</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.56</td>
<td>4.63</td>
</tr>
<tr>
<td>4</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.44</td>
<td>1.74</td>
<td>4.80</td>
</tr>
<tr>
<td>4</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.89</td>
<td>0.65</td>
<td>3.68</td>
</tr>
<tr>
<td>4</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.80</td>
<td>0.72</td>
<td>3.77</td>
</tr>
<tr>
<td>4</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.47</td>
<td>4.53</td>
</tr>
<tr>
<td>4</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.49</td>
<td>1.50</td>
<td>4.54</td>
</tr>
<tr>
<td>4</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.48</td>
<td>1.86</td>
<td>4.92</td>
</tr>
<tr>
<td>4</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.75</td>
<td>2.17</td>
<td>5.24</td>
</tr>
<tr>
<td>4</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.14</td>
<td>1.53</td>
<td>4.58</td>
</tr>
<tr>
<td>4</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.79</td>
<td>0.79</td>
<td>3.85</td>
</tr>
<tr>
<td>4</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.67</td>
<td>1.28</td>
<td>4.30</td>
</tr>
<tr>
<td>4</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.50</td>
<td>2.01</td>
<td>5.07</td>
</tr>
<tr>
<td>4</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.64</td>
<td>4.67</td>
</tr>
<tr>
<td>4</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.26</td>
<td>4.33</td>
</tr>
<tr>
<td>4</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.89</td>
<td>0.65</td>
<td>3.68</td>
</tr>
<tr>
<td>4</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.25</td>
<td>1.31</td>
<td>4.35</td>
</tr>
<tr>
<td>4</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.64</td>
<td>4.67</td>
</tr>
<tr>
<td>4</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.60</td>
<td>1.22</td>
<td>4.18</td>
</tr>
<tr>
<td>4</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.58</td>
<td>0.94</td>
<td>4</td>
</tr>
<tr>
<td>4</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.83</td>
<td>4.89</td>
</tr>
<tr>
<td>4</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.43</td>
<td>1.79</td>
<td>4.80</td>
</tr>
<tr>
<td>4</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.51</td>
<td>1.28</td>
<td>4.27</td>
</tr>
<tr>
<td>4</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.67</td>
<td>0.86</td>
<td>3.91</td>
</tr>
<tr>
<td>4</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.46</td>
<td>1.08</td>
<td>4.13</td>
</tr>
<tr>
<td>4</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.43</td>
<td>4.44</td>
</tr>
<tr>
<td>4</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.61</td>
<td>0.89</td>
<td>3.96</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.27</td>
<td>2.78</td>
<td>0.28</td>
</tr>
<tr>
<td>5</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.59</td>
<td>3.10</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.58</td>
<td>3.08</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>4.94</td>
<td>3.45</td>
<td>0.39</td>
</tr>
<tr>
<td>5</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.81</td>
<td>3.32</td>
<td>0.27</td>
</tr>
<tr>
<td>5</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.46</td>
<td>2.97</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.64</td>
<td>3.16</td>
<td>0.22</td>
</tr>
<tr>
<td>5</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.59</td>
<td>3.10</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.31</td>
<td>2.82</td>
<td>0.24</td>
</tr>
<tr>
<td>5</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.50</td>
<td>3</td>
<td>0.07</td>
</tr>
<tr>
<td>5</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.35</td>
<td>2.85</td>
<td>0.24</td>
</tr>
<tr>
<td>5</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.46</td>
<td>2.97</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5</td>
<td>3.51</td>
<td>0.46</td>
</tr>
<tr>
<td>5</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.24</td>
<td>2.75</td>
<td>0.35</td>
</tr>
<tr>
<td>5</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.17</td>
<td>2.67</td>
<td>0.44</td>
</tr>
<tr>
<td>5</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.37</td>
<td>2.87</td>
<td>0.21</td>
</tr>
<tr>
<td>5</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.46</td>
<td>2.97</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.58</td>
<td>3.08</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.81</td>
<td>3.32</td>
<td>0.27</td>
</tr>
<tr>
<td>5</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.68</td>
<td>3.19</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.68</td>
<td>3.19</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.29</td>
<td>2.81</td>
<td>0.38</td>
</tr>
<tr>
<td>5</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.09</td>
<td>2.59</td>
<td>0.46</td>
</tr>
<tr>
<td>5</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.59</td>
<td>3.10</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.15</td>
<td>0.39</td>
<td>3.44</td>
</tr>
<tr>
<td>5</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.93</td>
<td>0.61</td>
<td>3.66</td>
</tr>
<tr>
<td>5</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.81</td>
<td>0.31</td>
<td>2.75</td>
</tr>
<tr>
<td>5</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.18</td>
<td>0.32</td>
<td>3.38</td>
</tr>
<tr>
<td>5</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.37</td>
<td>0.20</td>
<td>3.22</td>
</tr>
<tr>
<td>5</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.04</td>
<td>0.46</td>
<td>3.51</td>
</tr>
<tr>
<td>5</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.57</td>
<td>1.07</td>
<td>1.99</td>
</tr>
<tr>
<td>5</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.29</td>
<td>0.30</td>
<td>3.31</td>
</tr>
<tr>
<td>5</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.86</td>
<td>0.41</td>
<td>2.70</td>
</tr>
<tr>
<td>5</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.39</td>
<td>0.88</td>
<td>2.17</td>
</tr>
<tr>
<td>5</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.54</td>
<td>0.17</td>
<td>3.01</td>
</tr>
<tr>
<td>5</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1.95</td>
<td>0.47</td>
<td>2.65</td>
</tr>
<tr>
<td>5</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.15</td>
<td>0.39</td>
<td>3.44</td>
</tr>
<tr>
<td>5</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.17</td>
<td>0.71</td>
<td>2.38</td>
</tr>
<tr>
<td>5</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.40</td>
<td>0.10</td>
<td>3.16</td>
</tr>
<tr>
<td>5</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.87</td>
<td>0.42</td>
<td>2.74</td>
</tr>
<tr>
<td>5</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>1.99</td>
<td>0.48</td>
<td>2.58</td>
</tr>
<tr>
<td>5</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.88</td>
<td>0.66</td>
<td>3.68</td>
</tr>
<tr>
<td>5</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.81</td>
<td>0.31</td>
<td>2.75</td>
</tr>
<tr>
<td>5</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.93</td>
<td>0.61</td>
<td>3.66</td>
</tr>
<tr>
<td>5</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.27</td>
<td>0.42</td>
<td>3.38</td>
</tr>
<tr>
<td>5</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.54</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>5</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.40</td>
<td>0.10</td>
<td>3.16</td>
</tr>
<tr>
<td>5</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.07</td>
<td>0.49</td>
<td>3.53</td>
</tr>
<tr>
<td>5</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>0</td>
<td>0.73</td>
<td>0.77</td>
<td>3.83</td>
</tr>
<tr>
<td>5</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.39</td>
<td>0.88</td>
<td>2.17</td>
</tr>
<tr>
<td>5</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.07</td>
<td>0.57</td>
<td>2.49</td>
</tr>
<tr>
<td>5</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.21</td>
<td>0.71</td>
<td>2.36</td>
</tr>
<tr>
<td>5</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>1.94</td>
<td>0.44</td>
<td>2.62</td>
</tr>
<tr>
<td>5</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.71</td>
<td>0.83</td>
<td>3.88</td>
</tr>
<tr>
<td>5</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.23</td>
<td>0.31</td>
<td>3.33</td>
</tr>
<tr>
<td>5</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.09</td>
<td>0.42</td>
<td>3.47</td>
</tr>
<tr>
<td>5</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.45</td>
<td>0.11</td>
<td>3.12</td>
</tr>
<tr>
<td>5</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.72</td>
<td>0.22</td>
<td>2.84</td>
</tr>
<tr>
<td>5</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.81</td>
<td>0.31</td>
<td>2.75</td>
</tr>
<tr>
<td>5</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.51</td>
<td>0.19</td>
<td>3.09</td>
</tr>
<tr>
<td>5</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.23</td>
<td>0.30</td>
<td>3.34</td>
</tr>
<tr>
<td>5</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.85</td>
<td>0.35</td>
<td>2.71</td>
</tr>
<tr>
<td>5</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.57</td>
<td>1.07</td>
<td>1.99</td>
</tr>
<tr>
<td>5</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.63</td>
<td>0.12</td>
<td>2.93</td>
</tr>
<tr>
<td>5</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.68</td>
<td>0.19</td>
<td>2.90</td>
</tr>
<tr>
<td>5</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.63</td>
<td>0.12</td>
<td>2.93</td>
</tr>
<tr>
<td>5</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.54</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>5</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.81</td>
<td>1.33</td>
<td>1.76</td>
</tr>
<tr>
<td>5</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.72</td>
<td>0.22</td>
<td>2.84</td>
</tr>
<tr>
<td>5</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.57</td>
<td>2.04</td>
<td>5.07</td>
</tr>
<tr>
<td>5</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.56</td>
<td>0.96</td>
<td>4</td>
</tr>
<tr>
<td>5</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.27</td>
<td>1.76</td>
<td>4.81</td>
</tr>
<tr>
<td>5</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.26</td>
<td>1.36</td>
<td>4.42</td>
</tr>
<tr>
<td>5</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.21</td>
<td>1.71</td>
<td>4.76</td>
</tr>
<tr>
<td>5</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.96</td>
<td>2.41</td>
<td>5.46</td>
</tr>
<tr>
<td>5</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.19</td>
<td>0.39</td>
<td>3.37</td>
</tr>
<tr>
<td>5</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.71</td>
<td>2.04</td>
<td>5.08</td>
</tr>
<tr>
<td>5</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.56</td>
<td>4.61</td>
</tr>
<tr>
<td>5</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.64</td>
<td>2.12</td>
<td>5.16</td>
</tr>
<tr>
<td>5</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.54</td>
<td>1.02</td>
<td>4.04</td>
</tr>
<tr>
<td>5</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.37</td>
<td>1.13</td>
<td>4.18</td>
</tr>
<tr>
<td>5</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.14</td>
<td>1.40</td>
<td>4.44</td>
</tr>
<tr>
<td>5</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.64</td>
<td>0.94</td>
<td>3.95</td>
</tr>
<tr>
<td>5</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.64</td>
<td>1.31</td>
<td>4.23</td>
</tr>
<tr>
<td>5</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.41</td>
<td>1.37</td>
<td>4.35</td>
</tr>
<tr>
<td>5</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.29</td>
<td>1.27</td>
<td>4.33</td>
</tr>
<tr>
<td>5</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.07</td>
<td>2.54</td>
<td>5.59</td>
</tr>
<tr>
<td>5</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.28</td>
<td>2.76</td>
<td>5.81</td>
</tr>
<tr>
<td>5</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.85</td>
<td>0.71</td>
<td>3.75</td>
</tr>
<tr>
<td>5</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.25</td>
<td>1.68</td>
<td>4.71</td>
</tr>
<tr>
<td>5</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.74</td>
<td>0.87</td>
<td>3.86</td>
</tr>
<tr>
<td>5</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1.06</td>
<td>2.48</td>
<td>5.52</td>
</tr>
<tr>
<td>5</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.78</td>
<td>0.74</td>
<td>3.77</td>
</tr>
<tr>
<td>5</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.07</td>
<td>1.58</td>
<td>4.63</td>
</tr>
<tr>
<td>5</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.45</td>
<td>1.75</td>
<td>4.80</td>
</tr>
<tr>
<td>5</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.88</td>
<td>0.66</td>
<td>3.68</td>
</tr>
<tr>
<td>5</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.78</td>
<td>0.74</td>
<td>3.77</td>
</tr>
<tr>
<td>5</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.49</td>
<td>4.53</td>
</tr>
<tr>
<td>5</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.49</td>
<td>1.51</td>
<td>4.54</td>
</tr>
<tr>
<td>5</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.49</td>
<td>1.87</td>
<td>4.92</td>
</tr>
<tr>
<td>5</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.76</td>
<td>2.19</td>
<td>5.24</td>
</tr>
<tr>
<td>5</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.54</td>
<td>4.58</td>
</tr>
<tr>
<td>5</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>0</td>
<td>0.78</td>
<td>0.80</td>
<td>3.85</td>
</tr>
<tr>
<td>5</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.66</td>
<td>1.29</td>
<td>4.30</td>
</tr>
<tr>
<td>5</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.52</td>
<td>2.02</td>
<td>5.07</td>
</tr>
<tr>
<td>5</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.66</td>
<td>4.67</td>
</tr>
<tr>
<td>5</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.29</td>
<td>1.27</td>
<td>4.33</td>
</tr>
<tr>
<td>5</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.88</td>
<td>0.66</td>
<td>3.68</td>
</tr>
<tr>
<td>5</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.24</td>
<td>1.32</td>
<td>4.35</td>
</tr>
<tr>
<td>5</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.66</td>
<td>4.67</td>
</tr>
<tr>
<td>5</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.59</td>
<td>1.23</td>
<td>4.18</td>
</tr>
<tr>
<td>5</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.56</td>
<td>0.96</td>
<td>4</td>
</tr>
<tr>
<td>5</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.36</td>
<td>1.85</td>
<td>4.89</td>
</tr>
<tr>
<td>5</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.44</td>
<td>1.80</td>
<td>4.80</td>
</tr>
<tr>
<td>5</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.50</td>
<td>1.30</td>
<td>4.27</td>
</tr>
<tr>
<td>5</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.66</td>
<td>0.88</td>
<td>3.91</td>
</tr>
<tr>
<td>5</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.44</td>
<td>1.10</td>
<td>4.13</td>
</tr>
<tr>
<td>5</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.44</td>
<td>4.44</td>
</tr>
<tr>
<td>5</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.60</td>
<td>0.91</td>
<td>3.96</td>
</tr>
<tr>
<td>6</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.26</td>
<td>2.76</td>
<td>0.28</td>
</tr>
<tr>
<td>6</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.08</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.56</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.15</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>4.93</td>
<td>3.43</td>
<td>0.39</td>
</tr>
<tr>
<td>6</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.80</td>
<td>3.30</td>
<td>0.27</td>
</tr>
<tr>
<td>6</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>2.95</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.63</td>
<td>3.14</td>
<td>0.22</td>
</tr>
<tr>
<td>6</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.08</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.30</td>
<td>2.80</td>
<td>0.24</td>
</tr>
<tr>
<td>6</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.48</td>
<td>2.99</td>
<td>0.07</td>
</tr>
<tr>
<td>6</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.34</td>
<td>2.84</td>
<td>0.24</td>
</tr>
<tr>
<td>6</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>2.95</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>4.98</td>
<td>3.49</td>
<td>0.46</td>
</tr>
<tr>
<td>6</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.22</td>
<td>2.73</td>
<td>0.35</td>
</tr>
<tr>
<td>6</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.16</td>
<td>2.66</td>
<td>0.44</td>
</tr>
<tr>
<td>6</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.35</td>
<td>2.86</td>
<td>0.21</td>
</tr>
<tr>
<td>6</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>2.95</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.56</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.80</td>
<td>3.30</td>
<td>0.27</td>
</tr>
<tr>
<td>6</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.15</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.28</td>
<td>2.80</td>
<td>0.38</td>
</tr>
<tr>
<td>6</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.07</td>
<td>2.58</td>
<td>0.46</td>
</tr>
<tr>
<td>6</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.08</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.13</td>
<td>0.41</td>
<td>3.44</td>
</tr>
<tr>
<td>6</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.91</td>
<td>0.62</td>
<td>3.66</td>
</tr>
<tr>
<td>6</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.30</td>
<td>2.75</td>
</tr>
<tr>
<td>6</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.16</td>
<td>0.34</td>
<td>3.38</td>
</tr>
<tr>
<td>6</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.35</td>
<td>0.22</td>
<td>3.22</td>
</tr>
<tr>
<td>6</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.03</td>
<td>0.47</td>
<td>3.51</td>
</tr>
<tr>
<td>6</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.55</td>
<td>1.06</td>
<td>1.99</td>
</tr>
<tr>
<td>6</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.27</td>
<td>0.31</td>
<td>3.31</td>
</tr>
<tr>
<td>6</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.84</td>
<td>0.39</td>
<td>2.70</td>
</tr>
<tr>
<td>6</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.37</td>
<td>0.87</td>
<td>2.17</td>
</tr>
<tr>
<td>6</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.53</td>
<td>0.17</td>
<td>3.01</td>
</tr>
<tr>
<td>6</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1.93</td>
<td>0.46</td>
<td>2.65</td>
</tr>
<tr>
<td>6</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.13</td>
<td>0.41</td>
<td>3.44</td>
</tr>
<tr>
<td>6</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.16</td>
<td>0.70</td>
<td>2.38</td>
</tr>
<tr>
<td>6</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.39</td>
<td>0.11</td>
<td>3.16</td>
</tr>
<tr>
<td>6</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.85</td>
<td>0.41</td>
<td>2.74</td>
</tr>
<tr>
<td>6</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>1.97</td>
<td>0.47</td>
<td>2.58</td>
</tr>
<tr>
<td>6</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.86</td>
<td>0.67</td>
<td>3.68</td>
</tr>
<tr>
<td>6</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.30</td>
<td>2.75</td>
</tr>
<tr>
<td>6</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.91</td>
<td>0.62</td>
<td>3.66</td>
</tr>
<tr>
<td>6</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.26</td>
<td>0.44</td>
<td>3.38</td>
</tr>
<tr>
<td>6</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.52</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>6</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.39</td>
<td>0.11</td>
<td>3.16</td>
</tr>
<tr>
<td>6</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.05</td>
<td>0.51</td>
<td>3.53</td>
</tr>
<tr>
<td>6</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>0</td>
<td>0.72</td>
<td>0.79</td>
<td>3.83</td>
</tr>
<tr>
<td>6</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.37</td>
<td>0.87</td>
<td>2.17</td>
</tr>
<tr>
<td>6</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.06</td>
<td>0.56</td>
<td>2.49</td>
</tr>
<tr>
<td>6</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.19</td>
<td>0.69</td>
<td>2.36</td>
</tr>
<tr>
<td>6</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>1.92</td>
<td>0.42</td>
<td>2.62</td>
</tr>
<tr>
<td>6</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.69</td>
<td>0.84</td>
<td>3.88</td>
</tr>
<tr>
<td>6</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.21</td>
<td>0.32</td>
<td>3.33</td>
</tr>
<tr>
<td>6</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.08</td>
<td>0.43</td>
<td>3.47</td>
</tr>
<tr>
<td>6</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.44</td>
<td>0.12</td>
<td>3.12</td>
</tr>
<tr>
<td>6</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.20</td>
<td>2.84</td>
</tr>
<tr>
<td>6</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.30</td>
<td>2.75</td>
</tr>
<tr>
<td>6</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.49</td>
<td>0.19</td>
<td>3.09</td>
</tr>
<tr>
<td>6</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.21</td>
<td>0.31</td>
<td>3.34</td>
</tr>
<tr>
<td>6</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.83</td>
<td>0.33</td>
<td>2.71</td>
</tr>
<tr>
<td>6</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.55</td>
<td>1.06</td>
<td>1.99</td>
</tr>
<tr>
<td>6</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>2.93</td>
</tr>
<tr>
<td>6</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.66</td>
<td>0.18</td>
<td>2.90</td>
</tr>
<tr>
<td>6</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>2.93</td>
</tr>
<tr>
<td>6</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.52</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>6</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.79</td>
<td>1.32</td>
<td>1.76</td>
</tr>
<tr>
<td>6</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.20</td>
<td>2.84</td>
</tr>
<tr>
<td>6</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.59</td>
<td>2.05</td>
<td>5.07</td>
</tr>
<tr>
<td>6</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.55</td>
<td>0.97</td>
<td>4</td>
</tr>
<tr>
<td>6</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.28</td>
<td>1.77</td>
<td>4.81</td>
</tr>
<tr>
<td>6</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.25</td>
<td>1.38</td>
<td>4.42</td>
</tr>
<tr>
<td>6</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.23</td>
<td>1.73</td>
<td>4.76</td>
</tr>
<tr>
<td>6</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.98</td>
<td>2.42</td>
<td>5.46</td>
</tr>
<tr>
<td>6</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.18</td>
<td>0.40</td>
<td>3.37</td>
</tr>
<tr>
<td>6</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.72</td>
<td>2.06</td>
<td>5.08</td>
</tr>
<tr>
<td>6</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.30</td>
<td>1.57</td>
<td>4.61</td>
</tr>
<tr>
<td>6</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.66</td>
<td>2.14</td>
<td>5.16</td>
</tr>
<tr>
<td>6</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.53</td>
<td>1.03</td>
<td>4.04</td>
</tr>
<tr>
<td>6</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.36</td>
<td>1.14</td>
<td>4.18</td>
</tr>
<tr>
<td>6</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.14</td>
<td>1.42</td>
<td>4.44</td>
</tr>
<tr>
<td>6</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.63</td>
<td>0.95</td>
<td>3.95</td>
</tr>
<tr>
<td>6</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.63</td>
<td>1.32</td>
<td>4.23</td>
</tr>
<tr>
<td>6</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.41</td>
<td>1.38</td>
<td>4.35</td>
</tr>
<tr>
<td>6</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.28</td>
<td>1.29</td>
<td>4.33</td>
</tr>
<tr>
<td>6</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.08</td>
<td>2.55</td>
<td>5.59</td>
</tr>
<tr>
<td>6</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.30</td>
<td>2.77</td>
<td>5.81</td>
</tr>
<tr>
<td>6</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.83</td>
<td>0.72</td>
<td>3.75</td>
</tr>
<tr>
<td>6</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.26</td>
<td>1.69</td>
<td>4.71</td>
</tr>
<tr>
<td>6</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.73</td>
<td>0.88</td>
<td>3.86</td>
</tr>
<tr>
<td>6</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1.07</td>
<td>2.49</td>
<td>5.52</td>
</tr>
<tr>
<td>6</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.77</td>
<td>0.75</td>
<td>3.77</td>
</tr>
<tr>
<td>6</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.09</td>
<td>1.59</td>
<td>4.63</td>
</tr>
<tr>
<td>6</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.45</td>
<td>1.76</td>
<td>4.80</td>
</tr>
<tr>
<td>6</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.86</td>
<td>0.67</td>
<td>3.68</td>
</tr>
<tr>
<td>6</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.77</td>
<td>0.75</td>
<td>3.77</td>
</tr>
<tr>
<td>6</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.50</td>
<td>4.53</td>
</tr>
<tr>
<td>6</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.48</td>
<td>1.53</td>
<td>4.54</td>
</tr>
<tr>
<td>6</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.50</td>
<td>1.89</td>
<td>4.92</td>
</tr>
<tr>
<td>6</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.78</td>
<td>2.20</td>
<td>5.24</td>
</tr>
<tr>
<td>6</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.55</td>
<td>4.58</td>
</tr>
<tr>
<td>6</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>0</td>
<td>0.76</td>
<td>0.82</td>
<td>3.85</td>
</tr>
<tr>
<td>6</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.65</td>
<td>1.31</td>
<td>4.30</td>
</tr>
<tr>
<td>6</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.54</td>
<td>2.04</td>
<td>5.07</td>
</tr>
<tr>
<td>6</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.35</td>
<td>1.67</td>
<td>4.67</td>
</tr>
<tr>
<td>6</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.28</td>
<td>1.29</td>
<td>4.33</td>
</tr>
<tr>
<td>6</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.86</td>
<td>0.67</td>
<td>3.68</td>
</tr>
<tr>
<td>6</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.23</td>
<td>1.33</td>
<td>4.35</td>
</tr>
<tr>
<td>6</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.35</td>
<td>1.67</td>
<td>4.67</td>
</tr>
<tr>
<td>6</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.58</td>
<td>1.24</td>
<td>4.18</td>
</tr>
<tr>
<td>6</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.55</td>
<td>0.97</td>
<td>4</td>
</tr>
<tr>
<td>6</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.37</td>
<td>1.86</td>
<td>4.89</td>
</tr>
<tr>
<td>6</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.46</td>
<td>1.81</td>
<td>4.80</td>
</tr>
<tr>
<td>6</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.50</td>
<td>1.31</td>
<td>4.27</td>
</tr>
<tr>
<td>6</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.64</td>
<td>0.89</td>
<td>3.91</td>
</tr>
<tr>
<td>6</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.43</td>
<td>1.11</td>
<td>4.13</td>
</tr>
<tr>
<td>6</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.45</td>
<td>4.44</td>
</tr>
<tr>
<td>6</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.58</td>
<td>0.92</td>
<td>3.96</td>
</tr>
</tbody>
</table>
</div>
<h1 id="k-中心点（AMP）"><a href="#k-中心点（AMP）" class="headerlink" title="k-中心点（AMP）"></a>k-中心点（AMP）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cdist</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Iris数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">features = iris.feature_names</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择用于可视化的两个特征（这里使用花瓣长度和宽度）</span></span><br><span class="line">feature1, feature2 = <span class="number">2</span>, <span class="number">3</span>  <span class="comment"># 可以修改为其他特征组合</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现PAM算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pam_clustering</span>(<span class="params">X, k, max_iter=<span class="number">100</span></span>):</span><br><span class="line">    np.random.seed(<span class="number">42</span>)  <span class="comment"># 设置随机种子，确保每次运行结果一致</span></span><br><span class="line">    n_samples = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机选择k个初始medoid 从样本中随机选出 k 个点作为初始 medoids（聚类中心点，但必须是实际样本）</span></span><br><span class="line">    initial_medoids_idx = np.random.choice(n_samples, k, replace=<span class="literal">False</span>)</span><br><span class="line">    medoids = X[initial_medoids_idx]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个点到medoid的欧氏距离并分配簇</span></span><br><span class="line">    <span class="comment">#计算所有样本到每个 medoid 的欧氏距离（返回 150×k 的矩阵）。</span></span><br><span class="line">	<span class="comment">#为每个样本分配距离最近的 medoid（返回一个长度为150的簇编号数组）。</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">assign_clusters</span>(<span class="params">X, medoids</span>):</span><br><span class="line">        distances = cdist(X, medoids, <span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> np.argmin(distances, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新medoids（选择簇内点距离最小的点）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_medoids</span>(<span class="params">X, clusters, k</span>):</span><br><span class="line">        new_medoids = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            <span class="comment"># 取出属于该簇的所有样本点。</span></span><br><span class="line">            cluster_points = X[clusters == i]</span><br><span class="line">            <span class="keyword">if</span> cluster_points.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment">#计算它们两两之间的距离矩阵。</span></span><br><span class="line">                dist_matrix = cdist(cluster_points, cluster_points, <span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">                <span class="comment">#对于每个点，计算其与其他点的距离总和，找出“最小代价”的那个点作为新的 medoid。</span></span><br><span class="line">                cost = dist_matrix.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">                new_medoids.append(cluster_points[np.argmin(cost)])</span><br><span class="line">        <span class="keyword">return</span> np.array(new_medoids)</span><br><span class="line">	</span><br><span class="line">    <span class="comment">#初始分配簇</span></span><br><span class="line">    clusters = assign_clusters(X, medoids)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        new_medoids = update_medoids(X, clusters, k)</span><br><span class="line">        new_clusters = assign_clusters(X, new_medoids)</span><br><span class="line">        <span class="keyword">if</span> np.array_equal(new_medoids, medoids):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        medoids = new_medoids</span><br><span class="line">        clusters = new_clusters</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> medoids, clusters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行PAM聚类</span></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">medoids, clusters = pam_clustering(X, k)</span><br><span class="line"><span class="comment"># 绘制原始数据分布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始数据图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, feature1], X[:, feature2], c=y, cmap=<span class="string">&#x27;viridis&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度 (cm)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度 (cm)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始鸢尾花数据分布&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制聚类结果</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.scatter(X[:, feature1], X[:, feature2], c=clusters, cmap=<span class="string">&#x27;viridis&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度 (cm)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度 (cm)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;PAM 聚类结果&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标注中心点（medoids）</span></span><br><span class="line">plt.scatter(medoids[:, feature1], medoids[:, feature2], c=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, s=<span class="number">200</span>, label=<span class="string">&#x27;代表对象&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图"><a href="#运行结果图" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/AMP.png" alt=""></p>
<h2 id="动态图-1"><a href="#动态图-1" class="headerlink" title="动态图"></a>动态图</h2><p><img src="images/pam_animation.gif" alt=""></p>
<h1 id="层次聚类算法"><a href="#层次聚类算法" class="headerlink" title="层次聚类算法"></a>层次聚类算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> dendrogram, linkage</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Iris数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 花瓣长度和花瓣宽度</span></span><br><span class="line">feature_names = iris.feature_names[<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成层次聚类的链接矩阵</span></span><br><span class="line">Z = linkage(X, method=<span class="string">&#x27;ward&#x27;</span>, metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化设置</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">8</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;鸢尾花数据集层次聚类树状图&#x27;</span>, fontsize=<span class="number">14</span>, pad=<span class="number">20</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本索引（或簇大小）&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;WARD距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制增强版树状图</span></span><br><span class="line">dendrogram(</span><br><span class="line">    Z,</span><br><span class="line">    truncate_mode=<span class="string">&#x27;lastp&#x27;</span>,  <span class="comment"># 显示最后p个合并的簇</span></span><br><span class="line">    p=<span class="number">12</span>,                   <span class="comment"># 显示最后12次合并</span></span><br><span class="line">    show_leaf_counts=<span class="literal">True</span>,  <span class="comment"># 显示簇包含的样本数</span></span><br><span class="line">    leaf_rotation=<span class="number">90.</span>,      <span class="comment"># 旋转叶子标签</span></span><br><span class="line">    leaf_font_size=<span class="number">8.</span>,      <span class="comment"># 叶子标签字体大小</span></span><br><span class="line">    show_contracted=<span class="literal">True</span>,   <span class="comment"># 显示收缩后的簇大小</span></span><br><span class="line">    color_threshold=<span class="number">2.5</span>     <span class="comment"># 颜色区分阈值</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 获取不同cut高度的聚类结果示例</span></span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> fcluster</span><br><span class="line"><span class="keyword">for</span> cutoff <span class="keyword">in</span> [<span class="number">2.0</span>, <span class="number">3.5</span>, <span class="number">5.0</span>]:</span><br><span class="line">    clusters = fcluster(Z, cutoff, criterion=<span class="string">&#x27;distance&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n在cut高度 <span class="subst">&#123;cutoff&#125;</span> 时，得到 <span class="subst">&#123;<span class="built_in">len</span>(np.unique(clusters))&#125;</span> 个簇&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加距离参考线</span></span><br><span class="line">plt.axhline(y=<span class="number">5</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, linewidth=<span class="number">0.8</span>)</span><br><span class="line">plt.text(<span class="number">5</span>, <span class="number">5</span>, <span class="string">&#x27;推荐分割阈值&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>, fontsize=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示颜色图例</span></span><br><span class="line">plt.gca().collections[-<span class="number">1</span>].set_edgecolor(<span class="string">&#x27;#333333&#x27;</span>)  <span class="comment"># 设置边框颜色</span></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>, alpha=<span class="number">0.6</span>)        <span class="comment"># 添加横向网格线</span></span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-1"><a href="#运行结果图-1" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>在cut高度 2.0 时，得到 6 个簇</p>
<p>在cut高度 3.5 时，得到 5 个簇</p>
<p>在cut高度 5.0 时，得到 3 个簇</p>
<p><img src="images/cwngci.png" alt=""></p>
<h1 id="层次聚类的BIRCH算法"><a href="#层次聚类的BIRCH算法" class="headerlink" title="层次聚类的BIRCH算法"></a>层次聚类的BIRCH算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> Birch</span><br><span class="line"><span class="comment"># 设置中文字体（可选：防止中文乱码）</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]        <span class="comment"># 使用黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>          <span class="comment"># 正常显示负号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载鸢尾花数据集，只选取花瓣长度和宽度</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, <span class="number">2</span>:<span class="number">4</span>]  <span class="comment"># 花瓣长度和宽度</span></span><br><span class="line">y = iris.target        <span class="comment"># 原始标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 BIRCH 算法进行聚类； 最终将数据划分成 3 个簇；控制聚类的紧密程度。较小值会导致更多簇（更精细划分）。</span></span><br><span class="line">birch_model = Birch(n_clusters=<span class="number">3</span>, threshold=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment">#用训练数据 X（特征矩阵）来训练 BIRCH 模型</span></span><br><span class="line"><span class="comment">#BIRCH 会先构造 CF（Clustering Feature）树，然后合并为指定数量的簇。</span></span><br><span class="line">birch_model.fit(X)</span><br><span class="line"><span class="comment">#labels_ 是模型聚类后的结果，是一个长度为 n_samples 的数组。</span></span><br><span class="line">labels = birch_model.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动计算每个最终簇的中心点（均值）</span></span><br><span class="line">final_centers = np.array([X[labels == i].mean(axis=<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建图像和子图</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 左图：原始鸢尾花类别</span></span><br><span class="line">axs[<span class="number">0</span>].scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=<span class="string">&#x27;Set1&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_title(<span class="string">&quot;原始鸢尾花类别&quot;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">axs[<span class="number">0</span>].grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 右图：BIRCH 聚类结果（显示真实3个中心）</span></span><br><span class="line">axs[<span class="number">1</span>].scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, cmap=<span class="string">&#x27;Set1&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].scatter(final_centers[:, <span class="number">0</span>], final_centers[:, <span class="number">1</span>],</span><br><span class="line">               marker=<span class="string">&#x27;*&#x27;</span>, c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;簇中心&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_title(<span class="string">&quot;BIRCH 算法聚类结果&quot;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">axs[<span class="number">1</span>].legend()</span><br><span class="line">axs[<span class="number">1</span>].grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-2"><a href="#运行结果图-2" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/BIRCH.png" alt=""></p>
<h2 id="动态图-2"><a href="#动态图-2" class="headerlink" title="动态图"></a>动态图</h2><p><img src="images/birch_33.gif" alt=""></p>
<h1 id="概率层次聚类算法"><a href="#概率层次聚类算法" class="headerlink" title="概率层次聚类算法"></a>概率层次聚类算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文字体支持</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据（花瓣长度和宽度）与真实标签</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 使用花瓣长度和宽度</span></span><br><span class="line">y = iris.target  <span class="comment"># 标签</span></span><br><span class="line">n_samples = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始每个样本是一个簇</span></span><br><span class="line">clusters = [[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_samples)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 高斯概率函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_prob</span>(<span class="params">cluster</span>):</span><br><span class="line">    data = X[cluster]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data) &lt; <span class="number">2</span>:<span class="comment">#如果这个聚类中的样本数小于2，无法计算协方差矩阵（至少需要两个样本），因此返回一个很小的概率值 1e-10，表示这个聚类的概率非常小</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1e-10</span></span><br><span class="line">    mean = np.mean(data, axis=<span class="number">0</span>)<span class="comment">#计算当前聚类数据的均值向量，用于高斯分布的 mean 参数。</span></span><br><span class="line">    cov = np.cov(data.T)<span class="comment">#计算协方差矩阵，需要对数据转置，使每一列是一个特征。</span></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(cov) &lt;= <span class="number">1e-5</span>:</span><br><span class="line">        cov += np.eye(cov.shape[<span class="number">0</span>]) * <span class="number">1e-3</span></span><br><span class="line">    prob = np.prod(multivariate_normal.pdf(data, mean=mean, cov=cov))<span class="comment">#计算每个样本在该高斯分布下的概率密度值</span></span><br><span class="line">    <span class="keyword">return</span> prob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化每个簇的概率</span></span><br><span class="line">cluster_probs = &#123;i: compute_prob(c) <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 距离函数：基于概率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dist</span>(<span class="params">ci, cj</span>):</span><br><span class="line">    ci_idx = clusters[ci]</span><br><span class="line">    cj_idx = clusters[cj]</span><br><span class="line">    union = ci_idx + cj_idx</span><br><span class="line">    p_i, p_j = cluster_probs[ci], cluster_probs[cj]</span><br><span class="line">    p_union = compute_prob(union)</span><br><span class="line">    <span class="keyword">if</span> p_i * p_j == <span class="number">0</span> <span class="keyword">or</span> p_union == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> np.inf</span><br><span class="line">    <span class="keyword">return</span> -np.log(p_union / (p_i * p_j))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类过程</span></span><br><span class="line">target_n_clusters = <span class="number">3</span><span class="comment">#设定目标聚类数目为 3，最终期望将数据分为 3 个聚类。</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(clusters) &gt; target_n_clusters:<span class="comment">#循环继续执行，直到聚类的数量减少到或小于目标数目</span></span><br><span class="line">    min_dist = np.inf<span class="comment">#初始化最小距离 min_dist 为无穷大</span></span><br><span class="line">    pair = (-<span class="number">1</span>, -<span class="number">1</span>)<span class="comment">#并且初始化 pair 为一个负值元组，表示尚未找到需要合并的两个聚类。</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(clusters)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(clusters)):</span><br><span class="line">            d = dist(i, j)</span><br><span class="line">            <span class="keyword">if</span> d &lt; min_dist:</span><br><span class="line">                min_dist = d</span><br><span class="line">                pair = (i, j)</span><br><span class="line"></span><br><span class="line">    i, j = pair<span class="comment">#从 pair 中提取出两个聚类的索引 i 和 j，这两个聚类将被合并</span></span><br><span class="line">    new_cluster = clusters[i] + clusters[j]</span><br><span class="line">    clusters.append(new_cluster)</span><br><span class="line">    clusters.pop(<span class="built_in">max</span>(i, j))<span class="comment">#删除已经合并的两个旧的聚类。通过 max(i, j) 和 min(i, j) 来确保无论 i 和 j 的顺序如何，都能删除正确的聚类。</span></span><br><span class="line">    clusters.pop(<span class="built_in">min</span>(i, j))</span><br><span class="line">    cluster_probs = &#123;idx: compute_prob(c) <span class="keyword">for</span> idx, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters)&#125;<span class="comment">#对每一个新的聚类 c，通过调用 compute_prob(c) 计算该聚类的概率值（由之前提到的高斯概率函数得到的联合概率密度）。使用字典推导式生成一个字典 cluster_probs，键是聚类的索引，值是每个聚类的概率密度。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ========== 图像展示 ==========</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;y&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 左图：原始数据（真实类别）</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    plt.scatter(X[y == i, <span class="number">0</span>], X[y == i, <span class="number">1</span>], color=colors[i], label=<span class="string">f&quot;类别 <span class="subst">&#123;i&#125;</span>&quot;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;原始数据（按真实类别）&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 右图：聚类结果（每个簇不同颜色）</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> idx, cluster <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters):</span><br><span class="line">    cluster_points = X[cluster]</span><br><span class="line">    plt.scatter(cluster_points[:, <span class="number">0</span>], cluster_points[:, <span class="number">1</span>],</span><br><span class="line">                color=colors[idx % <span class="built_in">len</span>(colors)], edgecolor=<span class="string">&#x27;k&#x27;</span>, label=<span class="string">f&quot;簇 <span class="subst">&#123;idx + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;概率层次聚类结果&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-3"><a href="#运行结果图-3" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/cengcigailv.png" alt=""></p>
<h1 id="密度DBSCAN算法"><a href="#密度DBSCAN算法" class="headerlink" title="密度DBSCAN算法"></a>密度DBSCAN算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Iris数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 使用花瓣长度和宽度</span></span><br><span class="line">feature_names = iris.feature_names[<span class="number">2</span>:]</span><br><span class="line">true_labels = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数优化函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_optimal_eps</span>(<span class="params">X, k=<span class="number">5</span></span>):</span><br><span class="line">    <span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line">    neighbors = NearestNeighbors(n_neighbors=k) <span class="comment"># 构造近邻模型</span></span><br><span class="line">    neighbors.fit(X)</span><br><span class="line">    distances, _ = neighbors.kneighbors(X)<span class="comment"># 计算每个点到第k近邻的距离</span></span><br><span class="line">    <span class="keyword">return</span> np.sort(distances[:, -<span class="number">1</span>])<span class="comment"># 提取每行的第k个距离，排序后返回</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动计算推荐参数</span></span><br><span class="line">distances = find_optimal_eps(X, k=<span class="number">5</span>)<span class="comment"># 找到每个点的第5近邻距离</span></span><br><span class="line">recommended_eps = distances[<span class="built_in">round</span>(<span class="built_in">len</span>(distances)*<span class="number">0.95</span>)]  <span class="comment"># 取95%位置的值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DBSCAN模型</span></span><br><span class="line">dbscan = DBSCAN(</span><br><span class="line">    eps=recommended_eps,   <span class="comment">#  # 半径阈值：邻域范围 自动计算的eps值</span></span><br><span class="line">    min_samples=<span class="number">4</span>,         <span class="comment"># 最少样本数，包含自身 根据数据量调整</span></span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>	   <span class="comment"># 使用欧氏距离</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行聚类</span></span><br><span class="line">clusters = dbscan.fit_predict(X)<span class="comment"># 拟合模型并返回聚类标签（-1为噪声）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建可视化对比</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义颜色映射（突出噪声点）</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图1：真实类别分布</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sc1 = plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">                edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;真实类别分布\n(Iris Species)&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图2：DBSCAN聚类结果</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分核心点和噪声点</span></span><br><span class="line">core_samples_mask = np.zeros_like(clusters, dtype=<span class="built_in">bool</span>)</span><br><span class="line">core_samples_mask[dbscan.core_sample_indices_] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制不同类别的点</span></span><br><span class="line"><span class="keyword">for</span> klass <span class="keyword">in</span> np.unique(clusters):</span><br><span class="line">    <span class="keyword">if</span> klass == -<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 噪声点</span></span><br><span class="line">        plt.scatter(X[clusters == klass, <span class="number">0</span>], X[clusters == klass, <span class="number">1</span>],</span><br><span class="line">                    c=<span class="string">&#x27;#999999&#x27;</span>, s=<span class="number">100</span>, marker=<span class="string">&#x27;x&#x27;</span>, alpha=<span class="number">0.8</span>,</span><br><span class="line">                    linewidth=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 核心点</span></span><br><span class="line">        plt.scatter(X[(clusters == klass) &amp; core_samples_mask, <span class="number">0</span>],</span><br><span class="line">                    X[(clusters == klass) &amp; core_samples_mask, <span class="number">1</span>],</span><br><span class="line">                    c=[cmap(klass+<span class="number">1</span>)], s=<span class="number">80</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">                    linewidth=<span class="number">0.5</span>, label=<span class="string">f&#x27;簇<span class="subst">&#123;klass&#125;</span>核心点&#x27;</span>)</span><br><span class="line">        <span class="comment"># 边界点</span></span><br><span class="line">        plt.scatter(X[(clusters == klass) &amp; ~core_samples_mask, <span class="number">0</span>],</span><br><span class="line">                    X[(clusters == klass) &amp; ~core_samples_mask, <span class="number">1</span>],</span><br><span class="line">                    c=[cmap(klass+<span class="number">1</span>)], s=<span class="number">50</span>, marker=<span class="string">&#x27;^&#x27;</span>,</span><br><span class="line">                    edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.6</span>, label=<span class="string">f&#x27;簇<span class="subst">&#123;klass&#125;</span>边界点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">f&#x27;DBSCAN聚类结果\n(eps=<span class="subst">&#123;recommended_eps:<span class="number">.2</span>f&#125;</span>, min_samples=4)&#x27;</span>,</span><br><span class="line">         fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, fontsize=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估指标</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;发现簇数量: <span class="subst">&#123;<span class="built_in">len</span>(np.unique(clusters)) - <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点数量: <span class="subst">&#123;np.<span class="built_in">sum</span>(clusters == -<span class="number">1</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-4"><a href="#运行结果图-4" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/DBSCN-17482501533272.png" alt=""></p>
<p>轮廓系数: 0.767<br>ARI指数: 0.568<br>发现簇数量: 2<br>噪声点数量: 0</p>
<h2 id="随机数据集"><a href="#随机数据集" class="headerlink" title="随机数据集"></a>随机数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文显示</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成模拟数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X, _ = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用 DBSCAN</span></span><br><span class="line">dbscan = DBSCAN(eps=<span class="number">0.5</span>, min_samples=<span class="number">5</span>)</span><br><span class="line">clusters = dbscan.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 唯一标签集合（包括噪声点 -1）</span></span><br><span class="line">unique_labels = <span class="built_in">set</span>(clusters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 tab10 色系（鲜明、对比强）</span></span><br><span class="line">colors = plt.cm.tab10(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">len</span>(unique_labels)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(unique_labels, colors):</span><br><span class="line">    <span class="keyword">if</span> k == -<span class="number">1</span>:</span><br><span class="line">        col = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]  <span class="comment"># 红色表示噪声点</span></span><br><span class="line">        label_name = <span class="string">&#x27;噪声点&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        label_name = <span class="string">f&#x27;簇 <span class="subst">&#123;k&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line">    class_member_mask = (clusters == k)</span><br><span class="line">    xy = X[class_member_mask]</span><br><span class="line">    plt.plot(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">             markerfacecolor=<span class="built_in">tuple</span>(col),</span><br><span class="line">             markeredgecolor=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">             markersize=<span class="number">6</span>,</span><br><span class="line">             label=label_name)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;DBSCAN 聚类结果&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;特征 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;特征 2&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-5"><a href="#运行结果图-5" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/suijiDBSCAN.png" alt=""></p>
<h1 id="密度OPTICS算法"><a href="#密度OPTICS算法" class="headerlink" title="密度OPTICS算法"></a>密度OPTICS算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> OPTICS</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示配置</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载并准备数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 花瓣长度和宽度</span></span><br><span class="line">feature_names = [n.replace(<span class="string">&#x27; (cm)&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="keyword">for</span> n <span class="keyword">in</span> iris.feature_names[<span class="number">2</span>:]]</span><br><span class="line">true_labels = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建OPTICS模型</span></span><br><span class="line">optics_model = OPTICS(</span><br><span class="line">    min_samples=<span class="number">4</span>,<span class="comment">#定义一个点成为核心点所需的最小邻域样本数</span></span><br><span class="line">    xi=<span class="number">0.05</span>,<span class="comment">#控制簇边界识别的灵敏度，通过可达距离图中的“波谷”深度判定簇</span></span><br><span class="line">    min_cluster_size=<span class="number">0.15</span>,<span class="comment">#定义最小簇规模，低于此规模的簇将被视为噪声</span></span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>,<span class="comment">#定义计算样本间距离的度量方法</span></span><br><span class="line">    cluster_method=<span class="string">&#x27;xi&#x27;</span><span class="comment">#指定从可达距离图中提取簇的方法</span></span><br><span class="line">).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换原来的 OPTICS 配置</span></span><br><span class="line"><span class="comment"># optics_model = OPTICS(</span></span><br><span class="line"><span class="comment">#     min_samples=5,</span></span><br><span class="line"><span class="comment">#     xi=0.03,</span></span><br><span class="line"><span class="comment">#     min_cluster_size=0.1,</span></span><br><span class="line"><span class="comment">#     metric=&#x27;euclidean&#x27;,</span></span><br><span class="line"><span class="comment">#     cluster_method=&#x27;xi&#x27;</span></span><br><span class="line"><span class="comment"># ).fit(X)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色配置</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>])</span><br><span class="line">cluster_labels = np.where(optics_model.labels_ == -<span class="number">1</span>, <span class="number">0</span>, optics_model.labels_+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第一大图：分析视图（1行3列）</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图1：原始数据分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据分布&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图2：可达距离排序图 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">space = np.arange(<span class="built_in">len</span>(X))</span><br><span class="line">reachability = optics_model.reachability_[optics_model.ordering_]</span><br><span class="line">labels = optics_model.labels_[optics_model.ordering_]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建颜色映射（排除噪声点）</span></span><br><span class="line">colors = [cmap(l+<span class="number">1</span>) <span class="keyword">if</span> l != -<span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;#999999&#x27;</span> <span class="keyword">for</span> l <span class="keyword">in</span> labels]</span><br><span class="line"></span><br><span class="line">plt.bar(space, reachability, color=colors, width=<span class="number">0.8</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.plot(reachability, color=<span class="string">&#x27;#2c3e50&#x27;</span>, linewidth=<span class="number">1.2</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;可达距离排序图&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本排序序号&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylim(top=np.percentile(reachability, <span class="number">95</span>)*<span class="number">1.1</span>)  <span class="comment"># 自动调整Y轴上限</span></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图3：聚类结果分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">noise_mask = (optics_model.labels_ == -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[~noise_mask, <span class="number">0</span>], X[~noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=cluster_labels[~noise_mask], cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;#999999&#x27;</span>, marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">100</span>, linewidths=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;OPTICS聚类结果&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第二大图：三维可视化</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三维散点图</span></span><br><span class="line">sc = ax.scatter3D(</span><br><span class="line">    X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], optics_model.reachability_,</span><br><span class="line">    c=cluster_labels, cmap=cmap,</span><br><span class="line">    s=<span class="number">50</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.8</span>, depthshade=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 坐标轴设置</span></span><br><span class="line">ax.set_xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;三维特征空间可视化&#x27;</span>, fontsize=<span class="number">16</span>, pad=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色条设置</span></span><br><span class="line">cbar = plt.colorbar(sc, pad=<span class="number">0.1</span>)</span><br><span class="line">cbar.set_ticks([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">cbar.set_ticklabels([<span class="string">&#x27;噪声&#x27;</span>, <span class="string">&#x27;簇 1&#x27;</span>, <span class="string">&#x27;簇 2&#x27;</span>, <span class="string">&#x27;簇 3&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 视角设置</span></span><br><span class="line">ax.view_init(elev=<span class="number">25</span>, azim=-<span class="number">45</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 性能评估 ==================</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n【性能评估】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数（越接近 1，聚类效果越好（点紧密集中在各自簇内，簇之间分得开））: <span class="subst">&#123;silhouette_score(X, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数（聚类结果与真实标签完全匹配，1 表示完全一致（）: <span class="subst">&#123;adjusted_rand_score(true_labels, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;检测到簇数量: <span class="subst">&#123;<span class="built_in">len</span>(np.unique(optics_model.labels_))-<span class="number">1</span>&#125;</span>个&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点比例: <span class="subst">&#123;np.mean(optics_model.labels_ == -<span class="number">1</span>):<span class="number">.1</span>%&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-6"><a href="#运行结果图-6" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>【性能评估】<br>轮廓系数（越接近 1，聚类效果越好（点紧密集中在各自簇内，簇之间分得开））: 0.576<br>ARI指数（聚类结果与真实标签完全匹配，1 表示完全一致（）: 0.643<br>检测到簇数量: 2个<br>噪声点比例: 27.3%</p>
<p><img src="images/OPTICS.png" alt=""></p>
<p><img src="images/OPTICS_2.png" alt=""></p>
<h2 id="随机数据集-1"><a href="#随机数据集-1" class="headerlink" title="随机数据集"></a>随机数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> OPTICS</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示配置</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成模拟数据（4个簇，2维）</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X, true_labels = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line">feature_names = [<span class="string">&#x27;特征 1&#x27;</span>, <span class="string">&#x27;特征 2&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建OPTICS模型</span></span><br><span class="line">optics_model = OPTICS(</span><br><span class="line">    min_samples=<span class="number">5</span>,</span><br><span class="line">    xi=<span class="number">0.08</span>,</span><br><span class="line">    min_cluster_size=<span class="number">0.1</span>,</span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>,</span><br><span class="line">    cluster_method=<span class="string">&#x27;xi&#x27;</span></span><br><span class="line">).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色配置（第一个为灰色，用于噪声）</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>, <span class="string">&#x27;#FFD700&#x27;</span>])</span><br><span class="line">cluster_labels = np.where(optics_model.labels_ == -<span class="number">1</span>, <span class="number">0</span>, optics_model.labels_ + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第一大图：分析视图（1行3列）</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图1：原始数据分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据分布（真实标签）&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图2：可达距离排序图 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">space = np.arange(<span class="built_in">len</span>(X))</span><br><span class="line">reachability = optics_model.reachability_[optics_model.ordering_]</span><br><span class="line">labels = optics_model.labels_[optics_model.ordering_]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建颜色映射（包括噪声）</span></span><br><span class="line">colors = [cmap(l + <span class="number">1</span>) <span class="keyword">if</span> l != -<span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;#999999&#x27;</span> <span class="keyword">for</span> l <span class="keyword">in</span> labels]</span><br><span class="line"></span><br><span class="line">plt.bar(space, reachability, color=colors, width=<span class="number">0.8</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.plot(reachability, color=<span class="string">&#x27;#2c3e50&#x27;</span>, linewidth=<span class="number">1.2</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;可达距离排序图&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本排序序号&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylim(top=np.percentile(reachability, <span class="number">95</span>) * <span class="number">1.1</span>)</span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图3：聚类结果分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">noise_mask = (optics_model.labels_ == -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[~noise_mask, <span class="number">0</span>], X[~noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=cluster_labels[~noise_mask], cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;#999999&#x27;</span>, marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">100</span>, linewidths=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;OPTICS聚类结果&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第二大图：三维可视化</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">sc = ax.scatter3D(</span><br><span class="line">    X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], optics_model.reachability_,</span><br><span class="line">    c=cluster_labels, cmap=cmap,</span><br><span class="line">    s=<span class="number">50</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.8</span>, depthshade=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;三维特征空间可视化&#x27;</span>, fontsize=<span class="number">16</span>, pad=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色条设置</span></span><br><span class="line">num_clusters = <span class="built_in">len</span>(<span class="built_in">set</span>(optics_model.labels_)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> optics_model.labels_ <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">cbar = plt.colorbar(sc, pad=<span class="number">0.1</span>)</span><br><span class="line">cbar.set_ticks(np.arange(<span class="number">0</span>, num_clusters + <span class="number">1</span>))</span><br><span class="line">cbar.set_ticklabels([<span class="string">&#x27;噪声&#x27;</span>] + [<span class="string">f&#x27;簇 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_clusters)])</span><br><span class="line"></span><br><span class="line">ax.view_init(elev=<span class="number">25</span>, azim=-<span class="number">45</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 性能评估 ==================</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n【性能评估】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;检测到簇数量: <span class="subst">&#123;num_clusters&#125;</span> 个&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点比例: <span class="subst">&#123;np.mean(optics_model.labels_ == -<span class="number">1</span>):<span class="number">.1</span>%&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-7"><a href="#运行结果图-7" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>【性能评估】<br>轮廓系数: 0.460<br>ARI指数: 0.731<br>检测到簇数量: 4 个<br>噪声点比例: 20.0%</p>
<p><img src="images/suijiOPTICS.png" alt=""></p>
<p><img src="images/suijiOPTICS_2.png" alt=""></p>
<h2 id="最符合的随机数据"><a href="#最符合的随机数据" class="headerlink" title="最符合的随机数据"></a>最符合的随机数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> OPTICS</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示配置</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 生成更优的模拟数据 ==================</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X, true_labels = make_blobs(</span><br><span class="line">    n_samples=<span class="number">300</span>,</span><br><span class="line">    centers=<span class="number">4</span>,</span><br><span class="line">    cluster_std=<span class="number">0.45</span>,          <span class="comment"># 降低标准差</span></span><br><span class="line">    center_box=(-<span class="number">15</span>, <span class="number">15</span>),      <span class="comment"># 扩大中心范围</span></span><br><span class="line">    random_state=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line">feature_names = [<span class="string">&#x27;特征 1&#x27;</span>, <span class="string">&#x27;特征 2&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 优化后的OPTICS模型 ==================</span></span><br><span class="line">optics_model = OPTICS(</span><br><span class="line">    min_samples=<span class="number">10</span>,            <span class="comment"># 增加核心点判定样本量</span></span><br><span class="line">    xi=<span class="number">0.1</span>,                    <span class="comment"># 调整簇边界阈值</span></span><br><span class="line">    min_cluster_size=<span class="number">20</span>,       <span class="comment"># 绝对数值定义最小簇</span></span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>,</span><br><span class="line">    cluster_method=<span class="string">&#x27;xi&#x27;</span>        <span class="comment"># 保持xi聚类方法</span></span><br><span class="line">).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色配置（第一个为灰色，用于噪声）</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>, <span class="string">&#x27;#FFD700&#x27;</span>])</span><br><span class="line">cluster_labels = np.where(optics_model.labels_ == -<span class="number">1</span>, <span class="number">0</span>, optics_model.labels_ + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第一大图：分析视图（1行3列）</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图1：原始数据分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;优化后的数据分布（真实标签）&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图2：可达距离排序图 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">space = np.arange(<span class="built_in">len</span>(X))</span><br><span class="line">reachability = optics_model.reachability_[optics_model.ordering_]</span><br><span class="line">labels = optics_model.labels_[optics_model.ordering_]</span><br><span class="line"></span><br><span class="line">colors = [cmap(l + <span class="number">1</span>) <span class="keyword">if</span> l != -<span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;#999999&#x27;</span> <span class="keyword">for</span> l <span class="keyword">in</span> labels]</span><br><span class="line">plt.bar(space, reachability, color=colors, width=<span class="number">0.8</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.plot(reachability, color=<span class="string">&#x27;#2c3e50&#x27;</span>, linewidth=<span class="number">1.2</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;可达距离排序图（优化后）&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本排序序号&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylim(top=np.percentile(reachability, <span class="number">95</span>) * <span class="number">1.1</span>)</span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图3：聚类结果分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">noise_mask = (optics_model.labels_ == -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[~noise_mask, <span class="number">0</span>], X[~noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=cluster_labels[~noise_mask], cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;#999999&#x27;</span>, marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">100</span>, linewidths=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;优化后的OPTICS聚类&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第二大图：三维可视化</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">sc = ax.scatter3D(</span><br><span class="line">    X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], optics_model.reachability_,</span><br><span class="line">    c=cluster_labels, cmap=cmap,</span><br><span class="line">    s=<span class="number">50</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.8</span>, depthshade=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;三维特征空间可视化（优化后）&#x27;</span>, fontsize=<span class="number">16</span>, pad=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色条设置</span></span><br><span class="line">num_clusters = <span class="built_in">len</span>(<span class="built_in">set</span>(optics_model.labels_)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> optics_model.labels_ <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">cbar = plt.colorbar(sc, pad=<span class="number">0.1</span>)</span><br><span class="line">cbar.set_ticks(np.arange(<span class="number">0</span>, num_clusters + <span class="number">1</span>))</span><br><span class="line">cbar.set_ticklabels([<span class="string">&#x27;噪声&#x27;</span>] + [<span class="string">f&#x27;簇 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_clusters)])</span><br><span class="line"></span><br><span class="line">ax.view_init(elev=<span class="number">25</span>, azim=-<span class="number">45</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 性能评估（排除噪声）==================</span></span><br><span class="line">valid_labels = optics_model.labels_ != -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n【优化后性能评估】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X[valid_labels], optics_model.labels_[valid_labels]):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;检测到簇数量: <span class="subst">&#123;num_clusters&#125;</span> 个&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点比例: <span class="subst">&#123;np.mean(optics_model.labels_ == -<span class="number">1</span>):<span class="number">.1</span>%&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-8"><a href="#运行结果图-8" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>【优化后性能评估】<br>轮廓系数: 0.841<br>ARI指数: 1.000<br>检测到簇数量: 4 个<br>噪声点比例: 0.0%</p>
<p><img src="images/suijiOP.png" alt=""></p>
<p><img src="images/suijiOP_2.png" alt=""></p>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/" rel="tag"># 第十章：聚类分析</a>
              <a href="/tags/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" rel="tag"># 大作业</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2025/04/11/%E8%93%9D%E6%A1%A5%E6%9D%AF/" rel="prev" title="蓝桥杯">
                  <i class="fa fa-angle-left"></i> 蓝桥杯
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2025/04/20/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" rel="next" title="数据挖掘">
                  数据挖掘 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">LiuJun</span>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
