<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"liujunblog.github.io","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.19.2","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Blog">
<meta property="og:url" content="https://liujunblog.github.io/index.html">
<meta property="og:site_name" content="Blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="LiuJun">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://liujunblog.github.io/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="LiuJun"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">LiuJun</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">10</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2025/04/20/%E5%A4%A7%E4%BD%9C%E4%B8%9A/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/20/%E5%A4%A7%E4%BD%9C%E4%B8%9A/" class="post-title-link" itemprop="url">大作业</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-20 16:18:32" itemprop="dateCreated datePublished" datetime="2025-04-20T16:18:32+08:00">2025-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-26 19:01:40" itemprop="dateModified" datetime="2025-05-26T19:01:40+08:00">2025-05-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> defaultdict</span><br><span class="line"><span class="keyword">from</span> itertools <span class="keyword">import</span> combinations</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AprioriAnalyzer</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, csv_path, min_support=<span class="number">3</span></span>):</span><br><span class="line">        <span class="variable language_">self</span>.csv_path = csv_path</span><br><span class="line">        <span class="variable language_">self</span>.min_support = min_support</span><br><span class="line">        <span class="variable language_">self</span>.transactions = []</span><br><span class="line">        <span class="variable language_">self</span>.item_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="variable language_">self</span>.frequent_itemsets = &#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_load_data</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;加载CSV数据并构建事务列表&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(<span class="variable language_">self</span>.csv_path):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;找不到文件 <span class="subst">&#123;self.csv_path&#125;</span>，请确认样本文件存在！&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(<span class="variable language_">self</span>.csv_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            reader = csv.reader(f)</span><br><span class="line">            <span class="built_in">next</span>(reader)  <span class="comment"># 跳过标题行</span></span><br><span class="line">            <span class="keyword">for</span> row <span class="keyword">in</span> reader:</span><br><span class="line">                <span class="keyword">if</span> row <span class="keyword">and</span> row[<span class="number">0</span>]:</span><br><span class="line">                    itemset = <span class="built_in">frozenset</span>(row[<span class="number">0</span>].split(<span class="string">&#x27;;&#x27;</span>))</span><br><span class="line">                    <span class="keyword">if</span> itemset:</span><br><span class="line">                        <span class="variable language_">self</span>.transactions.append(itemset)</span><br><span class="line">                        <span class="keyword">for</span> item <span class="keyword">in</span> itemset:</span><br><span class="line">                            <span class="variable language_">self</span>.item_counts[item] += <span class="number">1</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;已加载 <span class="subst">&#123;<span class="built_in">len</span>(self.transactions)&#125;</span> 条事务&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_generate_candidates</span>(<span class="params">self, prev_items, k</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;生成k项候选集&quot;&quot;&quot;</span></span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">            a.union(b)</span><br><span class="line">            <span class="keyword">for</span> a <span class="keyword">in</span> prev_items</span><br><span class="line">            <span class="keyword">for</span> b <span class="keyword">in</span> prev_items</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(a.union(b)) == k <span class="keyword">and</span></span><br><span class="line">               <span class="built_in">all</span>(<span class="built_in">frozenset</span>(c) <span class="keyword">in</span> prev_items <span class="keyword">for</span> c <span class="keyword">in</span> combinations(a.union(b), k - <span class="number">1</span>))</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">run</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;执行Apriori算法&quot;&quot;&quot;</span></span><br><span class="line">        <span class="variable language_">self</span>._load_data()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> <span class="variable language_">self</span>.transactions:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;没有事务数据，无法执行Apriori&quot;</span>)</span><br><span class="line">            <span class="keyword">return</span> &#123;&#125;</span><br><span class="line"></span><br><span class="line">        L = &#123;<span class="built_in">frozenset</span>([item]): cnt</span><br><span class="line">             <span class="keyword">for</span> item, cnt <span class="keyword">in</span> <span class="variable language_">self</span>.item_counts.items()</span><br><span class="line">             <span class="keyword">if</span> cnt &gt;= <span class="variable language_">self</span>.min_support&#125;</span><br><span class="line">        <span class="variable language_">self</span>.frequent_itemsets.update(L)</span><br><span class="line">        k = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            k += <span class="number">1</span></span><br><span class="line">            candidates = <span class="variable language_">self</span>._generate_candidates(L.keys(), k)</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> candidates:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">            <span class="keyword">for</span> transaction <span class="keyword">in</span> <span class="variable language_">self</span>.transactions:</span><br><span class="line">                <span class="keyword">for</span> candidate <span class="keyword">in</span> candidates:</span><br><span class="line">                    <span class="keyword">if</span> candidate.issubset(transaction):</span><br><span class="line">                        counts[candidate] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">            Lk = &#123;itemset: cnt <span class="keyword">for</span> itemset, cnt <span class="keyword">in</span> counts.items() <span class="keyword">if</span> cnt &gt;= <span class="variable language_">self</span>.min_support&#125;</span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> Lk:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">            <span class="variable language_">self</span>.frequent_itemsets.update(Lk)</span><br><span class="line">            L = Lk</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;发现 <span class="subst">&#123;<span class="built_in">len</span>(Lk)&#125;</span> 个 <span class="subst">&#123;k&#125;</span>-项频繁项集&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.frequent_itemsets</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">show_results</span>(<span class="params">self, top_n=<span class="number">20</span></span>):</span><br><span class="line">        <span class="string">&quot;&quot;&quot;展示挖掘结果，并统计各项集大小数量&quot;&quot;&quot;</span></span><br><span class="line">        sorted_items = <span class="built_in">sorted</span>(</span><br><span class="line">            <span class="variable language_">self</span>.frequent_itemsets.items(),</span><br><span class="line">            key=<span class="keyword">lambda</span> x: (-<span class="built_in">len</span>(x[<span class="number">0</span>]), -x[<span class="number">1</span>], <span class="built_in">sorted</span>(x[<span class="number">0</span>]))</span><br><span class="line">        )[:top_n]</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n频繁项集挖掘结果：&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;项集大小 | 支持度 | 作者组合&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;-&quot;</span> * <span class="number">50</span>)</span><br><span class="line">        <span class="keyword">for</span> itemset, support <span class="keyword">in</span> sorted_items:</span><br><span class="line">            authors = <span class="string">&quot;, &quot;</span>.join(<span class="built_in">sorted</span>(itemset))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="built_in">len</span>(itemset):&gt;<span class="number">6</span>&#125;</span> | <span class="subst">&#123;support:&gt;<span class="number">6</span>&#125;</span> | <span class="subst">&#123;authors&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 补充统计</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n====== 统计信息 ======&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;事务总数（数据集条数）：<span class="subst">&#123;<span class="built_in">len</span>(self.transactions)&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;频繁项集总数：<span class="subst">&#123;<span class="built_in">len</span>(self.frequent_itemsets)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 新增：统计每个项集大小的数量</span></span><br><span class="line">        size_counts = defaultdict(<span class="built_in">int</span>)</span><br><span class="line">        <span class="keyword">for</span> itemset <span class="keyword">in</span> <span class="variable language_">self</span>.frequent_itemsets.keys():</span><br><span class="line">            size_counts[<span class="built_in">len</span>(itemset)] += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n各大小频繁项集数量：&quot;</span>)</span><br><span class="line">        <span class="keyword">for</span> size <span class="keyword">in</span> <span class="built_in">sorted</span>(size_counts.keys()):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;size&#125;</span>-项集数量：<span class="subst">&#123;size_counts[size]&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;======================&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    csv_file = <span class="string">&#x27;sample_10000.csv&#x27;</span></span><br><span class="line">    analyzer = AprioriAnalyzer(csv_file, min_support=<span class="number">3</span>)</span><br><span class="line">    analyzer.run()</span><br><span class="line">    analyzer.show_results()</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> lxml <span class="keyword">import</span> etree</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess</span>(<span class="params">xml_path</span>):</span><br><span class="line">    clean_path = xml_path.replace(<span class="string">&#x27;.xml&#x27;</span>, <span class="string">&#x27;_clean.xml&#x27;</span>)</span><br><span class="line">    csv_path = xml_path.replace(<span class="string">&#x27;.xml&#x27;</span>, <span class="string">&#x27;_clean.csv&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;正在处理：<span class="subst">&#123;xml_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    illegal_patterns = [</span><br><span class="line">        (<span class="string">r&#x27;&amp;(?!amp;|lt;|gt;|apos;|quot;)\w+;&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">        (<span class="string">r&#x27;[\x00-\x08\x0b\x0c\x0e-\x1F\x7F]&#x27;</span>, <span class="string">&#x27;&#x27;</span>),</span><br><span class="line">        (<span class="string">r&#x27;&lt;!--.*?--&gt;&#x27;</span>, <span class="string">&#x27;&#x27;</span>)</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(xml_path, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>, errors=<span class="string">&#x27;replace&#x27;</span>) <span class="keyword">as</span> f_in, \</span><br><span class="line">            <span class="built_in">open</span>(clean_path, <span class="string">&#x27;w&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f_out, \</span><br><span class="line">            <span class="built_in">open</span>(csv_path, <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f_csv:</span><br><span class="line"></span><br><span class="line">        csv_writer = csv.writer(f_csv)</span><br><span class="line">        csv_writer.writerow([<span class="string">&#x27;Authors&#x27;</span>])</span><br><span class="line"></span><br><span class="line">        authors_buffer = []</span><br><span class="line">        in_paper = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i, line <span class="keyword">in</span> <span class="built_in">enumerate</span>(f_in):</span><br><span class="line">            <span class="keyword">for</span> pattern, repl <span class="keyword">in</span> illegal_patterns:</span><br><span class="line">                line = re.sub(pattern, repl, line)</span><br><span class="line">            f_out.write(line)</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">any</span>(tag <span class="keyword">in</span> line <span class="keyword">for</span> tag <span class="keyword">in</span> (<span class="string">&#x27;&lt;article&#x27;</span>, <span class="string">&#x27;&lt;inproceedings&#x27;</span>, <span class="string">&#x27;&lt;proceedings&#x27;</span>, <span class="string">&#x27;&lt;incollection&#x27;</span>)):</span><br><span class="line">                in_paper = <span class="literal">True</span></span><br><span class="line">                authors_buffer = []</span><br><span class="line">            <span class="keyword">elif</span> <span class="built_in">any</span>(tag <span class="keyword">in</span> line <span class="keyword">for</span> tag <span class="keyword">in</span> (<span class="string">&#x27;&lt;/article&gt;&#x27;</span>, <span class="string">&#x27;&lt;/inproceedings&gt;&#x27;</span>, <span class="string">&#x27;&lt;/proceedings&gt;&#x27;</span>, <span class="string">&#x27;&lt;/incollection&gt;&#x27;</span>)):</span><br><span class="line">                <span class="keyword">if</span> authors_buffer:</span><br><span class="line">                    csv_writer.writerow([<span class="string">&#x27;;&#x27;</span>.join(authors_buffer)])</span><br><span class="line">                in_paper = <span class="literal">False</span></span><br><span class="line">            <span class="keyword">elif</span> in_paper <span class="keyword">and</span> <span class="string">&#x27;&lt;author&gt;&#x27;</span> <span class="keyword">in</span> line:</span><br><span class="line">                <span class="keyword">match</span> = re.search(<span class="string">r&#x27;&lt;author&gt;(.*?)&lt;/author&gt;&#x27;</span>, line)</span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">match</span>:</span><br><span class="line">                    authors_buffer.append(<span class="keyword">match</span>.group(<span class="number">1</span>).strip())</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">100000</span> == <span class="number">0</span> <span class="keyword">and</span> i &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">f&quot;处理到第 <span class="subst">&#123;i&#125;</span> 行...&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n清洗完成！&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;清洗后的XML保存为：<span class="subst">&#123;clean_path&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;作者数据CSV保存为：<span class="subst">&#123;csv_path&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    xml_file = <span class="string">&#x27;dblp.xml&#x27;</span>  <span class="comment">#  直接写死，不需要输入参数</span></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(xml_file):</span><br><span class="line">        preprocess(xml_file)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;文件 <span class="subst">&#123;xml_file&#125;</span> 不存在，请检查！&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> csv</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">sample_data</span>(<span class="params">input_csv, output_csv, output_xml, sample_size=<span class="number">10000</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从清洗好的CSV中随机抽取样本并保存为CSV和符合DBLP格式的XML&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> os.path.exists(input_csv):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;找不到文件 <span class="subst">&#123;input_csv&#125;</span>，请确认清洗后的文件存在！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(input_csv, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f_in:</span><br><span class="line">        reader = <span class="built_in">list</span>(csv.reader(f_in))</span><br><span class="line">        header = reader[<span class="number">0</span>]</span><br><span class="line">        data = reader[<span class="number">1</span>:]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data) &lt;= sample_size:</span><br><span class="line">        sample = data</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;记录数不足 <span class="subst">&#123;sample_size&#125;</span>，将使用全部 <span class="subst">&#123;<span class="built_in">len</span>(data)&#125;</span> 条记录&quot;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        sample = random.sample(data, sample_size)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;已随机抽取 <span class="subst">&#123;sample_size&#125;</span> 条记录&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存成 CSV</span></span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(output_csv, <span class="string">&#x27;w&#x27;</span>, newline=<span class="string">&#x27;&#x27;</span>, encoding=<span class="string">&#x27;utf-8&#x27;</span>) <span class="keyword">as</span> f_out:</span><br><span class="line">        writer = csv.writer(f_out)</span><br><span class="line">        writer.writerow(header)</span><br><span class="line">        writer.writerows(sample)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;抽样数据保存为CSV文件：<span class="subst">&#123;output_csv&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 保存成符合 dblp 样式的 XML</span></span><br><span class="line">    dblp_root = ET.Element(<span class="string">&#x27;dblp&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> row <span class="keyword">in</span> sample:</span><br><span class="line">        authors_str = row[<span class="number">0</span>]  <span class="comment"># 只有一列 &quot;Authors&quot;</span></span><br><span class="line">        authors = authors_str.split(<span class="string">&#x27;;&#x27;</span>) <span class="keyword">if</span> authors_str <span class="keyword">else</span> []</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每条记录生成一个 article 节点</span></span><br><span class="line">        article = ET.SubElement(dblp_root, <span class="string">&#x27;article&#x27;</span>)</span><br><span class="line">        <span class="keyword">for</span> author_name <span class="keyword">in</span> authors:</span><br><span class="line">            author_name = author_name.strip()</span><br><span class="line">            <span class="keyword">if</span> author_name:</span><br><span class="line">                author_elem = ET.SubElement(article, <span class="string">&#x27;author&#x27;</span>)</span><br><span class="line">                author_elem.text = author_name</span><br><span class="line"></span><br><span class="line">    tree = ET.ElementTree(dblp_root)</span><br><span class="line">    tree.write(output_xml, encoding=<span class="string">&#x27;utf-8&#x27;</span>, xml_declaration=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;抽样数据保存为符合DBLP格式的XML文件：<span class="subst">&#123;output_xml&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    input_file = <span class="string">&#x27;dblp_clean.csv&#x27;</span></span><br><span class="line">    output_csv = <span class="string">&#x27;sample_10000.csv&#x27;</span></span><br><span class="line">    output_xml = <span class="string">&#x27;sample_10000.xml&#x27;</span></span><br><span class="line">    sample_data(input_file, output_csv, output_xml)</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2025/04/20/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/20/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" class="post-title-link" itemprop="url">数据挖掘</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-20 16:18:32" itemprop="dateCreated datePublished" datetime="2025-04-20T16:18:32+08:00">2025-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-26 18:56:04" itemprop="dateModified" datetime="2025-05-26T18:56:04+08:00">2025-05-26</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/20/%E7%AC%AC%E5%8D%81%E7%AB%A0%EF%BC%9A%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90/" class="post-title-link" itemprop="url">第十章：聚类分析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2025-04-20 16:18:32" itemprop="dateCreated datePublished" datetime="2025-04-20T16:18:32+08:00">2025-04-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2025-05-27 17:09:23" itemprop="dateModified" datetime="2025-05-27T17:09:23+08:00">2025-05-27</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/" itemprop="url" rel="index"><span itemprop="name">数据挖掘</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a href="./File/CHAPTER10聚类分析基本概念和方法PPT课件.pptx">CHAPTER10聚类分析基本概念和方法PPT课件.pptx</a></p>
<h1 id="K-均值"><a href="#K-均值" class="headerlink" title="K-均值"></a>K-均值</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 读取数据并预处理</span></span><br><span class="line">data = pd.read_csv(<span class="string">&#x27;iris.csv&#x27;</span>)</span><br><span class="line">X = data.iloc[:, [<span class="number">2</span>, <span class="number">3</span>]].values  <span class="comment"># 使用鸢尾花花瓣长度和宽度</span></span><br><span class="line">species = data[<span class="string">&#x27;Species&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">k_means</span>(<span class="params">X, k, max_iters=<span class="number">100</span></span>):</span><br><span class="line">    <span class="comment"># 随机选择k个初始中心</span></span><br><span class="line">    centers = X[np.random.choice(X.shape[<span class="number">0</span>], k, replace=<span class="literal">False</span>)] <span class="comment"># 随机选择 k 个样本作为初始簇中心</span></span><br><span class="line">    clusters = np.zeros(X.shape[<span class="number">0</span>], dtype=<span class="built_in">int</span>)<span class="comment"># 初始化每个点所属簇的编号为 0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_iters):</span><br><span class="line">        <span class="comment"># 计算每个点到中心的欧氏距离</span></span><br><span class="line">        diff = X[:, np.newaxis, :] - centers  <span class="comment"># 形状 (n_samples, k, n_features)</span></span><br><span class="line">        distances = np.<span class="built_in">sum</span>(diff ** <span class="number">2</span>, axis=<span class="number">2</span>)  <span class="comment"># 平方欧氏距离</span></span><br><span class="line">        new_clusters = np.argmin(distances, axis=<span class="number">1</span>)<span class="comment">#对每个数据点，找到其最近的簇中心，并返回所属簇的编号（0 到 k-1）组成的数组</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 检查簇是否稳定</span></span><br><span class="line">        <span class="keyword">if</span> np.array_equal(new_clusters, clusters):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        clusters = new_clusters</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 更新簇中心</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):<span class="comment">#循环遍历每一个簇（从 0 到 k-1），准备更新每个簇的新中心点</span></span><br><span class="line">            cluster_points = X[clusters == i]<span class="comment"># 提取属于第 i 个簇的所有样本点</span></span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(cluster_points) == <span class="number">0</span>:  <span class="comment"># 处理空簇</span></span><br><span class="line">                centers[i] = X[np.random.choice(X.shape[<span class="number">0</span>], <span class="number">1</span>)]<span class="comment">#如果是空簇，就随机选择一个样本点作为新的中心点</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                centers[i] = cluster_points.mean(axis=<span class="number">0</span>)<span class="comment"># 如果簇中有成员，就取这些点的“平均值”作为新的中心点</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> clusters, centers</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行K-means聚类</span></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">clusters, centers = k_means(X, k)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始数据分布图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">species_types = species.unique()</span><br><span class="line">colors = [<span class="string">&#x27;blue&#x27;</span>, <span class="string">&#x27;green&#x27;</span>, <span class="string">&#x27;orange&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i, specie <span class="keyword">in</span> <span class="built_in">enumerate</span>(species_types):</span><br><span class="line">    plt.scatter(X[species == specie, <span class="number">0</span>], X[species == specie, <span class="number">1</span>],</span><br><span class="line">                label=specie, c=colors[i], alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据分布&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度（厘米）&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度（厘米）&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类结果图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">cluster_colors = [<span class="string">&#x27;red&#x27;</span>, <span class="string">&#x27;purple&#x27;</span>, <span class="string">&#x27;brown&#x27;</span>]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    plt.scatter(X[clusters == i, <span class="number">0</span>], X[clusters == i, <span class="number">1</span>],</span><br><span class="line">                label=<span class="string">f&#x27;簇 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&#x27;</span>, c=cluster_colors[i], alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.scatter(centers[:, <span class="number">0</span>], centers[:, <span class="number">1</span>], s=<span class="number">200</span>, marker=<span class="string">&#x27;*&#x27;</span>,</span><br><span class="line">            c=<span class="string">&#x27;red&#x27;</span>, edgecolor=<span class="string">&#x27;black&#x27;</span>, label=<span class="string">&#x27;簇中心&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;K-means 聚类结果&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度（厘米）&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度（厘米）&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h4 id="运行截图如下"><a href="#运行截图如下" class="headerlink" title="运行截图如下"></a>运行截图如下</h4><p><img src="images/K_%E5%9D%87%E5%80%BC.png" alt=""></p>
<h4 id="动态图"><a href="#动态图" class="headerlink" title="动态图"></a>动态图</h4><p><img src="images/%E5%8A%A8%E6%80%81%E5%9B%BE.png" alt=""></p>
<h2 id="迭代数据"><a href="#迭代数据" class="headerlink" title="迭代数据"></a>迭代数据</h2><p><a href="./File/kmeans_iterations.csv">kmeans_iterations.csv</a></p>
<div class="table-container">
<table>
<thead>
<tr>
<th>iteration</th>
<th>point_index</th>
<th>petal_length</th>
<th>petal_width</th>
<th>assigned_cluster</th>
<th>distance_0</th>
<th>distance_1</th>
<th>distance_2</th>
</tr>
</thead>
<tbody>
<tr>
<td>迭代参数</td>
<td>数据编号</td>
<td>花瓣长度</td>
<td>花瓣宽度</td>
<td>分配到的簇编号</td>
<td>点到簇中心0的欧氏距离</td>
<td>点到簇中心1的欧氏距离</td>
<td>点到簇中心2的欧氏距离</td>
</tr>
<tr>
<td>1</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.35</td>
<td>3.20</td>
<td>0.41</td>
</tr>
<tr>
<td>1</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.51</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.49</td>
<td>0.28</td>
</tr>
<tr>
<td>1</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.58</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>5.02</td>
<td>3.86</td>
<td>0.28</td>
</tr>
<tr>
<td>1</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.73</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.38</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.72</td>
<td>3.57</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.51</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.39</td>
<td>3.23</td>
<td>0.40</td>
</tr>
<tr>
<td>1</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.42</td>
<td>0.20</td>
</tr>
<tr>
<td>1</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>3.27</td>
<td>0.41</td>
</tr>
<tr>
<td>1</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.38</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.07</td>
<td>3.92</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.31</td>
<td>3.16</td>
<td>0.45</td>
</tr>
<tr>
<td>1</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.25</td>
<td>3.09</td>
<td>0.61</td>
</tr>
<tr>
<td>1</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>3.29</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.38</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.49</td>
<td>0.28</td>
</tr>
<tr>
<td>1</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.73</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.58</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.61</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.61</td>
<td>0</td>
</tr>
<tr>
<td>1</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.64</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.37</td>
<td>3.23</td>
<td>0.42</td>
</tr>
<tr>
<td>1</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.16</td>
<td>3.01</td>
<td>0.61</td>
</tr>
<tr>
<td>1</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.51</td>
<td>0.10</td>
</tr>
<tr>
<td>1</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.36</td>
<td>0.32</td>
</tr>
<tr>
<td>1</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.45</td>
<td>0.22</td>
</tr>
<tr>
<td>1</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.55</td>
<td>0.14</td>
</tr>
<tr>
<td>1</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.22</td>
<td>0.10</td>
<td>3.57</td>
</tr>
<tr>
<td>1</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1</td>
<td>0.20</td>
<td>3.79</td>
</tr>
<tr>
<td>1</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.88</td>
<td>0.73</td>
<td>2.88</td>
</tr>
<tr>
<td>1</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.10</td>
<td>3.51</td>
</tr>
<tr>
<td>1</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.44</td>
<td>0.28</td>
<td>3.35</td>
</tr>
<tr>
<td>1</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.12</td>
<td>0.10</td>
<td>3.64</td>
</tr>
<tr>
<td>1</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.64</td>
<td>1.49</td>
<td>2.12</td>
</tr>
<tr>
<td>1</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.36</td>
<td>0.22</td>
<td>3.45</td>
</tr>
<tr>
<td>1</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.93</td>
<td>0.81</td>
<td>2.82</td>
</tr>
<tr>
<td>1</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.46</td>
<td>1.30</td>
<td>2.31</td>
</tr>
<tr>
<td>1</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.62</td>
<td>0.50</td>
<td>3.14</td>
</tr>
<tr>
<td>1</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>2.02</td>
<td>0.86</td>
<td>2.79</td>
</tr>
<tr>
<td>1</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.22</td>
<td>0.10</td>
<td>3.57</td>
</tr>
<tr>
<td>1</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.25</td>
<td>1.12</td>
<td>2.51</td>
</tr>
<tr>
<td>1</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.48</td>
<td>0.32</td>
<td>3.29</td>
</tr>
<tr>
<td>1</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.94</td>
<td>0.78</td>
<td>2.89</td>
</tr>
<tr>
<td>1</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2.06</td>
<td>0.89</td>
<td>2.72</td>
</tr>
<tr>
<td>1</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.95</td>
<td>0.32</td>
<td>3.81</td>
</tr>
<tr>
<td>1</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.88</td>
<td>0.73</td>
<td>2.88</td>
</tr>
<tr>
<td>1</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1</td>
<td>0.20</td>
<td>3.79</td>
</tr>
<tr>
<td>1</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.35</td>
<td>0.30</td>
<td>3.52</td>
</tr>
<tr>
<td>1</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.45</td>
<td>3.16</td>
</tr>
<tr>
<td>1</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.48</td>
<td>0.32</td>
<td>3.29</td>
</tr>
<tr>
<td>1</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.14</td>
<td>0.14</td>
<td>3.67</td>
</tr>
<tr>
<td>1</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>1</td>
<td>0.81</td>
<td>0.36</td>
<td>3.96</td>
</tr>
<tr>
<td>1</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.46</td>
<td>1.30</td>
<td>2.31</td>
</tr>
<tr>
<td>1</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.15</td>
<td>0.98</td>
<td>2.62</td>
</tr>
<tr>
<td>1</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.28</td>
<td>1.12</td>
<td>2.50</td>
</tr>
<tr>
<td>1</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>2.01</td>
<td>0.85</td>
<td>2.75</td>
</tr>
<tr>
<td>1</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>1</td>
<td>0.78</td>
<td>0.41</td>
<td>4.02</td>
</tr>
<tr>
<td>1</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.20</td>
<td>3.42</td>
</tr>
<tr>
<td>1</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.30</td>
<td>0.22</td>
<td>3.45</td>
</tr>
<tr>
<td>1</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.17</td>
<td>0</td>
<td>3.61</td>
</tr>
<tr>
<td>1</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.53</td>
<td>0.36</td>
<td>3.26</td>
</tr>
<tr>
<td>1</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.63</td>
<td>2.97</td>
</tr>
<tr>
<td>1</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.88</td>
<td>0.73</td>
<td>2.88</td>
</tr>
<tr>
<td>1</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.58</td>
<td>0.42</td>
<td>3.23</td>
</tr>
<tr>
<td>1</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.30</td>
<td>0.14</td>
<td>3.48</td>
</tr>
<tr>
<td>1</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.92</td>
<td>0.76</td>
<td>2.85</td>
</tr>
<tr>
<td>1</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.64</td>
<td>1.49</td>
<td>2.12</td>
</tr>
<tr>
<td>1</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.54</td>
<td>3.07</td>
</tr>
<tr>
<td>1</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.75</td>
<td>0.58</td>
<td>3.04</td>
</tr>
<tr>
<td>1</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.54</td>
<td>3.07</td>
</tr>
<tr>
<td>1</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.45</td>
<td>3.16</td>
</tr>
<tr>
<td>1</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.88</td>
<td>1.75</td>
<td>1.88</td>
</tr>
<tr>
<td>1</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.63</td>
<td>2.97</td>
</tr>
<tr>
<td>1</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.50</td>
<td>1.64</td>
<td>5.19</td>
</tr>
<tr>
<td>1</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>1</td>
<td>0.63</td>
<td>0.57</td>
<td>4.12</td>
</tr>
<tr>
<td>1</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1.34</td>
<td>4.94</td>
</tr>
<tr>
<td>1</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.32</td>
<td>0.95</td>
<td>4.55</td>
</tr>
<tr>
<td>1</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.14</td>
<td>1.30</td>
<td>4.88</td>
</tr>
<tr>
<td>1</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.90</td>
<td>1.99</td>
<td>5.60</td>
</tr>
<tr>
<td>1</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.26</td>
<td>0.28</td>
<td>3.49</td>
</tr>
<tr>
<td>1</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.67</td>
<td>1.63</td>
<td>5.22</td>
</tr>
<tr>
<td>1</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.32</td>
<td>1.14</td>
<td>4.74</td>
</tr>
<tr>
<td>1</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.57</td>
<td>1.72</td>
<td>5.28</td>
</tr>
<tr>
<td>1</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.61</td>
<td>0.64</td>
<td>4.16</td>
</tr>
<tr>
<td>1</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.45</td>
<td>0.72</td>
<td>4.31</td>
</tr>
<tr>
<td>1</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1</td>
<td>4.57</td>
</tr>
<tr>
<td>1</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>1</td>
<td>0.71</td>
<td>0.58</td>
<td>4.07</td>
</tr>
<tr>
<td>1</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.67</td>
<td>0.98</td>
<td>4.34</td>
</tr>
<tr>
<td>1</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1</td>
<td>4.47</td>
</tr>
<tr>
<td>1</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.36</td>
<td>0.85</td>
<td>4.46</td>
</tr>
<tr>
<td>1</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1</td>
<td>2.12</td>
<td>5.72</td>
</tr>
<tr>
<td>1</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.22</td>
<td>2.34</td>
<td>5.95</td>
</tr>
<tr>
<td>1</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.92</td>
<td>0.30</td>
<td>3.89</td>
</tr>
<tr>
<td>1</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.20</td>
<td>1.28</td>
<td>4.83</td>
</tr>
<tr>
<td>1</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>1</td>
<td>0.81</td>
<td>0.54</td>
<td>3.98</td>
</tr>
<tr>
<td>1</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>2.06</td>
<td>5.66</td>
</tr>
<tr>
<td>1</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.36</td>
<td>3.90</td>
</tr>
<tr>
<td>1</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0</td>
<td>1.17</td>
<td>4.75</td>
</tr>
<tr>
<td>1</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.42</td>
<td>1.33</td>
<td>4.93</td>
</tr>
<tr>
<td>1</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.95</td>
<td>0.32</td>
<td>3.81</td>
</tr>
<tr>
<td>1</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.36</td>
<td>3.90</td>
</tr>
<tr>
<td>1</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.10</td>
<td>1.08</td>
<td>4.66</td>
</tr>
<tr>
<td>1</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.51</td>
<td>1.10</td>
<td>4.68</td>
</tr>
<tr>
<td>1</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.45</td>
<td>1.46</td>
<td>5.06</td>
</tr>
<tr>
<td>1</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.71</td>
<td>1.77</td>
<td>5.38</td>
</tr>
<tr>
<td>1</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.14</td>
<td>1.14</td>
<td>4.70</td>
</tr>
<tr>
<td>1</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.85</td>
<td>0.40</td>
<td>3.98</td>
</tr>
<tr>
<td>1</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.71</td>
<td>0.91</td>
<td>4.44</td>
</tr>
<tr>
<td>1</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1.61</td>
<td>5.20</td>
</tr>
<tr>
<td>1</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.32</td>
<td>1.27</td>
<td>4.79</td>
</tr>
<tr>
<td>1</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.36</td>
<td>0.85</td>
<td>4.46</td>
</tr>
<tr>
<td>1</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.95</td>
<td>0.32</td>
<td>3.81</td>
</tr>
<tr>
<td>1</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.30</td>
<td>0.92</td>
<td>4.48</td>
</tr>
<tr>
<td>1</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.32</td>
<td>1.27</td>
<td>4.79</td>
</tr>
<tr>
<td>1</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.63</td>
<td>0.89</td>
<td>4.29</td>
</tr>
<tr>
<td>1</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>1</td>
<td>0.63</td>
<td>0.57</td>
<td>4.12</td>
</tr>
<tr>
<td>1</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.28</td>
<td>1.44</td>
<td>5.02</td>
</tr>
<tr>
<td>1</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.40</td>
<td>1.41</td>
<td>4.92</td>
</tr>
<tr>
<td>1</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.54</td>
<td>0.94</td>
<td>4.38</td>
</tr>
<tr>
<td>1</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>1</td>
<td>0.73</td>
<td>0.50</td>
<td>4.03</td>
</tr>
<tr>
<td>1</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.51</td>
<td>0.71</td>
<td>4.25</td>
</tr>
<tr>
<td>1</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.36</td>
<td>1.06</td>
<td>4.56</td>
</tr>
<tr>
<td>1</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>1</td>
<td>0.67</td>
<td>0.50</td>
<td>4.09</td>
</tr>
<tr>
<td>2</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.41</td>
<td>2.89</td>
<td>0.28</td>
</tr>
<tr>
<td>2</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.73</td>
<td>3.20</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.72</td>
<td>3.19</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.81</td>
<td>3.28</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>5.08</td>
<td>3.56</td>
<td>0.39</td>
</tr>
<tr>
<td>2</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.95</td>
<td>3.43</td>
<td>0.27</td>
</tr>
<tr>
<td>2</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.60</td>
<td>3.08</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.78</td>
<td>3.26</td>
<td>0.22</td>
</tr>
<tr>
<td>2</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.73</td>
<td>3.20</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.45</td>
<td>2.92</td>
<td>0.24</td>
</tr>
<tr>
<td>2</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.63</td>
<td>3.11</td>
<td>0.07</td>
</tr>
<tr>
<td>2</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.49</td>
<td>2.96</td>
<td>0.24</td>
</tr>
<tr>
<td>2</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.60</td>
<td>3.08</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.13</td>
<td>3.61</td>
<td>0.46</td>
</tr>
<tr>
<td>2</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.37</td>
<td>2.85</td>
<td>0.35</td>
</tr>
<tr>
<td>2</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.31</td>
<td>2.78</td>
<td>0.44</td>
</tr>
<tr>
<td>2</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.50</td>
<td>2.98</td>
<td>0.21</td>
</tr>
<tr>
<td>2</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.60</td>
<td>3.08</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.72</td>
<td>3.19</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.95</td>
<td>3.43</td>
<td>0.27</td>
</tr>
<tr>
<td>2</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.81</td>
<td>3.28</td>
<td>0.16</td>
</tr>
<tr>
<td>2</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.82</td>
<td>3.30</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.82</td>
<td>3.30</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.86</td>
<td>3.33</td>
<td>0.17</td>
</tr>
<tr>
<td>2</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.43</td>
<td>2.92</td>
<td>0.38</td>
</tr>
<tr>
<td>2</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.23</td>
<td>2.70</td>
<td>0.46</td>
</tr>
<tr>
<td>2</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.73</td>
<td>3.20</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.58</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>2</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.67</td>
<td>3.15</td>
<td>0.06</td>
</tr>
<tr>
<td>2</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.77</td>
<td>3.24</td>
<td>0.08</td>
</tr>
<tr>
<td>2</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.28</td>
<td>0.30</td>
<td>3.44</td>
</tr>
<tr>
<td>2</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1.06</td>
<td>0.51</td>
<td>3.66</td>
</tr>
<tr>
<td>2</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.94</td>
<td>0.42</td>
<td>2.75</td>
</tr>
<tr>
<td>2</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.32</td>
<td>0.21</td>
<td>3.38</td>
</tr>
<tr>
<td>2</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.50</td>
<td>0.16</td>
<td>3.22</td>
</tr>
<tr>
<td>2</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.18</td>
<td>0.35</td>
<td>3.51</td>
</tr>
<tr>
<td>2</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.70</td>
<td>1.18</td>
<td>1.99</td>
</tr>
<tr>
<td>2</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.42</td>
<td>0.24</td>
<td>3.31</td>
</tr>
<tr>
<td>2</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>2</td>
<td>0.50</td>
<td>2.70</td>
</tr>
<tr>
<td>2</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.52</td>
<td>0.99</td>
<td>2.17</td>
</tr>
<tr>
<td>2</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.68</td>
<td>0.21</td>
<td>3.01</td>
</tr>
<tr>
<td>2</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>2.08</td>
<td>0.58</td>
<td>2.65</td>
</tr>
<tr>
<td>2</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.28</td>
<td>0.30</td>
<td>3.44</td>
</tr>
<tr>
<td>2</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.31</td>
<td>0.81</td>
<td>2.38</td>
</tr>
<tr>
<td>2</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.54</td>
<td>0.02</td>
<td>3.16</td>
</tr>
<tr>
<td>2</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>2</td>
<td>0.52</td>
<td>2.74</td>
</tr>
<tr>
<td>2</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2.12</td>
<td>0.60</td>
<td>2.58</td>
</tr>
<tr>
<td>2</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>1.01</td>
<td>0.55</td>
<td>3.68</td>
</tr>
<tr>
<td>2</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.94</td>
<td>0.42</td>
<td>2.75</td>
</tr>
<tr>
<td>2</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>1.06</td>
<td>0.51</td>
<td>3.66</td>
</tr>
<tr>
<td>2</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.40</td>
<td>0.37</td>
<td>3.38</td>
</tr>
<tr>
<td>2</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.67</td>
<td>0.16</td>
<td>3.03</td>
</tr>
<tr>
<td>2</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.54</td>
<td>0.02</td>
<td>3.16</td>
</tr>
<tr>
<td>2</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.20</td>
<td>0.40</td>
<td>3.53</td>
</tr>
<tr>
<td>2</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>1</td>
<td>0.87</td>
<td>0.66</td>
<td>3.83</td>
</tr>
<tr>
<td>2</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.52</td>
<td>0.99</td>
<td>2.17</td>
</tr>
<tr>
<td>2</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.21</td>
<td>0.68</td>
<td>2.49</td>
</tr>
<tr>
<td>2</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.34</td>
<td>0.82</td>
<td>2.36</td>
</tr>
<tr>
<td>2</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>2.08</td>
<td>0.55</td>
<td>2.62</td>
</tr>
<tr>
<td>2</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>1</td>
<td>0.84</td>
<td>0.72</td>
<td>3.88</td>
</tr>
<tr>
<td>2</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.40</td>
<td>0.13</td>
<td>3.29</td>
</tr>
<tr>
<td>2</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.36</td>
<td>0.20</td>
<td>3.33</td>
</tr>
<tr>
<td>2</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.23</td>
<td>0.31</td>
<td>3.47</td>
</tr>
<tr>
<td>2</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.59</td>
<td>0.12</td>
<td>3.12</td>
</tr>
<tr>
<td>2</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.85</td>
<td>0.32</td>
<td>2.84</td>
</tr>
<tr>
<td>2</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.94</td>
<td>0.42</td>
<td>2.75</td>
</tr>
<tr>
<td>2</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.64</td>
<td>0.22</td>
<td>3.09</td>
</tr>
<tr>
<td>2</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.36</td>
<td>0.20</td>
<td>3.34</td>
</tr>
<tr>
<td>2</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.99</td>
<td>0.46</td>
<td>2.71</td>
</tr>
<tr>
<td>2</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.70</td>
<td>1.18</td>
<td>1.99</td>
</tr>
<tr>
<td>2</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.76</td>
<td>0.24</td>
<td>2.93</td>
</tr>
<tr>
<td>2</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.81</td>
<td>0.30</td>
<td>2.90</td>
</tr>
<tr>
<td>2</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.76</td>
<td>0.24</td>
<td>2.93</td>
</tr>
<tr>
<td>2</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.67</td>
<td>0.16</td>
<td>3.03</td>
</tr>
<tr>
<td>2</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.94</td>
<td>1.44</td>
<td>1.76</td>
</tr>
<tr>
<td>2</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.85</td>
<td>0.32</td>
<td>2.84</td>
</tr>
<tr>
<td>2</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.46</td>
<td>1.93</td>
<td>5.07</td>
</tr>
<tr>
<td>2</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.70</td>
<td>0.85</td>
<td>4</td>
</tr>
<tr>
<td>2</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.13</td>
<td>1.65</td>
<td>4.81</td>
</tr>
<tr>
<td>2</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.35</td>
<td>1.26</td>
<td>4.42</td>
</tr>
<tr>
<td>2</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.10</td>
<td>1.60</td>
<td>4.76</td>
</tr>
<tr>
<td>2</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.83</td>
<td>2.30</td>
<td>5.46</td>
</tr>
<tr>
<td>2</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.33</td>
<td>0.29</td>
<td>3.37</td>
</tr>
<tr>
<td>2</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.61</td>
<td>1.94</td>
<td>5.08</td>
</tr>
<tr>
<td>2</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.45</td>
<td>4.61</td>
</tr>
<tr>
<td>2</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.52</td>
<td>2.01</td>
<td>5.16</td>
</tr>
<tr>
<td>2</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.68</td>
<td>0.91</td>
<td>4.04</td>
</tr>
<tr>
<td>2</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.51</td>
<td>1.02</td>
<td>4.18</td>
</tr>
<tr>
<td>2</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.27</td>
<td>1.29</td>
<td>4.44</td>
</tr>
<tr>
<td>2</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.77</td>
<td>0.83</td>
<td>3.95</td>
</tr>
<tr>
<td>2</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.73</td>
<td>1.20</td>
<td>4.23</td>
</tr>
<tr>
<td>2</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.51</td>
<td>1.26</td>
<td>4.35</td>
</tr>
<tr>
<td>2</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.41</td>
<td>1.16</td>
<td>4.33</td>
</tr>
<tr>
<td>2</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>0.94</td>
<td>2.43</td>
<td>5.59</td>
</tr>
<tr>
<td>2</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.15</td>
<td>2.65</td>
<td>5.81</td>
</tr>
<tr>
<td>2</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.98</td>
<td>0.60</td>
<td>3.75</td>
</tr>
<tr>
<td>2</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.21</td>
<td>1.57</td>
<td>4.71</td>
</tr>
<tr>
<td>2</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>1</td>
<td>0.87</td>
<td>0.76</td>
<td>3.86</td>
</tr>
<tr>
<td>2</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>0.94</td>
<td>2.37</td>
<td>5.52</td>
</tr>
<tr>
<td>2</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.92</td>
<td>0.63</td>
<td>3.77</td>
</tr>
<tr>
<td>2</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.07</td>
<td>1.47</td>
<td>4.63</td>
</tr>
<tr>
<td>2</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.38</td>
<td>1.64</td>
<td>4.80</td>
</tr>
<tr>
<td>2</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>1.01</td>
<td>0.55</td>
<td>3.68</td>
</tr>
<tr>
<td>2</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.92</td>
<td>0.63</td>
<td>3.77</td>
</tr>
<tr>
<td>2</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.17</td>
<td>1.38</td>
<td>4.53</td>
</tr>
<tr>
<td>2</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.51</td>
<td>1.41</td>
<td>4.54</td>
</tr>
<tr>
<td>2</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.39</td>
<td>1.77</td>
<td>4.92</td>
</tr>
<tr>
<td>2</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.64</td>
<td>2.08</td>
<td>5.24</td>
</tr>
<tr>
<td>2</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.19</td>
<td>1.43</td>
<td>4.58</td>
</tr>
<tr>
<td>2</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.90</td>
<td>0.70</td>
<td>3.85</td>
</tr>
<tr>
<td>2</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.73</td>
<td>1.20</td>
<td>4.30</td>
</tr>
<tr>
<td>2</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.39</td>
<td>1.91</td>
<td>5.07</td>
</tr>
<tr>
<td>2</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.55</td>
<td>4.67</td>
</tr>
<tr>
<td>2</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.41</td>
<td>1.16</td>
<td>4.33</td>
</tr>
<tr>
<td>2</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>1.01</td>
<td>0.55</td>
<td>3.68</td>
</tr>
<tr>
<td>2</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.37</td>
<td>1.21</td>
<td>4.35</td>
</tr>
<tr>
<td>2</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.55</td>
<td>4.67</td>
</tr>
<tr>
<td>2</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.70</td>
<td>1.12</td>
<td>4.18</td>
</tr>
<tr>
<td>2</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.70</td>
<td>0.85</td>
<td>4</td>
</tr>
<tr>
<td>2</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.24</td>
<td>1.74</td>
<td>4.89</td>
</tr>
<tr>
<td>2</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.40</td>
<td>1.69</td>
<td>4.80</td>
</tr>
<tr>
<td>2</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.60</td>
<td>1.19</td>
<td>4.27</td>
</tr>
<tr>
<td>2</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>1</td>
<td>0.79</td>
<td>0.77</td>
<td>3.91</td>
</tr>
<tr>
<td>2</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.58</td>
<td>0.99</td>
<td>4.13</td>
</tr>
<tr>
<td>2</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.42</td>
<td>1.33</td>
<td>4.44</td>
</tr>
<tr>
<td>2</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.73</td>
<td>0.79</td>
<td>3.96</td>
</tr>
<tr>
<td>3</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.34</td>
<td>2.83</td>
<td>0.28</td>
</tr>
<tr>
<td>3</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.15</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.13</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.22</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>5.01</td>
<td>3.50</td>
<td>0.39</td>
</tr>
<tr>
<td>3</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.37</td>
<td>0.27</td>
</tr>
<tr>
<td>3</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.02</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.71</td>
<td>3.21</td>
<td>0.22</td>
</tr>
<tr>
<td>3</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.15</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.38</td>
<td>2.87</td>
<td>0.24</td>
</tr>
<tr>
<td>3</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.56</td>
<td>3.06</td>
<td>0.07</td>
</tr>
<tr>
<td>3</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.42</td>
<td>2.91</td>
<td>0.24</td>
</tr>
<tr>
<td>3</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.02</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.06</td>
<td>3.56</td>
<td>0.46</td>
</tr>
<tr>
<td>3</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.30</td>
<td>2.80</td>
<td>0.35</td>
</tr>
<tr>
<td>3</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.24</td>
<td>2.73</td>
<td>0.44</td>
</tr>
<tr>
<td>3</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.21</td>
</tr>
<tr>
<td>3</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.53</td>
<td>3.02</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.13</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.88</td>
<td>3.37</td>
<td>0.27</td>
</tr>
<tr>
<td>3</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.74</td>
<td>3.22</td>
<td>0.16</td>
</tr>
<tr>
<td>3</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.75</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.79</td>
<td>3.28</td>
<td>0.17</td>
</tr>
<tr>
<td>3</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.36</td>
<td>2.87</td>
<td>0.38</td>
</tr>
<tr>
<td>3</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.16</td>
<td>2.65</td>
<td>0.46</td>
</tr>
<tr>
<td>3</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.66</td>
<td>3.15</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.51</td>
<td>3</td>
<td>0.15</td>
</tr>
<tr>
<td>3</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.06</td>
</tr>
<tr>
<td>3</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.19</td>
<td>0.08</td>
</tr>
<tr>
<td>3</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.21</td>
<td>0.35</td>
<td>3.44</td>
</tr>
<tr>
<td>3</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.99</td>
<td>0.56</td>
<td>3.66</td>
</tr>
<tr>
<td>3</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.87</td>
<td>0.37</td>
<td>2.75</td>
</tr>
<tr>
<td>3</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.27</td>
<td>3.38</td>
</tr>
<tr>
<td>3</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.43</td>
<td>0.17</td>
<td>3.22</td>
</tr>
<tr>
<td>3</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.11</td>
<td>0.40</td>
<td>3.51</td>
</tr>
<tr>
<td>3</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.63</td>
<td>1.12</td>
<td>1.99</td>
</tr>
<tr>
<td>3</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.35</td>
<td>0.26</td>
<td>3.31</td>
</tr>
<tr>
<td>3</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.93</td>
<td>0.45</td>
<td>2.70</td>
</tr>
<tr>
<td>3</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.45</td>
<td>0.94</td>
<td>2.17</td>
</tr>
<tr>
<td>3</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.61</td>
<td>0.19</td>
<td>3.01</td>
</tr>
<tr>
<td>3</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>2.02</td>
<td>0.53</td>
<td>2.65</td>
</tr>
<tr>
<td>3</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.21</td>
<td>0.35</td>
<td>3.44</td>
</tr>
<tr>
<td>3</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.24</td>
<td>0.76</td>
<td>2.38</td>
</tr>
<tr>
<td>3</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.47</td>
<td>0.05</td>
<td>3.16</td>
</tr>
<tr>
<td>3</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.93</td>
<td>0.47</td>
<td>2.74</td>
</tr>
<tr>
<td>3</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2.05</td>
<td>0.54</td>
<td>2.58</td>
</tr>
<tr>
<td>3</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.68</td>
</tr>
<tr>
<td>3</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.87</td>
<td>0.37</td>
<td>2.75</td>
</tr>
<tr>
<td>3</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.99</td>
<td>0.56</td>
<td>3.66</td>
</tr>
<tr>
<td>3</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.34</td>
<td>0.40</td>
<td>3.38</td>
</tr>
<tr>
<td>3</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>3.03</td>
</tr>
<tr>
<td>3</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.47</td>
<td>0.05</td>
<td>3.16</td>
</tr>
<tr>
<td>3</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.13</td>
<td>0.45</td>
<td>3.53</td>
</tr>
<tr>
<td>3</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>1</td>
<td>0.80</td>
<td>0.72</td>
<td>3.83</td>
</tr>
<tr>
<td>3</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.45</td>
<td>0.94</td>
<td>2.17</td>
</tr>
<tr>
<td>3</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.14</td>
<td>0.63</td>
<td>2.49</td>
</tr>
<tr>
<td>3</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.28</td>
<td>0.76</td>
<td>2.36</td>
</tr>
<tr>
<td>3</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>2.01</td>
<td>0.49</td>
<td>2.62</td>
</tr>
<tr>
<td>3</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.77</td>
<td>0.77</td>
<td>3.88</td>
</tr>
<tr>
<td>3</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.34</td>
<td>0.18</td>
<td>3.29</td>
</tr>
<tr>
<td>3</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.29</td>
<td>0.25</td>
<td>3.33</td>
</tr>
<tr>
<td>3</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.16</td>
<td>0.36</td>
<td>3.47</td>
</tr>
<tr>
<td>3</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.52</td>
<td>0.10</td>
<td>3.12</td>
</tr>
<tr>
<td>3</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.78</td>
<td>0.27</td>
<td>2.84</td>
</tr>
<tr>
<td>3</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.87</td>
<td>0.37</td>
<td>2.75</td>
</tr>
<tr>
<td>3</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.57</td>
<td>0.20</td>
<td>3.09</td>
</tr>
<tr>
<td>3</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.30</td>
<td>0.25</td>
<td>3.34</td>
</tr>
<tr>
<td>3</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.92</td>
<td>0.40</td>
<td>2.71</td>
</tr>
<tr>
<td>3</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.63</td>
<td>1.12</td>
<td>1.99</td>
</tr>
<tr>
<td>3</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.69</td>
<td>0.18</td>
<td>2.93</td>
</tr>
<tr>
<td>3</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.74</td>
<td>0.25</td>
<td>2.90</td>
</tr>
<tr>
<td>3</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.69</td>
<td>0.18</td>
<td>2.93</td>
</tr>
<tr>
<td>3</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>3.03</td>
</tr>
<tr>
<td>3</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.87</td>
<td>1.39</td>
<td>1.76</td>
</tr>
<tr>
<td>3</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.78</td>
<td>0.27</td>
<td>2.84</td>
</tr>
<tr>
<td>3</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.51</td>
<td>1.98</td>
<td>5.07</td>
</tr>
<tr>
<td>3</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.63</td>
<td>0.90</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1.70</td>
<td>4.81</td>
</tr>
<tr>
<td>3</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.30</td>
<td>1.31</td>
<td>4.42</td>
</tr>
<tr>
<td>3</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.66</td>
<td>4.76</td>
</tr>
<tr>
<td>3</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.90</td>
<td>2.35</td>
<td>5.46</td>
</tr>
<tr>
<td>3</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.26</td>
<td>0.34</td>
<td>3.37</td>
</tr>
<tr>
<td>3</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.66</td>
<td>1.99</td>
<td>5.08</td>
</tr>
<tr>
<td>3</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.30</td>
<td>1.50</td>
<td>4.61</td>
</tr>
<tr>
<td>3</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.58</td>
<td>2.07</td>
<td>5.16</td>
</tr>
<tr>
<td>3</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.61</td>
<td>0.96</td>
<td>4.04</td>
</tr>
<tr>
<td>3</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.44</td>
<td>1.07</td>
<td>4.18</td>
</tr>
<tr>
<td>3</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.20</td>
<td>1.35</td>
<td>4.44</td>
</tr>
<tr>
<td>3</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.71</td>
<td>0.89</td>
<td>3.95</td>
</tr>
<tr>
<td>3</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.68</td>
<td>1.25</td>
<td>4.23</td>
</tr>
<tr>
<td>3</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1.31</td>
<td>4.35</td>
</tr>
<tr>
<td>3</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.35</td>
<td>1.22</td>
<td>4.33</td>
</tr>
<tr>
<td>3</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.01</td>
<td>2.48</td>
<td>5.59</td>
</tr>
<tr>
<td>3</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.22</td>
<td>2.70</td>
<td>5.81</td>
</tr>
<tr>
<td>3</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.91</td>
<td>0.65</td>
<td>3.75</td>
</tr>
<tr>
<td>3</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.21</td>
<td>1.62</td>
<td>4.71</td>
</tr>
<tr>
<td>3</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.80</td>
<td>0.82</td>
<td>3.86</td>
</tr>
<tr>
<td>3</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1</td>
<td>2.42</td>
<td>5.52</td>
</tr>
<tr>
<td>3</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.68</td>
<td>3.77</td>
</tr>
<tr>
<td>3</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.01</td>
<td>1.52</td>
<td>4.63</td>
</tr>
<tr>
<td>3</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.41</td>
<td>1.70</td>
<td>4.80</td>
</tr>
<tr>
<td>3</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.68</td>
</tr>
<tr>
<td>3</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.85</td>
<td>0.68</td>
<td>3.77</td>
</tr>
<tr>
<td>3</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.10</td>
<td>1.43</td>
<td>4.53</td>
</tr>
<tr>
<td>3</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.50</td>
<td>1.46</td>
<td>4.54</td>
</tr>
<tr>
<td>3</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.44</td>
<td>1.82</td>
<td>4.92</td>
</tr>
<tr>
<td>3</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.71</td>
<td>2.13</td>
<td>5.24</td>
</tr>
<tr>
<td>3</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.49</td>
<td>4.58</td>
</tr>
<tr>
<td>3</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.84</td>
<td>0.75</td>
<td>3.85</td>
</tr>
<tr>
<td>3</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.69</td>
<td>1.25</td>
<td>4.30</td>
</tr>
<tr>
<td>3</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.45</td>
<td>1.97</td>
<td>5.07</td>
</tr>
<tr>
<td>3</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.33</td>
<td>1.60</td>
<td>4.67</td>
</tr>
<tr>
<td>3</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.35</td>
<td>1.22</td>
<td>4.33</td>
</tr>
<tr>
<td>3</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.68</td>
</tr>
<tr>
<td>3</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.30</td>
<td>1.26</td>
<td>4.35</td>
</tr>
<tr>
<td>3</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.33</td>
<td>1.60</td>
<td>4.67</td>
</tr>
<tr>
<td>3</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.64</td>
<td>1.18</td>
<td>4.18</td>
</tr>
<tr>
<td>3</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.63</td>
<td>0.90</td>
<td>4</td>
</tr>
<tr>
<td>3</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.29</td>
<td>1.79</td>
<td>4.89</td>
</tr>
<tr>
<td>3</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.41</td>
<td>1.74</td>
<td>4.80</td>
</tr>
<tr>
<td>3</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.54</td>
<td>1.24</td>
<td>4.27</td>
</tr>
<tr>
<td>3</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.72</td>
<td>0.82</td>
<td>3.91</td>
</tr>
<tr>
<td>3</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.51</td>
<td>1.04</td>
<td>4.13</td>
</tr>
<tr>
<td>3</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.37</td>
<td>1.39</td>
<td>4.44</td>
</tr>
<tr>
<td>3</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.66</td>
<td>0.85</td>
<td>3.96</td>
</tr>
<tr>
<td>4</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.29</td>
<td>2.79</td>
<td>0.28</td>
</tr>
<tr>
<td>4</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.61</td>
<td>3.11</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.69</td>
<td>3.18</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>4.96</td>
<td>3.46</td>
<td>0.39</td>
</tr>
<tr>
<td>4</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.83</td>
<td>3.33</td>
<td>0.27</td>
</tr>
<tr>
<td>4</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.47</td>
<td>2.98</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.66</td>
<td>3.17</td>
<td>0.22</td>
</tr>
<tr>
<td>4</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.61</td>
<td>3.11</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.33</td>
<td>2.83</td>
<td>0.24</td>
</tr>
<tr>
<td>4</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.51</td>
<td>3.02</td>
<td>0.07</td>
</tr>
<tr>
<td>4</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.37</td>
<td>2.87</td>
<td>0.24</td>
</tr>
<tr>
<td>4</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.47</td>
<td>2.98</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5.01</td>
<td>3.52</td>
<td>0.46</td>
</tr>
<tr>
<td>4</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.25</td>
<td>2.76</td>
<td>0.35</td>
</tr>
<tr>
<td>4</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.19</td>
<td>2.69</td>
<td>0.44</td>
</tr>
<tr>
<td>4</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.38</td>
<td>2.89</td>
<td>0.21</td>
</tr>
<tr>
<td>4</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.47</td>
<td>2.98</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.60</td>
<td>3.09</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.83</td>
<td>3.33</td>
<td>0.27</td>
</tr>
<tr>
<td>4</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.69</td>
<td>3.18</td>
<td>0.16</td>
</tr>
<tr>
<td>4</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.70</td>
<td>3.20</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.70</td>
<td>3.20</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.74</td>
<td>3.24</td>
<td>0.17</td>
</tr>
<tr>
<td>4</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.31</td>
<td>2.83</td>
<td>0.38</td>
</tr>
<tr>
<td>4</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.11</td>
<td>2.61</td>
<td>0.46</td>
</tr>
<tr>
<td>4</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.61</td>
<td>3.11</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.46</td>
<td>2.96</td>
<td>0.15</td>
</tr>
<tr>
<td>4</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.55</td>
<td>3.05</td>
<td>0.06</td>
</tr>
<tr>
<td>4</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.64</td>
<td>3.14</td>
<td>0.08</td>
</tr>
<tr>
<td>4</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.16</td>
<td>0.38</td>
<td>3.44</td>
</tr>
<tr>
<td>4</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.66</td>
</tr>
<tr>
<td>4</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.82</td>
<td>0.33</td>
<td>2.75</td>
</tr>
<tr>
<td>4</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.20</td>
<td>0.31</td>
<td>3.38</td>
</tr>
<tr>
<td>4</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.38</td>
<td>0.19</td>
<td>3.22</td>
</tr>
<tr>
<td>4</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.06</td>
<td>0.45</td>
<td>3.51</td>
</tr>
<tr>
<td>4</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.58</td>
<td>1.08</td>
<td>1.99</td>
</tr>
<tr>
<td>4</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.30</td>
<td>0.29</td>
<td>3.31</td>
</tr>
<tr>
<td>4</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.88</td>
<td>0.42</td>
<td>2.70</td>
</tr>
<tr>
<td>4</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.40</td>
<td>0.90</td>
<td>2.17</td>
</tr>
<tr>
<td>4</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.56</td>
<td>0.18</td>
<td>3.01</td>
</tr>
<tr>
<td>4</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1.97</td>
<td>0.49</td>
<td>2.65</td>
</tr>
<tr>
<td>4</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.16</td>
<td>0.38</td>
<td>3.44</td>
</tr>
<tr>
<td>4</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.19</td>
<td>0.72</td>
<td>2.38</td>
</tr>
<tr>
<td>4</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.42</td>
<td>0.09</td>
<td>3.16</td>
</tr>
<tr>
<td>4</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.88</td>
<td>0.43</td>
<td>2.74</td>
</tr>
<tr>
<td>4</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>2</td>
<td>0.50</td>
<td>2.58</td>
</tr>
<tr>
<td>4</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.89</td>
<td>0.65</td>
<td>3.68</td>
</tr>
<tr>
<td>4</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.82</td>
<td>0.33</td>
<td>2.75</td>
</tr>
<tr>
<td>4</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.94</td>
<td>0.60</td>
<td>3.66</td>
</tr>
<tr>
<td>4</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.29</td>
<td>0.42</td>
<td>3.38</td>
</tr>
<tr>
<td>4</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.56</td>
<td>0.07</td>
<td>3.03</td>
</tr>
<tr>
<td>4</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.42</td>
<td>0.09</td>
<td>3.16</td>
</tr>
<tr>
<td>4</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.08</td>
<td>0.48</td>
<td>3.53</td>
</tr>
<tr>
<td>4</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>0</td>
<td>0.75</td>
<td>0.76</td>
<td>3.83</td>
</tr>
<tr>
<td>4</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.40</td>
<td>0.90</td>
<td>2.17</td>
</tr>
<tr>
<td>4</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.09</td>
<td>0.58</td>
<td>2.49</td>
</tr>
<tr>
<td>4</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.23</td>
<td>0.72</td>
<td>2.36</td>
</tr>
<tr>
<td>4</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>1.96</td>
<td>0.45</td>
<td>2.62</td>
</tr>
<tr>
<td>4</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.72</td>
<td>0.81</td>
<td>3.88</td>
</tr>
<tr>
<td>4</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.28</td>
<td>0.22</td>
<td>3.29</td>
</tr>
<tr>
<td>4</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.24</td>
<td>0.29</td>
<td>3.33</td>
</tr>
<tr>
<td>4</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.11</td>
<td>0.40</td>
<td>3.47</td>
</tr>
<tr>
<td>4</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.47</td>
<td>0.11</td>
<td>3.12</td>
</tr>
<tr>
<td>4</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.73</td>
<td>0.23</td>
<td>2.84</td>
</tr>
<tr>
<td>4</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.82</td>
<td>0.33</td>
<td>2.75</td>
</tr>
<tr>
<td>4</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.52</td>
<td>0.19</td>
<td>3.09</td>
</tr>
<tr>
<td>4</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.25</td>
<td>0.28</td>
<td>3.34</td>
</tr>
<tr>
<td>4</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.87</td>
<td>0.36</td>
<td>2.71</td>
</tr>
<tr>
<td>4</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.58</td>
<td>1.08</td>
<td>1.99</td>
</tr>
<tr>
<td>4</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.64</td>
<td>0.14</td>
<td>2.93</td>
</tr>
<tr>
<td>4</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.69</td>
<td>0.21</td>
<td>2.90</td>
</tr>
<tr>
<td>4</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.64</td>
<td>0.14</td>
<td>2.93</td>
</tr>
<tr>
<td>4</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.56</td>
<td>0.07</td>
<td>3.03</td>
</tr>
<tr>
<td>4</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.82</td>
<td>1.35</td>
<td>1.76</td>
</tr>
<tr>
<td>4</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.73</td>
<td>0.23</td>
<td>2.84</td>
</tr>
<tr>
<td>4</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.55</td>
<td>2.03</td>
<td>5.07</td>
</tr>
<tr>
<td>4</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.58</td>
<td>0.94</td>
<td>4</td>
</tr>
<tr>
<td>4</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.25</td>
<td>1.74</td>
<td>4.81</td>
</tr>
<tr>
<td>4</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.27</td>
<td>1.35</td>
<td>4.42</td>
</tr>
<tr>
<td>4</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.20</td>
<td>1.70</td>
<td>4.76</td>
</tr>
<tr>
<td>4</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.95</td>
<td>2.40</td>
<td>5.46</td>
</tr>
<tr>
<td>4</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.21</td>
<td>0.38</td>
<td>3.37</td>
</tr>
<tr>
<td>4</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.70</td>
<td>2.03</td>
<td>5.08</td>
</tr>
<tr>
<td>4</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.54</td>
<td>4.61</td>
</tr>
<tr>
<td>4</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.62</td>
<td>2.11</td>
<td>5.16</td>
</tr>
<tr>
<td>4</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.56</td>
<td>1</td>
<td>4.04</td>
</tr>
<tr>
<td>4</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.39</td>
<td>1.12</td>
<td>4.18</td>
</tr>
<tr>
<td>4</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.16</td>
<td>1.39</td>
<td>4.44</td>
</tr>
<tr>
<td>4</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.66</td>
<td>0.93</td>
<td>3.95</td>
</tr>
<tr>
<td>4</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.64</td>
<td>1.29</td>
<td>4.23</td>
</tr>
<tr>
<td>4</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.42</td>
<td>1.35</td>
<td>4.35</td>
</tr>
<tr>
<td>4</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.26</td>
<td>4.33</td>
</tr>
<tr>
<td>4</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.06</td>
<td>2.52</td>
<td>5.59</td>
</tr>
<tr>
<td>4</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.27</td>
<td>2.74</td>
<td>5.81</td>
</tr>
<tr>
<td>4</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.87</td>
<td>0.69</td>
<td>3.75</td>
</tr>
<tr>
<td>4</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.24</td>
<td>1.67</td>
<td>4.71</td>
</tr>
<tr>
<td>4</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.76</td>
<td>0.86</td>
<td>3.86</td>
</tr>
<tr>
<td>4</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1.05</td>
<td>2.46</td>
<td>5.52</td>
</tr>
<tr>
<td>4</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.80</td>
<td>0.72</td>
<td>3.77</td>
</tr>
<tr>
<td>4</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.56</td>
<td>4.63</td>
</tr>
<tr>
<td>4</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.44</td>
<td>1.74</td>
<td>4.80</td>
</tr>
<tr>
<td>4</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.89</td>
<td>0.65</td>
<td>3.68</td>
</tr>
<tr>
<td>4</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.80</td>
<td>0.72</td>
<td>3.77</td>
</tr>
<tr>
<td>4</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.47</td>
<td>4.53</td>
</tr>
<tr>
<td>4</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.49</td>
<td>1.50</td>
<td>4.54</td>
</tr>
<tr>
<td>4</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.48</td>
<td>1.86</td>
<td>4.92</td>
</tr>
<tr>
<td>4</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.75</td>
<td>2.17</td>
<td>5.24</td>
</tr>
<tr>
<td>4</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.14</td>
<td>1.53</td>
<td>4.58</td>
</tr>
<tr>
<td>4</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>1</td>
<td>0.79</td>
<td>0.79</td>
<td>3.85</td>
</tr>
<tr>
<td>4</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.67</td>
<td>1.28</td>
<td>4.30</td>
</tr>
<tr>
<td>4</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.50</td>
<td>2.01</td>
<td>5.07</td>
</tr>
<tr>
<td>4</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.64</td>
<td>4.67</td>
</tr>
<tr>
<td>4</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.26</td>
<td>4.33</td>
</tr>
<tr>
<td>4</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.89</td>
<td>0.65</td>
<td>3.68</td>
</tr>
<tr>
<td>4</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.25</td>
<td>1.31</td>
<td>4.35</td>
</tr>
<tr>
<td>4</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.64</td>
<td>4.67</td>
</tr>
<tr>
<td>4</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.60</td>
<td>1.22</td>
<td>4.18</td>
</tr>
<tr>
<td>4</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.58</td>
<td>0.94</td>
<td>4</td>
</tr>
<tr>
<td>4</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.83</td>
<td>4.89</td>
</tr>
<tr>
<td>4</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.43</td>
<td>1.79</td>
<td>4.80</td>
</tr>
<tr>
<td>4</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.51</td>
<td>1.28</td>
<td>4.27</td>
</tr>
<tr>
<td>4</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.67</td>
<td>0.86</td>
<td>3.91</td>
</tr>
<tr>
<td>4</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.46</td>
<td>1.08</td>
<td>4.13</td>
</tr>
<tr>
<td>4</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.43</td>
<td>4.44</td>
</tr>
<tr>
<td>4</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.61</td>
<td>0.89</td>
<td>3.96</td>
</tr>
<tr>
<td>5</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.27</td>
<td>2.78</td>
<td>0.28</td>
</tr>
<tr>
<td>5</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.59</td>
<td>3.10</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.58</td>
<td>3.08</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>4.94</td>
<td>3.45</td>
<td>0.39</td>
</tr>
<tr>
<td>5</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.81</td>
<td>3.32</td>
<td>0.27</td>
</tr>
<tr>
<td>5</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.46</td>
<td>2.97</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.64</td>
<td>3.16</td>
<td>0.22</td>
</tr>
<tr>
<td>5</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.59</td>
<td>3.10</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.31</td>
<td>2.82</td>
<td>0.24</td>
</tr>
<tr>
<td>5</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.50</td>
<td>3</td>
<td>0.07</td>
</tr>
<tr>
<td>5</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.35</td>
<td>2.85</td>
<td>0.24</td>
</tr>
<tr>
<td>5</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.46</td>
<td>2.97</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>5</td>
<td>3.51</td>
<td>0.46</td>
</tr>
<tr>
<td>5</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.24</td>
<td>2.75</td>
<td>0.35</td>
</tr>
<tr>
<td>5</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.17</td>
<td>2.67</td>
<td>0.44</td>
</tr>
<tr>
<td>5</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.37</td>
<td>2.87</td>
<td>0.21</td>
</tr>
<tr>
<td>5</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.46</td>
<td>2.97</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.58</td>
<td>3.08</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.81</td>
<td>3.32</td>
<td>0.27</td>
</tr>
<tr>
<td>5</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.16</td>
</tr>
<tr>
<td>5</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.68</td>
<td>3.19</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.68</td>
<td>3.19</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.72</td>
<td>3.22</td>
<td>0.17</td>
</tr>
<tr>
<td>5</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.29</td>
<td>2.81</td>
<td>0.38</td>
</tr>
<tr>
<td>5</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.09</td>
<td>2.59</td>
<td>0.46</td>
</tr>
<tr>
<td>5</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.59</td>
<td>3.10</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.45</td>
<td>2.95</td>
<td>0.15</td>
</tr>
<tr>
<td>5</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.54</td>
<td>3.04</td>
<td>0.06</td>
</tr>
<tr>
<td>5</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.63</td>
<td>3.13</td>
<td>0.08</td>
</tr>
<tr>
<td>5</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.15</td>
<td>0.39</td>
<td>3.44</td>
</tr>
<tr>
<td>5</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.93</td>
<td>0.61</td>
<td>3.66</td>
</tr>
<tr>
<td>5</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.81</td>
<td>0.31</td>
<td>2.75</td>
</tr>
<tr>
<td>5</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.18</td>
<td>0.32</td>
<td>3.38</td>
</tr>
<tr>
<td>5</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.37</td>
<td>0.20</td>
<td>3.22</td>
</tr>
<tr>
<td>5</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.04</td>
<td>0.46</td>
<td>3.51</td>
</tr>
<tr>
<td>5</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.57</td>
<td>1.07</td>
<td>1.99</td>
</tr>
<tr>
<td>5</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.29</td>
<td>0.30</td>
<td>3.31</td>
</tr>
<tr>
<td>5</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.86</td>
<td>0.41</td>
<td>2.70</td>
</tr>
<tr>
<td>5</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.39</td>
<td>0.88</td>
<td>2.17</td>
</tr>
<tr>
<td>5</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.54</td>
<td>0.17</td>
<td>3.01</td>
</tr>
<tr>
<td>5</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1.95</td>
<td>0.47</td>
<td>2.65</td>
</tr>
<tr>
<td>5</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.15</td>
<td>0.39</td>
<td>3.44</td>
</tr>
<tr>
<td>5</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.17</td>
<td>0.71</td>
<td>2.38</td>
</tr>
<tr>
<td>5</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.40</td>
<td>0.10</td>
<td>3.16</td>
</tr>
<tr>
<td>5</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.87</td>
<td>0.42</td>
<td>2.74</td>
</tr>
<tr>
<td>5</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>1.99</td>
<td>0.48</td>
<td>2.58</td>
</tr>
<tr>
<td>5</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.88</td>
<td>0.66</td>
<td>3.68</td>
</tr>
<tr>
<td>5</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.81</td>
<td>0.31</td>
<td>2.75</td>
</tr>
<tr>
<td>5</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.93</td>
<td>0.61</td>
<td>3.66</td>
</tr>
<tr>
<td>5</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.27</td>
<td>0.42</td>
<td>3.38</td>
</tr>
<tr>
<td>5</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.54</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>5</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.40</td>
<td>0.10</td>
<td>3.16</td>
</tr>
<tr>
<td>5</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.07</td>
<td>0.49</td>
<td>3.53</td>
</tr>
<tr>
<td>5</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>0</td>
<td>0.73</td>
<td>0.77</td>
<td>3.83</td>
</tr>
<tr>
<td>5</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.39</td>
<td>0.88</td>
<td>2.17</td>
</tr>
<tr>
<td>5</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.07</td>
<td>0.57</td>
<td>2.49</td>
</tr>
<tr>
<td>5</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.21</td>
<td>0.71</td>
<td>2.36</td>
</tr>
<tr>
<td>5</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>1.94</td>
<td>0.44</td>
<td>2.62</td>
</tr>
<tr>
<td>5</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.71</td>
<td>0.83</td>
<td>3.88</td>
</tr>
<tr>
<td>5</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.27</td>
<td>0.24</td>
<td>3.29</td>
</tr>
<tr>
<td>5</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.23</td>
<td>0.31</td>
<td>3.33</td>
</tr>
<tr>
<td>5</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.09</td>
<td>0.42</td>
<td>3.47</td>
</tr>
<tr>
<td>5</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.45</td>
<td>0.11</td>
<td>3.12</td>
</tr>
<tr>
<td>5</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.72</td>
<td>0.22</td>
<td>2.84</td>
</tr>
<tr>
<td>5</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.81</td>
<td>0.31</td>
<td>2.75</td>
</tr>
<tr>
<td>5</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.51</td>
<td>0.19</td>
<td>3.09</td>
</tr>
<tr>
<td>5</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.23</td>
<td>0.30</td>
<td>3.34</td>
</tr>
<tr>
<td>5</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.85</td>
<td>0.35</td>
<td>2.71</td>
</tr>
<tr>
<td>5</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.57</td>
<td>1.07</td>
<td>1.99</td>
</tr>
<tr>
<td>5</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.63</td>
<td>0.12</td>
<td>2.93</td>
</tr>
<tr>
<td>5</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.68</td>
<td>0.19</td>
<td>2.90</td>
</tr>
<tr>
<td>5</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.63</td>
<td>0.12</td>
<td>2.93</td>
</tr>
<tr>
<td>5</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.54</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>5</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.81</td>
<td>1.33</td>
<td>1.76</td>
</tr>
<tr>
<td>5</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.72</td>
<td>0.22</td>
<td>2.84</td>
</tr>
<tr>
<td>5</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.57</td>
<td>2.04</td>
<td>5.07</td>
</tr>
<tr>
<td>5</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.56</td>
<td>0.96</td>
<td>4</td>
</tr>
<tr>
<td>5</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.27</td>
<td>1.76</td>
<td>4.81</td>
</tr>
<tr>
<td>5</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.26</td>
<td>1.36</td>
<td>4.42</td>
</tr>
<tr>
<td>5</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.21</td>
<td>1.71</td>
<td>4.76</td>
</tr>
<tr>
<td>5</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.96</td>
<td>2.41</td>
<td>5.46</td>
</tr>
<tr>
<td>5</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.19</td>
<td>0.39</td>
<td>3.37</td>
</tr>
<tr>
<td>5</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.71</td>
<td>2.04</td>
<td>5.08</td>
</tr>
<tr>
<td>5</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.31</td>
<td>1.56</td>
<td>4.61</td>
</tr>
<tr>
<td>5</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.64</td>
<td>2.12</td>
<td>5.16</td>
</tr>
<tr>
<td>5</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.54</td>
<td>1.02</td>
<td>4.04</td>
</tr>
<tr>
<td>5</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.37</td>
<td>1.13</td>
<td>4.18</td>
</tr>
<tr>
<td>5</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.14</td>
<td>1.40</td>
<td>4.44</td>
</tr>
<tr>
<td>5</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.64</td>
<td>0.94</td>
<td>3.95</td>
</tr>
<tr>
<td>5</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.64</td>
<td>1.31</td>
<td>4.23</td>
</tr>
<tr>
<td>5</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.41</td>
<td>1.37</td>
<td>4.35</td>
</tr>
<tr>
<td>5</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.29</td>
<td>1.27</td>
<td>4.33</td>
</tr>
<tr>
<td>5</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.07</td>
<td>2.54</td>
<td>5.59</td>
</tr>
<tr>
<td>5</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.28</td>
<td>2.76</td>
<td>5.81</td>
</tr>
<tr>
<td>5</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.85</td>
<td>0.71</td>
<td>3.75</td>
</tr>
<tr>
<td>5</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.25</td>
<td>1.68</td>
<td>4.71</td>
</tr>
<tr>
<td>5</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.74</td>
<td>0.87</td>
<td>3.86</td>
</tr>
<tr>
<td>5</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1.06</td>
<td>2.48</td>
<td>5.52</td>
</tr>
<tr>
<td>5</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.78</td>
<td>0.74</td>
<td>3.77</td>
</tr>
<tr>
<td>5</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.07</td>
<td>1.58</td>
<td>4.63</td>
</tr>
<tr>
<td>5</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.45</td>
<td>1.75</td>
<td>4.80</td>
</tr>
<tr>
<td>5</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.88</td>
<td>0.66</td>
<td>3.68</td>
</tr>
<tr>
<td>5</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.78</td>
<td>0.74</td>
<td>3.77</td>
</tr>
<tr>
<td>5</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.49</td>
<td>4.53</td>
</tr>
<tr>
<td>5</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.49</td>
<td>1.51</td>
<td>4.54</td>
</tr>
<tr>
<td>5</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.49</td>
<td>1.87</td>
<td>4.92</td>
</tr>
<tr>
<td>5</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.76</td>
<td>2.19</td>
<td>5.24</td>
</tr>
<tr>
<td>5</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.54</td>
<td>4.58</td>
</tr>
<tr>
<td>5</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>0</td>
<td>0.78</td>
<td>0.80</td>
<td>3.85</td>
</tr>
<tr>
<td>5</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.66</td>
<td>1.29</td>
<td>4.30</td>
</tr>
<tr>
<td>5</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.52</td>
<td>2.02</td>
<td>5.07</td>
</tr>
<tr>
<td>5</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.66</td>
<td>4.67</td>
</tr>
<tr>
<td>5</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.29</td>
<td>1.27</td>
<td>4.33</td>
</tr>
<tr>
<td>5</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.88</td>
<td>0.66</td>
<td>3.68</td>
</tr>
<tr>
<td>5</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.24</td>
<td>1.32</td>
<td>4.35</td>
</tr>
<tr>
<td>5</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.34</td>
<td>1.66</td>
<td>4.67</td>
</tr>
<tr>
<td>5</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.59</td>
<td>1.23</td>
<td>4.18</td>
</tr>
<tr>
<td>5</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.56</td>
<td>0.96</td>
<td>4</td>
</tr>
<tr>
<td>5</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.36</td>
<td>1.85</td>
<td>4.89</td>
</tr>
<tr>
<td>5</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.44</td>
<td>1.80</td>
<td>4.80</td>
</tr>
<tr>
<td>5</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.50</td>
<td>1.30</td>
<td>4.27</td>
</tr>
<tr>
<td>5</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.66</td>
<td>0.88</td>
<td>3.91</td>
</tr>
<tr>
<td>5</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.44</td>
<td>1.10</td>
<td>4.13</td>
</tr>
<tr>
<td>5</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.44</td>
<td>4.44</td>
</tr>
<tr>
<td>5</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.60</td>
<td>0.91</td>
<td>3.96</td>
</tr>
<tr>
<td>6</td>
<td>0</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>1</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>2</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>3</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>4</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>5</td>
<td>1.70</td>
<td>0.40</td>
<td>2</td>
<td>4.26</td>
<td>2.76</td>
<td>0.28</td>
</tr>
<tr>
<td>6</td>
<td>6</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.08</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>7</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>8</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>9</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.56</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>10</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>11</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>12</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.15</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>13</td>
<td>1.10</td>
<td>0.10</td>
<td>2</td>
<td>4.93</td>
<td>3.43</td>
<td>0.39</td>
</tr>
<tr>
<td>6</td>
<td>14</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.80</td>
<td>3.30</td>
<td>0.27</td>
</tr>
<tr>
<td>6</td>
<td>15</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>2.95</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>16</td>
<td>1.30</td>
<td>0.40</td>
<td>2</td>
<td>4.63</td>
<td>3.14</td>
<td>0.22</td>
</tr>
<tr>
<td>6</td>
<td>17</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.08</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>18</td>
<td>1.70</td>
<td>0.30</td>
<td>2</td>
<td>4.30</td>
<td>2.80</td>
<td>0.24</td>
</tr>
<tr>
<td>6</td>
<td>19</td>
<td>1.50</td>
<td>0.30</td>
<td>2</td>
<td>4.48</td>
<td>2.99</td>
<td>0.07</td>
</tr>
<tr>
<td>6</td>
<td>20</td>
<td>1.70</td>
<td>0.20</td>
<td>2</td>
<td>4.34</td>
<td>2.84</td>
<td>0.24</td>
</tr>
<tr>
<td>6</td>
<td>21</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>2.95</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>22</td>
<td>1</td>
<td>0.20</td>
<td>2</td>
<td>4.98</td>
<td>3.49</td>
<td>0.46</td>
</tr>
<tr>
<td>6</td>
<td>23</td>
<td>1.70</td>
<td>0.50</td>
<td>2</td>
<td>4.22</td>
<td>2.73</td>
<td>0.35</td>
</tr>
<tr>
<td>6</td>
<td>24</td>
<td>1.90</td>
<td>0.20</td>
<td>2</td>
<td>4.16</td>
<td>2.66</td>
<td>0.44</td>
</tr>
<tr>
<td>6</td>
<td>25</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>26</td>
<td>1.60</td>
<td>0.40</td>
<td>2</td>
<td>4.35</td>
<td>2.86</td>
<td>0.21</td>
</tr>
<tr>
<td>6</td>
<td>27</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>28</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>29</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>30</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>31</td>
<td>1.50</td>
<td>0.40</td>
<td>2</td>
<td>4.44</td>
<td>2.95</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>32</td>
<td>1.50</td>
<td>0.10</td>
<td>2</td>
<td>4.56</td>
<td>3.06</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>33</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>34</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>35</td>
<td>1.20</td>
<td>0.20</td>
<td>2</td>
<td>4.80</td>
<td>3.30</td>
<td>0.27</td>
</tr>
<tr>
<td>6</td>
<td>36</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>37</td>
<td>1.40</td>
<td>0.10</td>
<td>2</td>
<td>4.65</td>
<td>3.15</td>
<td>0.16</td>
</tr>
<tr>
<td>6</td>
<td>38</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>39</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>40</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>41</td>
<td>1.30</td>
<td>0.30</td>
<td>2</td>
<td>4.67</td>
<td>3.17</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>42</td>
<td>1.30</td>
<td>0.20</td>
<td>2</td>
<td>4.70</td>
<td>3.21</td>
<td>0.17</td>
</tr>
<tr>
<td>6</td>
<td>43</td>
<td>1.60</td>
<td>0.60</td>
<td>2</td>
<td>4.28</td>
<td>2.80</td>
<td>0.38</td>
</tr>
<tr>
<td>6</td>
<td>44</td>
<td>1.90</td>
<td>0.40</td>
<td>2</td>
<td>4.07</td>
<td>2.58</td>
<td>0.46</td>
</tr>
<tr>
<td>6</td>
<td>45</td>
<td>1.40</td>
<td>0.30</td>
<td>2</td>
<td>4.57</td>
<td>3.08</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>46</td>
<td>1.60</td>
<td>0.20</td>
<td>2</td>
<td>4.43</td>
<td>2.93</td>
<td>0.15</td>
</tr>
<tr>
<td>6</td>
<td>47</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>48</td>
<td>1.50</td>
<td>0.20</td>
<td>2</td>
<td>4.52</td>
<td>3.02</td>
<td>0.06</td>
</tr>
<tr>
<td>6</td>
<td>49</td>
<td>1.40</td>
<td>0.20</td>
<td>2</td>
<td>4.61</td>
<td>3.12</td>
<td>0.08</td>
</tr>
<tr>
<td>6</td>
<td>50</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.13</td>
<td>0.41</td>
<td>3.44</td>
</tr>
<tr>
<td>6</td>
<td>51</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>52</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.91</td>
<td>0.62</td>
<td>3.66</td>
</tr>
<tr>
<td>6</td>
<td>53</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.30</td>
<td>2.75</td>
</tr>
<tr>
<td>6</td>
<td>54</td>
<td>4.60</td>
<td>1.50</td>
<td>1</td>
<td>1.16</td>
<td>0.34</td>
<td>3.38</td>
</tr>
<tr>
<td>6</td>
<td>55</td>
<td>4.50</td>
<td>1.30</td>
<td>1</td>
<td>1.35</td>
<td>0.22</td>
<td>3.22</td>
</tr>
<tr>
<td>6</td>
<td>56</td>
<td>4.70</td>
<td>1.60</td>
<td>1</td>
<td>1.03</td>
<td>0.47</td>
<td>3.51</td>
</tr>
<tr>
<td>6</td>
<td>57</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.55</td>
<td>1.06</td>
<td>1.99</td>
</tr>
<tr>
<td>6</td>
<td>58</td>
<td>4.60</td>
<td>1.30</td>
<td>1</td>
<td>1.27</td>
<td>0.31</td>
<td>3.31</td>
</tr>
<tr>
<td>6</td>
<td>59</td>
<td>3.90</td>
<td>1.40</td>
<td>1</td>
<td>1.84</td>
<td>0.39</td>
<td>2.70</td>
</tr>
<tr>
<td>6</td>
<td>60</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.37</td>
<td>0.87</td>
<td>2.17</td>
</tr>
<tr>
<td>6</td>
<td>61</td>
<td>4.20</td>
<td>1.50</td>
<td>1</td>
<td>1.53</td>
<td>0.17</td>
<td>3.01</td>
</tr>
<tr>
<td>6</td>
<td>62</td>
<td>4</td>
<td>1</td>
<td>1</td>
<td>1.93</td>
<td>0.46</td>
<td>2.65</td>
</tr>
<tr>
<td>6</td>
<td>63</td>
<td>4.70</td>
<td>1.40</td>
<td>1</td>
<td>1.13</td>
<td>0.41</td>
<td>3.44</td>
</tr>
<tr>
<td>6</td>
<td>64</td>
<td>3.60</td>
<td>1.30</td>
<td>1</td>
<td>2.16</td>
<td>0.70</td>
<td>2.38</td>
</tr>
<tr>
<td>6</td>
<td>65</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.39</td>
<td>0.11</td>
<td>3.16</td>
</tr>
<tr>
<td>6</td>
<td>66</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>67</td>
<td>4.10</td>
<td>1</td>
<td>1</td>
<td>1.85</td>
<td>0.41</td>
<td>2.74</td>
</tr>
<tr>
<td>6</td>
<td>68</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>69</td>
<td>3.90</td>
<td>1.10</td>
<td>1</td>
<td>1.97</td>
<td>0.47</td>
<td>2.58</td>
</tr>
<tr>
<td>6</td>
<td>70</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.86</td>
<td>0.67</td>
<td>3.68</td>
</tr>
<tr>
<td>6</td>
<td>71</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.30</td>
<td>2.75</td>
</tr>
<tr>
<td>6</td>
<td>72</td>
<td>4.90</td>
<td>1.50</td>
<td>1</td>
<td>0.91</td>
<td>0.62</td>
<td>3.66</td>
</tr>
<tr>
<td>6</td>
<td>73</td>
<td>4.70</td>
<td>1.20</td>
<td>1</td>
<td>1.26</td>
<td>0.44</td>
<td>3.38</td>
</tr>
<tr>
<td>6</td>
<td>74</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.52</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>6</td>
<td>75</td>
<td>4.40</td>
<td>1.40</td>
<td>1</td>
<td>1.39</td>
<td>0.11</td>
<td>3.16</td>
</tr>
<tr>
<td>6</td>
<td>76</td>
<td>4.80</td>
<td>1.40</td>
<td>1</td>
<td>1.05</td>
<td>0.51</td>
<td>3.53</td>
</tr>
<tr>
<td>6</td>
<td>77</td>
<td>5</td>
<td>1.70</td>
<td>0</td>
<td>0.72</td>
<td>0.79</td>
<td>3.83</td>
</tr>
<tr>
<td>6</td>
<td>78</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>79</td>
<td>3.50</td>
<td>1</td>
<td>1</td>
<td>2.37</td>
<td>0.87</td>
<td>2.17</td>
</tr>
<tr>
<td>6</td>
<td>80</td>
<td>3.80</td>
<td>1.10</td>
<td>1</td>
<td>2.06</td>
<td>0.56</td>
<td>2.49</td>
</tr>
<tr>
<td>6</td>
<td>81</td>
<td>3.70</td>
<td>1</td>
<td>1</td>
<td>2.19</td>
<td>0.69</td>
<td>2.36</td>
</tr>
<tr>
<td>6</td>
<td>82</td>
<td>3.90</td>
<td>1.20</td>
<td>1</td>
<td>1.92</td>
<td>0.42</td>
<td>2.62</td>
</tr>
<tr>
<td>6</td>
<td>83</td>
<td>5.10</td>
<td>1.60</td>
<td>0</td>
<td>0.69</td>
<td>0.84</td>
<td>3.88</td>
</tr>
<tr>
<td>6</td>
<td>84</td>
<td>4.50</td>
<td>1.50</td>
<td>1</td>
<td>1.25</td>
<td>0.25</td>
<td>3.29</td>
</tr>
<tr>
<td>6</td>
<td>85</td>
<td>4.50</td>
<td>1.60</td>
<td>1</td>
<td>1.21</td>
<td>0.32</td>
<td>3.33</td>
</tr>
<tr>
<td>6</td>
<td>86</td>
<td>4.70</td>
<td>1.50</td>
<td>1</td>
<td>1.08</td>
<td>0.43</td>
<td>3.47</td>
</tr>
<tr>
<td>6</td>
<td>87</td>
<td>4.40</td>
<td>1.30</td>
<td>1</td>
<td>1.44</td>
<td>0.12</td>
<td>3.12</td>
</tr>
<tr>
<td>6</td>
<td>88</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.20</td>
<td>2.84</td>
</tr>
<tr>
<td>6</td>
<td>89</td>
<td>4</td>
<td>1.30</td>
<td>1</td>
<td>1.79</td>
<td>0.30</td>
<td>2.75</td>
</tr>
<tr>
<td>6</td>
<td>90</td>
<td>4.40</td>
<td>1.20</td>
<td>1</td>
<td>1.49</td>
<td>0.19</td>
<td>3.09</td>
</tr>
<tr>
<td>6</td>
<td>91</td>
<td>4.60</td>
<td>1.40</td>
<td>1</td>
<td>1.21</td>
<td>0.31</td>
<td>3.34</td>
</tr>
<tr>
<td>6</td>
<td>92</td>
<td>4</td>
<td>1.20</td>
<td>1</td>
<td>1.83</td>
<td>0.33</td>
<td>2.71</td>
</tr>
<tr>
<td>6</td>
<td>93</td>
<td>3.30</td>
<td>1</td>
<td>1</td>
<td>2.55</td>
<td>1.06</td>
<td>1.99</td>
</tr>
<tr>
<td>6</td>
<td>94</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>2.93</td>
</tr>
<tr>
<td>6</td>
<td>95</td>
<td>4.20</td>
<td>1.20</td>
<td>1</td>
<td>1.66</td>
<td>0.18</td>
<td>2.90</td>
</tr>
<tr>
<td>6</td>
<td>96</td>
<td>4.20</td>
<td>1.30</td>
<td>1</td>
<td>1.61</td>
<td>0.11</td>
<td>2.93</td>
</tr>
<tr>
<td>6</td>
<td>97</td>
<td>4.30</td>
<td>1.30</td>
<td>1</td>
<td>1.52</td>
<td>0.06</td>
<td>3.03</td>
</tr>
<tr>
<td>6</td>
<td>98</td>
<td>3</td>
<td>1.10</td>
<td>1</td>
<td>2.79</td>
<td>1.32</td>
<td>1.76</td>
</tr>
<tr>
<td>6</td>
<td>99</td>
<td>4.10</td>
<td>1.30</td>
<td>1</td>
<td>1.70</td>
<td>0.20</td>
<td>2.84</td>
</tr>
<tr>
<td>6</td>
<td>100</td>
<td>6</td>
<td>2.50</td>
<td>0</td>
<td>0.59</td>
<td>2.05</td>
<td>5.07</td>
</tr>
<tr>
<td>6</td>
<td>101</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.55</td>
<td>0.97</td>
<td>4</td>
</tr>
<tr>
<td>6</td>
<td>102</td>
<td>5.90</td>
<td>2.10</td>
<td>0</td>
<td>0.28</td>
<td>1.77</td>
<td>4.81</td>
</tr>
<tr>
<td>6</td>
<td>103</td>
<td>5.60</td>
<td>1.80</td>
<td>0</td>
<td>0.25</td>
<td>1.38</td>
<td>4.42</td>
</tr>
<tr>
<td>6</td>
<td>104</td>
<td>5.80</td>
<td>2.20</td>
<td>0</td>
<td>0.23</td>
<td>1.73</td>
<td>4.76</td>
</tr>
<tr>
<td>6</td>
<td>105</td>
<td>6.60</td>
<td>2.10</td>
<td>0</td>
<td>0.98</td>
<td>2.42</td>
<td>5.46</td>
</tr>
<tr>
<td>6</td>
<td>106</td>
<td>4.50</td>
<td>1.70</td>
<td>1</td>
<td>1.18</td>
<td>0.40</td>
<td>3.37</td>
</tr>
<tr>
<td>6</td>
<td>107</td>
<td>6.30</td>
<td>1.80</td>
<td>0</td>
<td>0.72</td>
<td>2.06</td>
<td>5.08</td>
</tr>
<tr>
<td>6</td>
<td>108</td>
<td>5.80</td>
<td>1.80</td>
<td>0</td>
<td>0.30</td>
<td>1.57</td>
<td>4.61</td>
</tr>
<tr>
<td>6</td>
<td>109</td>
<td>6.10</td>
<td>2.50</td>
<td>0</td>
<td>0.66</td>
<td>2.14</td>
<td>5.16</td>
</tr>
<tr>
<td>6</td>
<td>110</td>
<td>5.10</td>
<td>2</td>
<td>0</td>
<td>0.53</td>
<td>1.03</td>
<td>4.04</td>
</tr>
<tr>
<td>6</td>
<td>111</td>
<td>5.30</td>
<td>1.90</td>
<td>0</td>
<td>0.36</td>
<td>1.14</td>
<td>4.18</td>
</tr>
<tr>
<td>6</td>
<td>112</td>
<td>5.50</td>
<td>2.10</td>
<td>0</td>
<td>0.14</td>
<td>1.42</td>
<td>4.44</td>
</tr>
<tr>
<td>6</td>
<td>113</td>
<td>5</td>
<td>2</td>
<td>0</td>
<td>0.63</td>
<td>0.95</td>
<td>3.95</td>
</tr>
<tr>
<td>6</td>
<td>114</td>
<td>5.10</td>
<td>2.40</td>
<td>0</td>
<td>0.63</td>
<td>1.32</td>
<td>4.23</td>
</tr>
<tr>
<td>6</td>
<td>115</td>
<td>5.30</td>
<td>2.30</td>
<td>0</td>
<td>0.41</td>
<td>1.38</td>
<td>4.35</td>
</tr>
<tr>
<td>6</td>
<td>116</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.28</td>
<td>1.29</td>
<td>4.33</td>
</tr>
<tr>
<td>6</td>
<td>117</td>
<td>6.70</td>
<td>2.20</td>
<td>0</td>
<td>1.08</td>
<td>2.55</td>
<td>5.59</td>
</tr>
<tr>
<td>6</td>
<td>118</td>
<td>6.90</td>
<td>2.30</td>
<td>0</td>
<td>1.30</td>
<td>2.77</td>
<td>5.81</td>
</tr>
<tr>
<td>6</td>
<td>119</td>
<td>5</td>
<td>1.50</td>
<td>1</td>
<td>0.83</td>
<td>0.72</td>
<td>3.75</td>
</tr>
<tr>
<td>6</td>
<td>120</td>
<td>5.70</td>
<td>2.30</td>
<td>0</td>
<td>0.26</td>
<td>1.69</td>
<td>4.71</td>
</tr>
<tr>
<td>6</td>
<td>121</td>
<td>4.90</td>
<td>2</td>
<td>0</td>
<td>0.73</td>
<td>0.88</td>
<td>3.86</td>
</tr>
<tr>
<td>6</td>
<td>122</td>
<td>6.70</td>
<td>2</td>
<td>0</td>
<td>1.07</td>
<td>2.49</td>
<td>5.52</td>
</tr>
<tr>
<td>6</td>
<td>123</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.77</td>
<td>0.75</td>
<td>3.77</td>
</tr>
<tr>
<td>6</td>
<td>124</td>
<td>5.70</td>
<td>2.10</td>
<td>0</td>
<td>0.09</td>
<td>1.59</td>
<td>4.63</td>
</tr>
<tr>
<td>6</td>
<td>125</td>
<td>6</td>
<td>1.80</td>
<td>0</td>
<td>0.45</td>
<td>1.76</td>
<td>4.80</td>
</tr>
<tr>
<td>6</td>
<td>126</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.86</td>
<td>0.67</td>
<td>3.68</td>
</tr>
<tr>
<td>6</td>
<td>127</td>
<td>4.90</td>
<td>1.80</td>
<td>1</td>
<td>0.77</td>
<td>0.75</td>
<td>3.77</td>
</tr>
<tr>
<td>6</td>
<td>128</td>
<td>5.60</td>
<td>2.10</td>
<td>0</td>
<td>0.06</td>
<td>1.50</td>
<td>4.53</td>
</tr>
<tr>
<td>6</td>
<td>129</td>
<td>5.80</td>
<td>1.60</td>
<td>0</td>
<td>0.48</td>
<td>1.53</td>
<td>4.54</td>
</tr>
<tr>
<td>6</td>
<td>130</td>
<td>6.10</td>
<td>1.90</td>
<td>0</td>
<td>0.50</td>
<td>1.89</td>
<td>4.92</td>
</tr>
<tr>
<td>6</td>
<td>131</td>
<td>6.40</td>
<td>2</td>
<td>0</td>
<td>0.78</td>
<td>2.20</td>
<td>5.24</td>
</tr>
<tr>
<td>6</td>
<td>132</td>
<td>5.60</td>
<td>2.20</td>
<td>0</td>
<td>0.15</td>
<td>1.55</td>
<td>4.58</td>
</tr>
<tr>
<td>6</td>
<td>133</td>
<td>5.10</td>
<td>1.50</td>
<td>0</td>
<td>0.76</td>
<td>0.82</td>
<td>3.85</td>
</tr>
<tr>
<td>6</td>
<td>134</td>
<td>5.60</td>
<td>1.40</td>
<td>0</td>
<td>0.65</td>
<td>1.31</td>
<td>4.30</td>
</tr>
<tr>
<td>6</td>
<td>135</td>
<td>6.10</td>
<td>2.30</td>
<td>0</td>
<td>0.54</td>
<td>2.04</td>
<td>5.07</td>
</tr>
<tr>
<td>6</td>
<td>136</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.35</td>
<td>1.67</td>
<td>4.67</td>
</tr>
<tr>
<td>6</td>
<td>137</td>
<td>5.50</td>
<td>1.80</td>
<td>0</td>
<td>0.28</td>
<td>1.29</td>
<td>4.33</td>
</tr>
<tr>
<td>6</td>
<td>138</td>
<td>4.80</td>
<td>1.80</td>
<td>1</td>
<td>0.86</td>
<td>0.67</td>
<td>3.68</td>
</tr>
<tr>
<td>6</td>
<td>139</td>
<td>5.40</td>
<td>2.10</td>
<td>0</td>
<td>0.23</td>
<td>1.33</td>
<td>4.35</td>
</tr>
<tr>
<td>6</td>
<td>140</td>
<td>5.60</td>
<td>2.40</td>
<td>0</td>
<td>0.35</td>
<td>1.67</td>
<td>4.67</td>
</tr>
<tr>
<td>6</td>
<td>141</td>
<td>5.10</td>
<td>2.30</td>
<td>0</td>
<td>0.58</td>
<td>1.24</td>
<td>4.18</td>
</tr>
<tr>
<td>6</td>
<td>142</td>
<td>5.10</td>
<td>1.90</td>
<td>0</td>
<td>0.55</td>
<td>0.97</td>
<td>4</td>
</tr>
<tr>
<td>6</td>
<td>143</td>
<td>5.90</td>
<td>2.30</td>
<td>0</td>
<td>0.37</td>
<td>1.86</td>
<td>4.89</td>
</tr>
<tr>
<td>6</td>
<td>144</td>
<td>5.70</td>
<td>2.50</td>
<td>0</td>
<td>0.46</td>
<td>1.81</td>
<td>4.80</td>
</tr>
<tr>
<td>6</td>
<td>145</td>
<td>5.20</td>
<td>2.30</td>
<td>0</td>
<td>0.50</td>
<td>1.31</td>
<td>4.27</td>
</tr>
<tr>
<td>6</td>
<td>146</td>
<td>5</td>
<td>1.90</td>
<td>0</td>
<td>0.64</td>
<td>0.89</td>
<td>3.91</td>
</tr>
<tr>
<td>6</td>
<td>147</td>
<td>5.20</td>
<td>2</td>
<td>0</td>
<td>0.43</td>
<td>1.11</td>
<td>4.13</td>
</tr>
<tr>
<td>6</td>
<td>148</td>
<td>5.40</td>
<td>2.30</td>
<td>0</td>
<td>0.34</td>
<td>1.45</td>
<td>4.44</td>
</tr>
<tr>
<td>6</td>
<td>149</td>
<td>5.10</td>
<td>1.80</td>
<td>0</td>
<td>0.58</td>
<td>0.92</td>
<td>3.96</td>
</tr>
</tbody>
</table>
</div>
<h1 id="k-中心点（AMP）"><a href="#k-中心点（AMP）" class="headerlink" title="k-中心点（AMP）"></a>k-中心点（AMP）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.spatial.distance <span class="keyword">import</span> cdist</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> pairwise_distances</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Iris数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data</span><br><span class="line">y = iris.target</span><br><span class="line">features = iris.feature_names</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择用于可视化的两个特征（这里使用花瓣长度和宽度）</span></span><br><span class="line">feature1, feature2 = <span class="number">2</span>, <span class="number">3</span>  <span class="comment"># 可以修改为其他特征组合</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实现PAM算法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">pam_clustering</span>(<span class="params">X, k, max_iter=<span class="number">100</span></span>):</span><br><span class="line">    np.random.seed(<span class="number">42</span>)  <span class="comment"># 设置随机种子，确保每次运行结果一致</span></span><br><span class="line">    n_samples = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 随机选择k个初始medoid 从样本中随机选出 k 个点作为初始 medoids（聚类中心点，但必须是实际样本）</span></span><br><span class="line">    initial_medoids_idx = np.random.choice(n_samples, k, replace=<span class="literal">False</span>)</span><br><span class="line">    medoids = X[initial_medoids_idx]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个点到medoid的欧氏距离并分配簇</span></span><br><span class="line">    <span class="comment">#计算所有样本到每个 medoid 的欧氏距离（返回 150×k 的矩阵）。</span></span><br><span class="line">	<span class="comment">#为每个样本分配距离最近的 medoid（返回一个长度为150的簇编号数组）。</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">assign_clusters</span>(<span class="params">X, medoids</span>):</span><br><span class="line">        distances = cdist(X, medoids, <span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> np.argmin(distances, axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新medoids（选择簇内点距离最小的点）</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update_medoids</span>(<span class="params">X, clusters, k</span>):</span><br><span class="line">        new_medoids = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            <span class="comment"># 取出属于该簇的所有样本点。</span></span><br><span class="line">            cluster_points = X[clusters == i]</span><br><span class="line">            <span class="keyword">if</span> cluster_points.shape[<span class="number">0</span>] &gt; <span class="number">0</span>:</span><br><span class="line">                <span class="comment">#计算它们两两之间的距离矩阵。</span></span><br><span class="line">                dist_matrix = cdist(cluster_points, cluster_points, <span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line">                <span class="comment">#对于每个点，计算其与其他点的距离总和，找出“最小代价”的那个点作为新的 medoid。</span></span><br><span class="line">                cost = dist_matrix.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">                new_medoids.append(cluster_points[np.argmin(cost)])</span><br><span class="line">        <span class="keyword">return</span> np.array(new_medoids)</span><br><span class="line">	</span><br><span class="line">    <span class="comment">#初始分配簇</span></span><br><span class="line">    clusters = assign_clusters(X, medoids)</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(max_iter):</span><br><span class="line">        new_medoids = update_medoids(X, clusters, k)</span><br><span class="line">        new_clusters = assign_clusters(X, new_medoids)</span><br><span class="line">        <span class="keyword">if</span> np.array_equal(new_medoids, medoids):</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">        medoids = new_medoids</span><br><span class="line">        clusters = new_clusters</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> medoids, clusters</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行PAM聚类</span></span><br><span class="line">k = <span class="number">3</span></span><br><span class="line">medoids, clusters = pam_clustering(X, k)</span><br><span class="line"><span class="comment"># 绘制原始数据分布</span></span><br><span class="line">plt.figure(figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 原始数据图</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, feature1], X[:, feature2], c=y, cmap=<span class="string">&#x27;viridis&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度 (cm)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度 (cm)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始鸢尾花数据分布&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制聚类结果</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">plt.scatter(X[:, feature1], X[:, feature2], c=clusters, cmap=<span class="string">&#x27;viridis&#x27;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度 (cm)&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度 (cm)&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;PAM 聚类结果&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 标注中心点（medoids）</span></span><br><span class="line">plt.scatter(medoids[:, feature1], medoids[:, feature2], c=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, s=<span class="number">200</span>, label=<span class="string">&#x27;代表对象&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图"><a href="#运行结果图" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/AMP.png" alt=""></p>
<h2 id="动态图-1"><a href="#动态图-1" class="headerlink" title="动态图"></a>动态图</h2><p><img src="images/pam_animation.gif" alt=""></p>
<h1 id="层次聚类算法"><a href="#层次聚类算法" class="headerlink" title="层次聚类算法"></a>层次聚类算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> dendrogram, linkage</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Iris数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 花瓣长度和花瓣宽度</span></span><br><span class="line">feature_names = iris.feature_names[<span class="number">2</span>:]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成层次聚类的链接矩阵</span></span><br><span class="line">Z = linkage(X, method=<span class="string">&#x27;ward&#x27;</span>, metric=<span class="string">&#x27;euclidean&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化设置</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">8</span>))</span><br><span class="line">plt.title(<span class="string">&#x27;鸢尾花数据集层次聚类树状图&#x27;</span>, fontsize=<span class="number">14</span>, pad=<span class="number">20</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本索引（或簇大小）&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;WARD距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制增强版树状图</span></span><br><span class="line">dendrogram(</span><br><span class="line">    Z,</span><br><span class="line">    truncate_mode=<span class="string">&#x27;lastp&#x27;</span>,  <span class="comment"># 显示最后p个合并的簇</span></span><br><span class="line">    p=<span class="number">12</span>,                   <span class="comment"># 显示最后12次合并</span></span><br><span class="line">    show_leaf_counts=<span class="literal">True</span>,  <span class="comment"># 显示簇包含的样本数</span></span><br><span class="line">    leaf_rotation=<span class="number">90.</span>,      <span class="comment"># 旋转叶子标签</span></span><br><span class="line">    leaf_font_size=<span class="number">8.</span>,      <span class="comment"># 叶子标签字体大小</span></span><br><span class="line">    show_contracted=<span class="literal">True</span>,   <span class="comment"># 显示收缩后的簇大小</span></span><br><span class="line">    color_threshold=<span class="number">2.5</span>     <span class="comment"># 颜色区分阈值</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 获取不同cut高度的聚类结果示例</span></span><br><span class="line"><span class="keyword">from</span> scipy.cluster.hierarchy <span class="keyword">import</span> fcluster</span><br><span class="line"><span class="keyword">for</span> cutoff <span class="keyword">in</span> [<span class="number">2.0</span>, <span class="number">3.5</span>, <span class="number">5.0</span>]:</span><br><span class="line">    clusters = fcluster(Z, cutoff, criterion=<span class="string">&#x27;distance&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n在cut高度 <span class="subst">&#123;cutoff&#125;</span> 时，得到 <span class="subst">&#123;<span class="built_in">len</span>(np.unique(clusters))&#125;</span> 个簇&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 添加距离参考线</span></span><br><span class="line">plt.axhline(y=<span class="number">5</span>, color=<span class="string">&#x27;r&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, linewidth=<span class="number">0.8</span>)</span><br><span class="line">plt.text(<span class="number">5</span>, <span class="number">5</span>, <span class="string">&#x27;推荐分割阈值&#x27;</span>, color=<span class="string">&#x27;r&#x27;</span>, fontsize=<span class="number">9</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示颜色图例</span></span><br><span class="line">plt.gca().collections[-<span class="number">1</span>].set_edgecolor(<span class="string">&#x27;#333333&#x27;</span>)  <span class="comment"># 设置边框颜色</span></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, linestyle=<span class="string">&#x27;:&#x27;</span>, alpha=<span class="number">0.6</span>)        <span class="comment"># 添加横向网格线</span></span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-1"><a href="#运行结果图-1" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>在cut高度 2.0 时，得到 6 个簇</p>
<p>在cut高度 3.5 时，得到 5 个簇</p>
<p>在cut高度 5.0 时，得到 3 个簇</p>
<p><img src="images/cwngci.png" alt=""></p>
<h1 id="层次聚类的BIRCH算法"><a href="#层次聚类的BIRCH算法" class="headerlink" title="层次聚类的BIRCH算法"></a>层次聚类的BIRCH算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> Birch</span><br><span class="line"><span class="comment"># 设置中文字体（可选：防止中文乱码）</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]        <span class="comment"># 使用黑体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>          <span class="comment"># 正常显示负号</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载鸢尾花数据集，只选取花瓣长度和宽度</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, <span class="number">2</span>:<span class="number">4</span>]  <span class="comment"># 花瓣长度和宽度</span></span><br><span class="line">y = iris.target        <span class="comment"># 原始标签</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 BIRCH 算法进行聚类； 最终将数据划分成 3 个簇；控制聚类的紧密程度。较小值会导致更多簇（更精细划分）。</span></span><br><span class="line">birch_model = Birch(n_clusters=<span class="number">3</span>, threshold=<span class="number">0.5</span>)</span><br><span class="line"><span class="comment">#用训练数据 X（特征矩阵）来训练 BIRCH 模型</span></span><br><span class="line"><span class="comment">#BIRCH 会先构造 CF（Clustering Feature）树，然后合并为指定数量的簇。</span></span><br><span class="line">birch_model.fit(X)</span><br><span class="line"><span class="comment">#labels_ 是模型聚类后的结果，是一个长度为 n_samples 的数组。</span></span><br><span class="line">labels = birch_model.labels_</span><br><span class="line"></span><br><span class="line"><span class="comment"># 手动计算每个最终簇的中心点（均值）</span></span><br><span class="line">final_centers = np.array([X[labels == i].mean(axis=<span class="number">0</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建图像和子图</span></span><br><span class="line">fig, axs = plt.subplots(<span class="number">1</span>, <span class="number">2</span>, figsize=(<span class="number">14</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 左图：原始鸢尾花类别</span></span><br><span class="line">axs[<span class="number">0</span>].scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=<span class="string">&#x27;Set1&#x27;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_title(<span class="string">&quot;原始鸢尾花类别&quot;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">axs[<span class="number">0</span>].set_ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">axs[<span class="number">0</span>].grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 右图：BIRCH 聚类结果（显示真实3个中心）</span></span><br><span class="line">axs[<span class="number">1</span>].scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=labels, cmap=<span class="string">&#x27;Set1&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].scatter(final_centers[:, <span class="number">0</span>], final_centers[:, <span class="number">1</span>],</span><br><span class="line">               marker=<span class="string">&#x27;*&#x27;</span>, c=<span class="string">&#x27;red&#x27;</span>, s=<span class="number">200</span>, edgecolors=<span class="string">&#x27;k&#x27;</span>, label=<span class="string">&#x27;簇中心&#x27;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_title(<span class="string">&quot;BIRCH 算法聚类结果&quot;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">axs[<span class="number">1</span>].set_ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">axs[<span class="number">1</span>].legend()</span><br><span class="line">axs[<span class="number">1</span>].grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-2"><a href="#运行结果图-2" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/BIRCH.png" alt=""></p>
<h2 id="动态图-2"><a href="#动态图-2" class="headerlink" title="动态图"></a>动态图</h2><p><img src="images/birch_33.gif" alt=""></p>
<h1 id="概率层次聚类算法"><a href="#概率层次聚类算法" class="headerlink" title="概率层次聚类算法"></a>概率层次聚类算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.stats <span class="keyword">import</span> multivariate_normal</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文字体支持</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据（花瓣长度和宽度）与真实标签</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 使用花瓣长度和宽度</span></span><br><span class="line">y = iris.target  <span class="comment"># 标签</span></span><br><span class="line">n_samples = X.shape[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始每个样本是一个簇</span></span><br><span class="line">clusters = [[i] <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_samples)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 高斯概率函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">compute_prob</span>(<span class="params">cluster</span>):</span><br><span class="line">    data = X[cluster]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(data) &lt; <span class="number">2</span>:<span class="comment">#如果这个聚类中的样本数小于2，无法计算协方差矩阵（至少需要两个样本），因此返回一个很小的概率值 1e-10，表示这个聚类的概率非常小</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1e-10</span></span><br><span class="line">    mean = np.mean(data, axis=<span class="number">0</span>)<span class="comment">#计算当前聚类数据的均值向量，用于高斯分布的 mean 参数。</span></span><br><span class="line">    cov = np.cov(data.T)<span class="comment">#计算协方差矩阵，需要对数据转置，使每一列是一个特征。</span></span><br><span class="line">    <span class="keyword">if</span> np.linalg.det(cov) &lt;= <span class="number">1e-5</span>:</span><br><span class="line">        cov += np.eye(cov.shape[<span class="number">0</span>]) * <span class="number">1e-3</span></span><br><span class="line">    prob = np.prod(multivariate_normal.pdf(data, mean=mean, cov=cov))<span class="comment">#计算每个样本在该高斯分布下的概率密度值</span></span><br><span class="line">    <span class="keyword">return</span> prob</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化每个簇的概率</span></span><br><span class="line">cluster_probs = &#123;i: compute_prob(c) <span class="keyword">for</span> i, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 距离函数：基于概率</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dist</span>(<span class="params">ci, cj</span>):</span><br><span class="line">    ci_idx = clusters[ci]</span><br><span class="line">    cj_idx = clusters[cj]</span><br><span class="line">    union = ci_idx + cj_idx</span><br><span class="line">    p_i, p_j = cluster_probs[ci], cluster_probs[cj]</span><br><span class="line">    p_union = compute_prob(union)</span><br><span class="line">    <span class="keyword">if</span> p_i * p_j == <span class="number">0</span> <span class="keyword">or</span> p_union == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> np.inf</span><br><span class="line">    <span class="keyword">return</span> -np.log(p_union / (p_i * p_j))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 聚类过程</span></span><br><span class="line">target_n_clusters = <span class="number">3</span><span class="comment">#设定目标聚类数目为 3，最终期望将数据分为 3 个聚类。</span></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">len</span>(clusters) &gt; target_n_clusters:<span class="comment">#循环继续执行，直到聚类的数量减少到或小于目标数目</span></span><br><span class="line">    min_dist = np.inf<span class="comment">#初始化最小距离 min_dist 为无穷大</span></span><br><span class="line">    pair = (-<span class="number">1</span>, -<span class="number">1</span>)<span class="comment">#并且初始化 pair 为一个负值元组，表示尚未找到需要合并的两个聚类。</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(clusters)):</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(i + <span class="number">1</span>, <span class="built_in">len</span>(clusters)):</span><br><span class="line">            d = dist(i, j)</span><br><span class="line">            <span class="keyword">if</span> d &lt; min_dist:</span><br><span class="line">                min_dist = d</span><br><span class="line">                pair = (i, j)</span><br><span class="line"></span><br><span class="line">    i, j = pair<span class="comment">#从 pair 中提取出两个聚类的索引 i 和 j，这两个聚类将被合并</span></span><br><span class="line">    new_cluster = clusters[i] + clusters[j]</span><br><span class="line">    clusters.append(new_cluster)</span><br><span class="line">    clusters.pop(<span class="built_in">max</span>(i, j))<span class="comment">#删除已经合并的两个旧的聚类。通过 max(i, j) 和 min(i, j) 来确保无论 i 和 j 的顺序如何，都能删除正确的聚类。</span></span><br><span class="line">    clusters.pop(<span class="built_in">min</span>(i, j))</span><br><span class="line">    cluster_probs = &#123;idx: compute_prob(c) <span class="keyword">for</span> idx, c <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters)&#125;<span class="comment">#对每一个新的聚类 c，通过调用 compute_prob(c) 计算该聚类的概率值（由之前提到的高斯概率函数得到的联合概率密度）。使用字典推导式生成一个字典 cluster_probs，键是聚类的索引，值是每个聚类的概率密度。</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ========== 图像展示 ==========</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">6</span>))</span><br><span class="line">colors = [<span class="string">&#x27;r&#x27;</span>, <span class="string">&#x27;g&#x27;</span>, <span class="string">&#x27;b&#x27;</span>, <span class="string">&#x27;c&#x27;</span>, <span class="string">&#x27;m&#x27;</span>, <span class="string">&#x27;y&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 左图：原始数据（真实类别）</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">3</span>):</span><br><span class="line">    plt.scatter(X[y == i, <span class="number">0</span>], X[y == i, <span class="number">1</span>], color=colors[i], label=<span class="string">f&quot;类别 <span class="subst">&#123;i&#125;</span>&quot;</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;原始数据（按真实类别）&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 右图：聚类结果（每个簇不同颜色）</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> idx, cluster <span class="keyword">in</span> <span class="built_in">enumerate</span>(clusters):</span><br><span class="line">    cluster_points = X[cluster]</span><br><span class="line">    plt.scatter(cluster_points[:, <span class="number">0</span>], cluster_points[:, <span class="number">1</span>],</span><br><span class="line">                color=colors[idx % <span class="built_in">len</span>(colors)], edgecolor=<span class="string">&#x27;k&#x27;</span>, label=<span class="string">f&quot;簇 <span class="subst">&#123;idx + <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;概率层次聚类结果&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;花瓣长度&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;花瓣宽度&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-3"><a href="#运行结果图-3" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/cengcigailv.png" alt=""></p>
<h1 id="密度DBSCAN算法"><a href="#密度DBSCAN算法" class="headerlink" title="密度DBSCAN算法"></a>密度DBSCAN算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算两点之间的欧氏距离</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">euclidean_distance</span>(<span class="params">p1, p2</span>):</span><br><span class="line">    <span class="keyword">return</span> np.linalg.norm(p1 - p2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># DBSCAN核心函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">dbscan</span>(<span class="params">X, eps, MinPts</span>):</span><br><span class="line">    n = <span class="built_in">len</span>(X)</span><br><span class="line">    labels = np.full(n, -<span class="number">1</span>)  <span class="comment"># -1代表噪声点，初始化所有点为噪声</span></span><br><span class="line">    cluster_id = <span class="number">0</span>  <span class="comment"># 聚类编号</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="keyword">if</span> labels[i] != -<span class="number">1</span>:  <span class="comment"># 已经访问过的点跳过</span></span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># 找到当前点的邻域</span></span><br><span class="line">        neighbors = region_query(X, i, eps)</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(neighbors) &lt; MinPts:  <span class="comment"># 如果邻域内点少于MinPts，标记为噪声</span></span><br><span class="line">            labels[i] = -<span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 否则，创建新簇</span></span><br><span class="line">            cluster_id += <span class="number">1</span></span><br><span class="line">            expand_cluster(X, labels, i, neighbors, cluster_id, eps, MinPts)</span><br><span class="line">    <span class="keyword">return</span> labels</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查找某个点的ε邻域</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">region_query</span>(<span class="params">X, p_idx, eps</span>):</span><br><span class="line">    neighbors = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X)):</span><br><span class="line">        <span class="keyword">if</span> euclidean_distance(X[p_idx], X[i]) &lt;= eps:</span><br><span class="line">            neighbors.append(i)</span><br><span class="line">    <span class="keyword">return</span> neighbors</span><br><span class="line"></span><br><span class="line"><span class="comment"># 扩展簇的过程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">expand_cluster</span>(<span class="params">X, labels, p_idx, neighbors, cluster_id, eps, MinPts</span>):</span><br><span class="line">    labels[p_idx] = cluster_id  <span class="comment"># 将p_idx标记为当前簇</span></span><br><span class="line">    i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> i &lt; <span class="built_in">len</span>(neighbors):</span><br><span class="line">        p = neighbors[i]</span><br><span class="line">        <span class="keyword">if</span> labels[p] == -<span class="number">1</span>:  <span class="comment"># 如果该点是噪声点，则将其转为边界点</span></span><br><span class="line">            labels[p] = cluster_id</span><br><span class="line">        <span class="keyword">elif</span> labels[p] == <span class="number">0</span>:  <span class="comment"># 如果该点未被访问</span></span><br><span class="line">            labels[p] = cluster_id</span><br><span class="line">            <span class="comment"># 获取邻域</span></span><br><span class="line">            new_neighbors = region_query(X, p, eps)</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">len</span>(new_neighbors) &gt;= MinPts:  <span class="comment"># 如果邻域内点数大于等于 MinPts，扩展</span></span><br><span class="line">                neighbors += new_neighbors</span><br><span class="line">        i += <span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 使用花瓣长度和宽度</span></span><br><span class="line">true_labels = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择参数</span></span><br><span class="line">eps = <span class="number">1.2</span>  <span class="comment"># 邻域半径</span></span><br><span class="line">MinPts = <span class="number">3</span>  <span class="comment"># 邻域内最小点数</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用自定义的DBSCAN算法</span></span><br><span class="line">clusters = dbscan(X, eps, MinPts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化原始数据和聚类结果</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图1：真实类别分布</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sc1 = plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=<span class="string">&#x27;tab10&#x27;</span>,</span><br><span class="line">                  edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;真实类别分布\n(Iris Species)&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图2：DBSCAN聚类结果</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分核心点和噪声点</span></span><br><span class="line">core_samples_mask = np.zeros_like(clusters, dtype=<span class="built_in">bool</span>)</span><br><span class="line">core_samples_mask[clusters != -<span class="number">1</span>] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取唯一簇标签（不包括噪声点 -1）</span></span><br><span class="line">unique_labels = <span class="built_in">sorted</span>(<span class="built_in">set</span>(clusters))</span><br><span class="line">n_clusters = <span class="built_in">len</span>([label <span class="keyword">for</span> label <span class="keyword">in</span> unique_labels <span class="keyword">if</span> label != -<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 matplotlib colormap 动态生成不同颜色</span></span><br><span class="line">colors = plt.cm.get_cmap(<span class="string">&#x27;tab20&#x27;</span>, n_clusters).colors</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制聚类结果</span></span><br><span class="line"><span class="keyword">for</span> idx, klass <span class="keyword">in</span> <span class="built_in">enumerate</span>(unique_labels):</span><br><span class="line">    <span class="keyword">if</span> klass == -<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 噪声点为灰色</span></span><br><span class="line">        plt.scatter(X[clusters == klass, <span class="number">0</span>], X[clusters == klass, <span class="number">1</span>],</span><br><span class="line">                    c=<span class="string">&#x27;#999999&#x27;</span>, s=<span class="number">100</span>, marker=<span class="string">&#x27;x&#x27;</span>, alpha=<span class="number">0.8</span>,</span><br><span class="line">                    linewidth=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        color = colors[idx % n_clusters]  <span class="comment"># 为每个簇分配不同颜色</span></span><br><span class="line">        <span class="comment"># 核心点</span></span><br><span class="line">        plt.scatter(X[(clusters == klass) &amp; core_samples_mask, <span class="number">0</span>],</span><br><span class="line">                    X[(clusters == klass) &amp; core_samples_mask, <span class="number">1</span>],</span><br><span class="line">                    color=color, s=<span class="number">80</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">                    linewidth=<span class="number">0.5</span>, label=<span class="string">f&#x27;簇<span class="subst">&#123;klass&#125;</span>核心点&#x27;</span>)</span><br><span class="line">        <span class="comment"># 边界点</span></span><br><span class="line">        plt.scatter(X[(clusters == klass) &amp; ~core_samples_mask, <span class="number">0</span>],</span><br><span class="line">                    X[(clusters == klass) &amp; ~core_samples_mask, <span class="number">1</span>],</span><br><span class="line">                    color=color, s=<span class="number">50</span>, marker=<span class="string">&#x27;^&#x27;</span>,</span><br><span class="line">                    edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.6</span>, label=<span class="string">f&#x27;簇<span class="subst">&#123;klass&#125;</span>边界点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">f&#x27;DBSCAN聚类结果\n(eps=<span class="subst">&#123;eps&#125;</span>, min_samples=<span class="subst">&#123;MinPts&#125;</span>)&#x27;</span>,</span><br><span class="line">         fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;花瓣长度&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;花瓣宽度&#x27;</span>, fontsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, fontsize=<span class="number">8</span>)</span><br><span class="line"><span class="comment"># 评估指标</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;发现簇数量: <span class="subst">&#123;n_clusters&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点数量: <span class="subst">&#123;np.<span class="built_in">sum</span>(clusters == -<span class="number">1</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果"><a href="#运行结果" class="headerlink" title="运行结果"></a>运行结果</h2><p>轮廓系数: 0.500<br>ARI指数: 0.575<br>发现簇数量: 4<br>噪声点数量: 0</p>
<p><img src="images/Figure_1999_11.png" alt=""></p>
<h1 id="密度DBSCAN算法（库）"><a href="#密度DBSCAN算法（库）" class="headerlink" title="密度DBSCAN算法（库）"></a>密度DBSCAN算法（库）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载Iris数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 使用花瓣长度和宽度</span></span><br><span class="line">feature_names = iris.feature_names[<span class="number">2</span>:]</span><br><span class="line">true_labels = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 参数优化函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">find_optimal_eps</span>(<span class="params">X, k=<span class="number">5</span></span>):</span><br><span class="line">    <span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> NearestNeighbors</span><br><span class="line">    neighbors = NearestNeighbors(n_neighbors=k) <span class="comment"># 构造近邻模型</span></span><br><span class="line">    neighbors.fit(X)</span><br><span class="line">    distances, _ = neighbors.kneighbors(X)<span class="comment"># 计算每个点到第k近邻的距离</span></span><br><span class="line">    <span class="keyword">return</span> np.sort(distances[:, -<span class="number">1</span>])<span class="comment"># 提取每行的第k个距离，排序后返回</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 自动计算推荐参数</span></span><br><span class="line">distances = find_optimal_eps(X, k=<span class="number">5</span>)<span class="comment"># 找到每个点的第5近邻距离</span></span><br><span class="line">recommended_eps = distances[<span class="built_in">round</span>(<span class="built_in">len</span>(distances)*<span class="number">0.95</span>)]  <span class="comment"># 取95%位置的值</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建DBSCAN模型</span></span><br><span class="line">dbscan = DBSCAN(</span><br><span class="line">    eps=recommended_eps,   <span class="comment">#  # 半径阈值：邻域范围 自动计算的eps值</span></span><br><span class="line">    min_samples=<span class="number">4</span>,         <span class="comment"># 最少样本数，包含自身 根据数据量调整</span></span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>	   <span class="comment"># 使用欧氏距离</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 执行聚类</span></span><br><span class="line">clusters = dbscan.fit_predict(X)<span class="comment"># 拟合模型并返回聚类标签（-1为噪声）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建可视化对比</span></span><br><span class="line">plt.figure(figsize=(<span class="number">16</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 自定义颜色映射（突出噪声点）</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图1：真实类别分布</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</span><br><span class="line">sc1 = plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">                edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;真实类别分布\n(Iris Species)&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 子图2：DBSCAN聚类结果</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 区分核心点和噪声点</span></span><br><span class="line">core_samples_mask = np.zeros_like(clusters, dtype=<span class="built_in">bool</span>)</span><br><span class="line">core_samples_mask[dbscan.core_sample_indices_] = <span class="literal">True</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制不同类别的点</span></span><br><span class="line"><span class="keyword">for</span> klass <span class="keyword">in</span> np.unique(clusters):</span><br><span class="line">    <span class="keyword">if</span> klass == -<span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 噪声点</span></span><br><span class="line">        plt.scatter(X[clusters == klass, <span class="number">0</span>], X[clusters == klass, <span class="number">1</span>],</span><br><span class="line">                    c=<span class="string">&#x27;#999999&#x27;</span>, s=<span class="number">100</span>, marker=<span class="string">&#x27;x&#x27;</span>, alpha=<span class="number">0.8</span>,</span><br><span class="line">                    linewidth=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># 核心点</span></span><br><span class="line">        plt.scatter(X[(clusters == klass) &amp; core_samples_mask, <span class="number">0</span>],</span><br><span class="line">                    X[(clusters == klass) &amp; core_samples_mask, <span class="number">1</span>],</span><br><span class="line">                    c=[cmap(klass+<span class="number">1</span>)], s=<span class="number">80</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">                    linewidth=<span class="number">0.5</span>, label=<span class="string">f&#x27;簇<span class="subst">&#123;klass&#125;</span>核心点&#x27;</span>)</span><br><span class="line">        <span class="comment"># 边界点</span></span><br><span class="line">        plt.scatter(X[(clusters == klass) &amp; ~core_samples_mask, <span class="number">0</span>],</span><br><span class="line">                    X[(clusters == klass) &amp; ~core_samples_mask, <span class="number">1</span>],</span><br><span class="line">                    c=[cmap(klass+<span class="number">1</span>)], s=<span class="number">50</span>, marker=<span class="string">&#x27;^&#x27;</span>,</span><br><span class="line">                    edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.6</span>, label=<span class="string">f&#x27;簇<span class="subst">&#123;klass&#125;</span>边界点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">f&#x27;DBSCAN聚类结果\n(eps=<span class="subst">&#123;recommended_eps:<span class="number">.2</span>f&#125;</span>, min_samples=4)&#x27;</span>,</span><br><span class="line">         fontsize=<span class="number">12</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">10</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.4</span>)</span><br><span class="line">plt.legend(loc=<span class="string">&#x27;upper right&#x27;</span>, fontsize=<span class="number">8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估指标</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;发现簇数量: <span class="subst">&#123;<span class="built_in">len</span>(np.unique(clusters)) - <span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点数量: <span class="subst">&#123;np.<span class="built_in">sum</span>(clusters == -<span class="number">1</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-4"><a href="#运行结果图-4" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/OBSC_44.png" alt=""></p>
<p>轮廓系数: 0.767<br>ARI指数: 0.568<br>发现簇数量: 2<br>噪声点数量: 0</p>
<h2 id="随机数据集"><a href="#随机数据集" class="headerlink" title="随机数据集"></a>随机数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> DBSCAN</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置中文显示</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成模拟数据</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X, true_labels = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 应用 DBSCAN</span></span><br><span class="line">dbscan = DBSCAN(eps=<span class="number">0.5</span>, min_samples=<span class="number">5</span>)</span><br><span class="line">clusters = dbscan.fit_predict(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 唯一标签集合（包括噪声点 -1）</span></span><br><span class="line">unique_labels = <span class="built_in">set</span>(clusters)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 tab10 色系（鲜明、对比强）</span></span><br><span class="line">colors = plt.cm.tab10(np.linspace(<span class="number">0</span>, <span class="number">1</span>, <span class="built_in">len</span>(unique_labels)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘图</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line"><span class="keyword">for</span> k, col <span class="keyword">in</span> <span class="built_in">zip</span>(unique_labels, colors):</span><br><span class="line">    <span class="keyword">if</span> k == -<span class="number">1</span>:</span><br><span class="line">        col = [<span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]  <span class="comment"># 红色表示噪声点</span></span><br><span class="line">        label_name = <span class="string">&#x27;噪声点&#x27;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        label_name = <span class="string">f&#x27;簇 <span class="subst">&#123;k&#125;</span>&#x27;</span></span><br><span class="line"></span><br><span class="line">    class_member_mask = (clusters == k)</span><br><span class="line">    xy = X[class_member_mask]</span><br><span class="line">    plt.plot(xy[:, <span class="number">0</span>], xy[:, <span class="number">1</span>], <span class="string">&#x27;o&#x27;</span>,</span><br><span class="line">             markerfacecolor=<span class="built_in">tuple</span>(col),</span><br><span class="line">             markeredgecolor=<span class="string">&#x27;k&#x27;</span>,</span><br><span class="line">             markersize=<span class="number">6</span>,</span><br><span class="line">             label=label_name)</span><br><span class="line"><span class="comment"># 评估指标</span></span><br><span class="line">n_clusters = <span class="built_in">len</span>(<span class="built_in">set</span>(clusters)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> clusters <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, clusters):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;发现簇数量: <span class="subst">&#123;n_clusters&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点数量: <span class="subst">&#123;np.<span class="built_in">sum</span>(clusters == -<span class="number">1</span>)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&quot;DBSCAN 聚类结果&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;特征 1&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;特征 2&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>轮廓系数: 0.630<br>ARI指数: 0.914<br>发现簇数量: 4<br>噪声点数量: 18</p>
<h2 id="运行结果图-5"><a href="#运行结果图-5" class="headerlink" title="运行结果图"></a>运行结果图</h2><p><img src="images/Figure_2025_5_27.png" alt=""></p>
<h1 id="密度OPTICS算法"><a href="#密度OPTICS算法" class="headerlink" title="密度OPTICS算法"></a>密度OPTICS算法</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> OPTICS</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示配置</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载并准备数据</span></span><br><span class="line">iris = load_iris()</span><br><span class="line">X = iris.data[:, [<span class="number">2</span>, <span class="number">3</span>]]  <span class="comment"># 花瓣长度和宽度</span></span><br><span class="line">feature_names = [n.replace(<span class="string">&#x27; (cm)&#x27;</span>, <span class="string">&#x27;&#x27;</span>) <span class="keyword">for</span> n <span class="keyword">in</span> iris.feature_names[<span class="number">2</span>:]]</span><br><span class="line">true_labels = iris.target</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建OPTICS模型</span></span><br><span class="line">optics_model = OPTICS(</span><br><span class="line">    min_samples=<span class="number">4</span>,<span class="comment">#定义一个点成为核心点所需的最小邻域样本数</span></span><br><span class="line">    xi=<span class="number">0.05</span>,<span class="comment">#控制簇边界识别的灵敏度，通过可达距离图中的“波谷”深度判定簇</span></span><br><span class="line">    min_cluster_size=<span class="number">0.15</span>,<span class="comment">#定义最小簇规模，低于此规模的簇将被视为噪声</span></span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>,<span class="comment">#定义计算样本间距离的度量方法</span></span><br><span class="line">    cluster_method=<span class="string">&#x27;xi&#x27;</span><span class="comment">#指定从可达距离图中提取簇的方法</span></span><br><span class="line">).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 替换原来的 OPTICS 配置</span></span><br><span class="line"><span class="comment"># optics_model = OPTICS(</span></span><br><span class="line"><span class="comment">#     min_samples=5,</span></span><br><span class="line"><span class="comment">#     xi=0.03,</span></span><br><span class="line"><span class="comment">#     min_cluster_size=0.1,</span></span><br><span class="line"><span class="comment">#     metric=&#x27;euclidean&#x27;,</span></span><br><span class="line"><span class="comment">#     cluster_method=&#x27;xi&#x27;</span></span><br><span class="line"><span class="comment"># ).fit(X)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色配置</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>])</span><br><span class="line">cluster_labels = np.where(optics_model.labels_ == -<span class="number">1</span>, <span class="number">0</span>, optics_model.labels_+<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第一大图：分析视图（1行3列）</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图1：原始数据分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据分布&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图2：可达距离排序图 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">space = np.arange(<span class="built_in">len</span>(X))</span><br><span class="line">reachability = optics_model.reachability_[optics_model.ordering_]</span><br><span class="line">labels = optics_model.labels_[optics_model.ordering_]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建颜色映射（排除噪声点）</span></span><br><span class="line">colors = [cmap(l+<span class="number">1</span>) <span class="keyword">if</span> l != -<span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;#999999&#x27;</span> <span class="keyword">for</span> l <span class="keyword">in</span> labels]</span><br><span class="line"></span><br><span class="line">plt.bar(space, reachability, color=colors, width=<span class="number">0.8</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.plot(reachability, color=<span class="string">&#x27;#2c3e50&#x27;</span>, linewidth=<span class="number">1.2</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;可达距离排序图&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本排序序号&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylim(top=np.percentile(reachability, <span class="number">95</span>)*<span class="number">1.1</span>)  <span class="comment"># 自动调整Y轴上限</span></span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图3：聚类结果分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">noise_mask = (optics_model.labels_ == -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[~noise_mask, <span class="number">0</span>], X[~noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=cluster_labels[~noise_mask], cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;#999999&#x27;</span>, marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">100</span>, linewidths=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;OPTICS聚类结果&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第二大图：三维可视化</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 三维散点图</span></span><br><span class="line">sc = ax.scatter3D(</span><br><span class="line">    X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], optics_model.reachability_,</span><br><span class="line">    c=cluster_labels, cmap=cmap,</span><br><span class="line">    s=<span class="number">50</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.8</span>, depthshade=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 坐标轴设置</span></span><br><span class="line">ax.set_xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;三维特征空间可视化&#x27;</span>, fontsize=<span class="number">16</span>, pad=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色条设置</span></span><br><span class="line">cbar = plt.colorbar(sc, pad=<span class="number">0.1</span>)</span><br><span class="line">cbar.set_ticks([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line">cbar.set_ticklabels([<span class="string">&#x27;噪声&#x27;</span>, <span class="string">&#x27;簇 1&#x27;</span>, <span class="string">&#x27;簇 2&#x27;</span>, <span class="string">&#x27;簇 3&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 视角设置</span></span><br><span class="line">ax.view_init(elev=<span class="number">25</span>, azim=-<span class="number">45</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 性能评估 ==================</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n【性能评估】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数（越接近 1，聚类效果越好（点紧密集中在各自簇内，簇之间分得开））: <span class="subst">&#123;silhouette_score(X, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数（聚类结果与真实标签完全匹配，1 表示完全一致（）: <span class="subst">&#123;adjusted_rand_score(true_labels, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;检测到簇数量: <span class="subst">&#123;<span class="built_in">len</span>(np.unique(optics_model.labels_))-<span class="number">1</span>&#125;</span>个&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点比例: <span class="subst">&#123;np.mean(optics_model.labels_ == -<span class="number">1</span>):<span class="number">.1</span>%&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-6"><a href="#运行结果图-6" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>【性能评估】<br>轮廓系数（越接近 1，聚类效果越好（点紧密集中在各自簇内，簇之间分得开））: 0.576<br>ARI指数（聚类结果与真实标签完全匹配，1 表示完全一致（）: 0.643<br>检测到簇数量: 2个<br>噪声点比例: 27.3%</p>
<p><img src="images/Figure_4499.png" alt=""></p>
<p><img src="images/Figure_44999.png" alt=""></p>
<p>【性能评估】<br>轮廓系数（越接近 1，聚类效果越好）: 0.260<br>ARI指数（聚类结果与真实标签匹配度）: 0.538<br>检测到簇数量: 3 个<br>噪声点比例: 46.0%</p>
<p><img src="images/Figure_3399.png" alt=""></p>
<p><img src="images/Figure_33999.png" alt=""></p>
<h2 id="随机数据集-1"><a href="#随机数据集-1" class="headerlink" title="随机数据集"></a>随机数据集</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> OPTICS</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示配置</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 生成模拟数据（4个簇，2维）</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X, true_labels = make_blobs(n_samples=<span class="number">300</span>, centers=<span class="number">4</span>, cluster_std=<span class="number">0.60</span>, random_state=<span class="number">0</span>)</span><br><span class="line">feature_names = [<span class="string">&#x27;特征 1&#x27;</span>, <span class="string">&#x27;特征 2&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建OPTICS模型</span></span><br><span class="line">optics_model = OPTICS(</span><br><span class="line">    min_samples=<span class="number">5</span>,</span><br><span class="line">    xi=<span class="number">0.08</span>,</span><br><span class="line">    min_cluster_size=<span class="number">0.1</span>,</span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>,</span><br><span class="line">    cluster_method=<span class="string">&#x27;xi&#x27;</span></span><br><span class="line">).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色配置（第一个为灰色，用于噪声）</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>, <span class="string">&#x27;#FFD700&#x27;</span>])</span><br><span class="line">cluster_labels = np.where(optics_model.labels_ == -<span class="number">1</span>, <span class="number">0</span>, optics_model.labels_ + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第一大图：分析视图（1行3列）</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图1：原始数据分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;原始数据分布（真实标签）&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图2：可达距离排序图 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">space = np.arange(<span class="built_in">len</span>(X))</span><br><span class="line">reachability = optics_model.reachability_[optics_model.ordering_]</span><br><span class="line">labels = optics_model.labels_[optics_model.ordering_]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建颜色映射（包括噪声）</span></span><br><span class="line">colors = [cmap(l + <span class="number">1</span>) <span class="keyword">if</span> l != -<span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;#999999&#x27;</span> <span class="keyword">for</span> l <span class="keyword">in</span> labels]</span><br><span class="line"></span><br><span class="line">plt.bar(space, reachability, color=colors, width=<span class="number">0.8</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.plot(reachability, color=<span class="string">&#x27;#2c3e50&#x27;</span>, linewidth=<span class="number">1.2</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;可达距离排序图&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本排序序号&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylim(top=np.percentile(reachability, <span class="number">95</span>) * <span class="number">1.1</span>)</span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图3：聚类结果分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">noise_mask = (optics_model.labels_ == -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[~noise_mask, <span class="number">0</span>], X[~noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=cluster_labels[~noise_mask], cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;#999999&#x27;</span>, marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">100</span>, linewidths=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;OPTICS聚类结果&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第二大图：三维可视化</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">sc = ax.scatter3D(</span><br><span class="line">    X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], optics_model.reachability_,</span><br><span class="line">    c=cluster_labels, cmap=cmap,</span><br><span class="line">    s=<span class="number">50</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.8</span>, depthshade=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;三维特征空间可视化&#x27;</span>, fontsize=<span class="number">16</span>, pad=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色条设置</span></span><br><span class="line">num_clusters = <span class="built_in">len</span>(<span class="built_in">set</span>(optics_model.labels_)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> optics_model.labels_ <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">cbar = plt.colorbar(sc, pad=<span class="number">0.1</span>)</span><br><span class="line">cbar.set_ticks(np.arange(<span class="number">0</span>, num_clusters + <span class="number">1</span>))</span><br><span class="line">cbar.set_ticklabels([<span class="string">&#x27;噪声&#x27;</span>] + [<span class="string">f&#x27;簇 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_clusters)])</span><br><span class="line"></span><br><span class="line">ax.view_init(elev=<span class="number">25</span>, azim=-<span class="number">45</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 性能评估 ==================</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n【性能评估】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;检测到簇数量: <span class="subst">&#123;num_clusters&#125;</span> 个&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点比例: <span class="subst">&#123;np.mean(optics_model.labels_ == -<span class="number">1</span>):<span class="number">.1</span>%&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-7"><a href="#运行结果图-7" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>【性能评估】<br>轮廓系数: 0.460<br>ARI指数: 0.731<br>检测到簇数量: 4 个<br>噪声点比例: 20.0%</p>
<p><img src="images/suijiOPTICS.png" alt=""></p>
<p><img src="images/suijiOPTICS_2.png" alt=""></p>
<h2 id="最符合的随机数据"><a href="#最符合的随机数据" class="headerlink" title="最符合的随机数据"></a>最符合的随机数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> OPTICS</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> matplotlib.colors <span class="keyword">import</span> ListedColormap</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> silhouette_score, adjusted_rand_score</span><br><span class="line"><span class="keyword">import</span> matplotlib</span><br><span class="line"><span class="keyword">from</span> mpl_toolkits.mplot3d <span class="keyword">import</span> Axes3D</span><br><span class="line"></span><br><span class="line"><span class="comment"># 中文显示配置</span></span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]</span><br><span class="line">matplotlib.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 生成更优的模拟数据 ==================</span></span><br><span class="line">np.random.seed(<span class="number">0</span>)</span><br><span class="line">X, true_labels = make_blobs(</span><br><span class="line">    n_samples=<span class="number">300</span>,</span><br><span class="line">    centers=<span class="number">4</span>,</span><br><span class="line">    cluster_std=<span class="number">0.45</span>,          <span class="comment"># 降低标准差</span></span><br><span class="line">    center_box=(-<span class="number">15</span>, <span class="number">15</span>),      <span class="comment"># 扩大中心范围</span></span><br><span class="line">    random_state=<span class="number">0</span></span><br><span class="line">)</span><br><span class="line">feature_names = [<span class="string">&#x27;特征 1&#x27;</span>, <span class="string">&#x27;特征 2&#x27;</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 优化后的OPTICS模型 ==================</span></span><br><span class="line">optics_model = OPTICS(</span><br><span class="line">    min_samples=<span class="number">10</span>,            <span class="comment"># 增加核心点判定样本量</span></span><br><span class="line">    xi=<span class="number">0.1</span>,                    <span class="comment"># 调整簇边界阈值</span></span><br><span class="line">    min_cluster_size=<span class="number">20</span>,       <span class="comment"># 绝对数值定义最小簇</span></span><br><span class="line">    metric=<span class="string">&#x27;euclidean&#x27;</span>,</span><br><span class="line">    cluster_method=<span class="string">&#x27;xi&#x27;</span>        <span class="comment"># 保持xi聚类方法</span></span><br><span class="line">).fit(X)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色配置（第一个为灰色，用于噪声）</span></span><br><span class="line">cmap = ListedColormap([<span class="string">&#x27;#999999&#x27;</span>, <span class="string">&#x27;#FF6B6B&#x27;</span>, <span class="string">&#x27;#4ECDC4&#x27;</span>, <span class="string">&#x27;#45B7D1&#x27;</span>, <span class="string">&#x27;#FFD700&#x27;</span>])</span><br><span class="line">cluster_labels = np.where(optics_model.labels_ == -<span class="number">1</span>, <span class="number">0</span>, optics_model.labels_ + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第一大图：分析视图（1行3列）</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">20</span>, <span class="number">6</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图1：原始数据分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=true_labels, cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;优化后的数据分布（真实标签）&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图2：可达距离排序图 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">2</span>)</span><br><span class="line">space = np.arange(<span class="built_in">len</span>(X))</span><br><span class="line">reachability = optics_model.reachability_[optics_model.ordering_]</span><br><span class="line">labels = optics_model.labels_[optics_model.ordering_]</span><br><span class="line"></span><br><span class="line">colors = [cmap(l + <span class="number">1</span>) <span class="keyword">if</span> l != -<span class="number">1</span> <span class="keyword">else</span> <span class="string">&#x27;#999999&#x27;</span> <span class="keyword">for</span> l <span class="keyword">in</span> labels]</span><br><span class="line">plt.bar(space, reachability, color=colors, width=<span class="number">0.8</span>, alpha=<span class="number">0.8</span>)</span><br><span class="line">plt.plot(reachability, color=<span class="string">&#x27;#2c3e50&#x27;</span>, linewidth=<span class="number">1.2</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;可达距离排序图（优化后）&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;样本排序序号&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylim(top=np.percentile(reachability, <span class="number">95</span>) * <span class="number">1.1</span>)</span><br><span class="line">plt.grid(axis=<span class="string">&#x27;y&#x27;</span>, ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ---- 子图3：聚类结果分布 ----</span></span><br><span class="line">plt.subplot(<span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line">noise_mask = (optics_model.labels_ == -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">plt.scatter(X[~noise_mask, <span class="number">0</span>], X[~noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=cluster_labels[~noise_mask], cmap=cmap,</span><br><span class="line">            edgecolor=<span class="string">&#x27;k&#x27;</span>, s=<span class="number">60</span>, alpha=<span class="number">0.9</span>)</span><br><span class="line">plt.scatter(X[noise_mask, <span class="number">0</span>], X[noise_mask, <span class="number">1</span>],</span><br><span class="line">            c=<span class="string">&#x27;#999999&#x27;</span>, marker=<span class="string">&#x27;X&#x27;</span>, s=<span class="number">100</span>, linewidths=<span class="number">1.5</span>, label=<span class="string">&#x27;噪声点&#x27;</span>)</span><br><span class="line"></span><br><span class="line">plt.title(<span class="string">&#x27;优化后的OPTICS聚类&#x27;</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(ls=<span class="string">&#x27;--&#x27;</span>, alpha=<span class="number">0.3</span>)</span><br><span class="line"></span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line"><span class="comment"># 第二大图：三维可视化</span></span><br><span class="line"><span class="comment"># ==================================================</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">ax = plt.axes(projection=<span class="string">&#x27;3d&#x27;</span>)</span><br><span class="line"></span><br><span class="line">sc = ax.scatter3D(</span><br><span class="line">    X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], optics_model.reachability_,</span><br><span class="line">    c=cluster_labels, cmap=cmap,</span><br><span class="line">    s=<span class="number">50</span>, edgecolor=<span class="string">&#x27;k&#x27;</span>, alpha=<span class="number">0.8</span>, depthshade=<span class="literal">False</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">ax.set_xlabel(feature_names[<span class="number">0</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_ylabel(feature_names[<span class="number">1</span>], fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_zlabel(<span class="string">&#x27;可达距离&#x27;</span>, fontsize=<span class="number">12</span>, labelpad=<span class="number">10</span>)</span><br><span class="line">ax.set_title(<span class="string">&#x27;三维特征空间可视化（优化后）&#x27;</span>, fontsize=<span class="number">16</span>, pad=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 颜色条设置</span></span><br><span class="line">num_clusters = <span class="built_in">len</span>(<span class="built_in">set</span>(optics_model.labels_)) - (<span class="number">1</span> <span class="keyword">if</span> -<span class="number">1</span> <span class="keyword">in</span> optics_model.labels_ <span class="keyword">else</span> <span class="number">0</span>)</span><br><span class="line">cbar = plt.colorbar(sc, pad=<span class="number">0.1</span>)</span><br><span class="line">cbar.set_ticks(np.arange(<span class="number">0</span>, num_clusters + <span class="number">1</span>))</span><br><span class="line">cbar.set_ticklabels([<span class="string">&#x27;噪声&#x27;</span>] + [<span class="string">f&#x27;簇 <span class="subst">&#123;i + <span class="number">1</span>&#125;</span>&#x27;</span> <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_clusters)])</span><br><span class="line"></span><br><span class="line">ax.view_init(elev=<span class="number">25</span>, azim=-<span class="number">45</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ================== 性能评估（排除噪声）==================</span></span><br><span class="line">valid_labels = optics_model.labels_ != -<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n【优化后性能评估】&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;轮廓系数: <span class="subst">&#123;silhouette_score(X[valid_labels], optics_model.labels_[valid_labels]):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;ARI指数: <span class="subst">&#123;adjusted_rand_score(true_labels, optics_model.labels_):<span class="number">.3</span>f&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;检测到簇数量: <span class="subst">&#123;num_clusters&#125;</span> 个&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;噪声点比例: <span class="subst">&#123;np.mean(optics_model.labels_ == -<span class="number">1</span>):<span class="number">.1</span>%&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="运行结果图-8"><a href="#运行结果图-8" class="headerlink" title="运行结果图"></a>运行结果图</h2><p>【优化后性能评估】<br>轮廓系数: 0.841<br>ARI指数: 1.000<br>检测到簇数量: 4 个<br>噪声点比例: 0.0%</p>
<p><img src="images/suijiOP.png" alt=""></p>
<p><img src="images/suijiOP_2.png" alt=""></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2025/04/11/%E8%93%9D%E6%A1%A5%E6%9D%AF/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/04/11/%E8%93%9D%E6%A1%A5%E6%9D%AF/" class="post-title-link" itemprop="url">蓝桥杯</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-04-11 16:42:36 / 修改时间：16:55:50" itemprop="dateCreated datePublished" datetime="2025-04-11T16:42:36+08:00">2025-04-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C/" itemprop="url" rel="index"><span itemprop="name">C++</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="读取文件"><a href="#读取文件" class="headerlink" title="读取文件"></a>读取文件</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;fstream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;sstream&gt;</span>  <span class="comment">// 用于字符串流处理</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ifstream inflie;</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; arr2D;  <span class="comment">// 二维数组容器</span></span><br><span class="line"></span><br><span class="line">    inflie.<span class="built_in">open</span>(<span class="string">&quot;C:\\Users\\liujun\\Desktop\\ttyy.txt&quot;</span>, ios::in);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查文件是否成功打开</span></span><br><span class="line">    <span class="keyword">if</span> (!inflie.<span class="built_in">is_open</span>()) &#123;</span><br><span class="line">        cerr &lt;&lt; <span class="string">&quot;无法打开文件！&quot;</span> &lt;&lt; endl;</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    string line;</span><br><span class="line">    <span class="comment">// 逐行读取文件内容</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">getline</span>(inflie, line)) &#123;</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; row;        <span class="comment">// 存储当前行的数据</span></span><br><span class="line">        <span class="function">istringstream <span class="title">iss</span><span class="params">(line)</span></span>;</span><br><span class="line">        <span class="type">int</span> num;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 从当前行中提取数字并存入 row</span></span><br><span class="line">        <span class="keyword">while</span> (iss &gt;&gt; num) &#123;</span><br><span class="line">            row.<span class="built_in">push_back</span>(num);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 避免将空行加入二维数组</span></span><br><span class="line">        <span class="keyword">if</span> (!row.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">            arr2D.<span class="built_in">push_back</span>(row);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    inflie.<span class="built_in">close</span>();  <span class="comment">// 关闭文件</span></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 可选：打印二维数组内容验证结果</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">const</span> <span class="keyword">auto</span>&amp; row : arr2D) &#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> num : row) &#123;</span><br><span class="line">            cout &lt;&lt; num &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="回文"><a href="#回文" class="headerlink" title="回文"></a>回文</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 判断单个数字字符串是否是有效回文数</span></span><br><span class="line"><span class="function"><span class="type">bool</span> <span class="title">isPalindromeNumber</span><span class="params">(<span class="type">const</span> string&amp; s)</span> </span>&#123;</span><br><span class="line">    <span class="type">int</span> n = s.<span class="built_in">size</span>();</span><br><span class="line">    <span class="keyword">if</span> (n == <span class="number">0</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查是否全为数字</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) &#123;         <span class="comment">// 修改为传统循环</span></span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">isdigit</span>(s[i])) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 处理前导零（长度&gt;1时不能以0开头）</span></span><br><span class="line">    <span class="keyword">if</span> (n &gt; <span class="number">1</span> &amp;&amp; s[<span class="number">0</span>] == <span class="string">&#x27;0&#x27;</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 检查回文</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n / <span class="number">2</span>; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (s[i] != s[n - <span class="number">1</span> - i]) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// 从混合字符串中提取所有连续的数字子串</span></span><br><span class="line"><span class="function">vector&lt;string&gt; <span class="title">extractNumberSubstrings</span><span class="params">(<span class="type">const</span> string&amp; s)</span> </span>&#123;</span><br><span class="line">    vector&lt;string&gt; numbers;</span><br><span class="line">    string current;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; s.<span class="built_in">size</span>(); i++) &#123;  <span class="comment">// 修改为传统循环</span></span><br><span class="line">        <span class="type">char</span> c = s[i];</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isdigit</span>(c)) &#123;</span><br><span class="line">            current += c;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (!current.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">                numbers.<span class="built_in">push_back</span>(current);</span><br><span class="line">                current.<span class="built_in">clear</span>();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 处理末尾可能的剩余数字</span></span><br><span class="line">    <span class="keyword">if</span> (!current.<span class="built_in">empty</span>()) &#123;</span><br><span class="line">        numbers.<span class="built_in">push_back</span>(current);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> numbers;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    string input = <span class="string">&quot;abc121def33gh78not98900dd00900&quot;</span>;</span><br><span class="line">    vector&lt;string&gt; numberSubstrings = <span class="built_in">extractNumberSubstrings</span>(input);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">size_t</span> i = <span class="number">0</span>; i &lt; numberSubstrings.<span class="built_in">size</span>(); i++) &#123;  <span class="comment">// 修改为传统循环</span></span><br><span class="line">        <span class="type">const</span> string&amp; numStr = numberSubstrings[i];</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">isPalindromeNumber</span>(numStr)) &#123;</span><br><span class="line">            cout &lt;&lt; numStr &lt;&lt; <span class="string">&quot; 是回文数&quot;</span> &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            cout &lt;&lt; numStr &lt;&lt; <span class="string">&quot; 不是回文数&quot;</span> &lt;&lt; endl;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h1 id="快排找最小数"><a href="#快排找最小数" class="headerlink" title="快排找最小数"></a>快排找最小数</h1><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="type">const</span> <span class="type">int</span> N = <span class="number">100010</span>;</span><br><span class="line"><span class="type">int</span> n, k;</span><br><span class="line"><span class="type">int</span> q[N];</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">quick_sort</span><span class="params">(<span class="type">int</span> l, <span class="type">int</span> r, <span class="type">int</span> k)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (l &gt;= r) <span class="keyword">return</span> q[l];  <span class="comment">// 这里修正为 q[l]</span></span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> x = q[l], i = l - <span class="number">1</span>, j = r + <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">while</span> (i &lt; j) &#123;</span><br><span class="line">        <span class="keyword">while</span> (q[++i] &lt; x);  <span class="comment">// 找到大于等于 x 的元素</span></span><br><span class="line">        <span class="keyword">while</span> (q[--j] &gt; x);  <span class="comment">// 找到小于等于 x 的元素</span></span><br><span class="line">        <span class="keyword">if</span> (i &lt; j) <span class="built_in">swap</span>(q[i], q[j]);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="type">int</span> s1 = j - l + <span class="number">1</span>;  <span class="comment">// 计算左侧部分元素个数</span></span><br><span class="line">    <span class="keyword">if</span> (k &lt;= s1) <span class="keyword">return</span> <span class="built_in">quick_sort</span>(l, j, k);     <span class="comment">// 递归左侧</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">quick_sort</span>(j + <span class="number">1</span>, r, k - s1);         <span class="comment">// 递归右侧</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    cin &gt;&gt; n &gt;&gt; k;</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; n; i++) cin &gt;&gt; q[i];</span><br><span class="line"></span><br><span class="line">    cout &lt;&lt; <span class="built_in">quick_sort</span>(<span class="number">0</span>, n - <span class="number">1</span>, k) &lt;&lt; endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="vector-常用基础操作"><a href="#vector-常用基础操作" class="headerlink" title="vector 常用基础操作"></a>vector 常用基础操作</h2><p>以下列出了添加元素、查询、索引、赋值、比较等常用操作方法：</p>
<ul>
<li><code>v.empty()</code>：如果 v 为空则返回 true，否则返回 false。</li>
<li><code>v.size()</code>：返回 v 中元素的个数。</li>
<li><code>v.push_back(val)</code>：向 vector 的尾端添加值为 val 的元素。注意：vector 不支持 <code>push_front</code> 操作。</li>
<li><code>v.pop_back()</code>：删除尾元素，返回 void。vector 同样不支持 <code>pop_front</code> 操作。若想在同时弹出元素的值，就必须在执行弹出之前保存它（可以使用 <code>v.back()</code>）。</li>
<li><code>v[n]</code>：返回 v 中第 n 个位置上元素的引用，不能用下标操作添加元素。</li>
<li><code>v.back()</code>：返回 v 中最后一个元素的引用。</li>
<li><code>v.front()</code>：返回 v 中第一个元素的引用。</li>
<li><code>v1 = v2</code>：用 v2 中的元素替换 v1 中的元素。</li>
<li><code>v1 = &#123;a, b, c...&#125;</code>：用元素 {a, b, c…} 替换 v1 中的元素。</li>
<li><code>v1 == v2</code>：当且仅当拥有相同数量且相同位置上值相同的元素时，v1 与 v2 相等。</li>
<li><code>v1 != v2</code>：当 v1 与 v2 不相等时返回 true。</li>
<li><code>&lt;, &lt;=, &gt;, &gt;=</code>：以字典序进行比较。</li>
</ul>
<hr>
<h2 id="使用迭代器的遍历、插入、删除操作"><a href="#使用迭代器的遍历、插入、删除操作" class="headerlink" title="使用迭代器的遍历、插入、删除操作"></a>使用迭代器的遍历、插入、删除操作</h2><p>迭代器类似于指针，提供了对象的间接访问，但获取迭代器并不是使用取地址符。如果将指针理解为元素的“地址”，那么迭代器可以理解为元素的“位置”。可以使用迭代器访问某个元素，迭代器也能从一个元素移动到另一个元素。</p>
<p>一个迭代器的范围由一对迭代器表示，分别为 begin 和 end。其中 begin 成员返回指向第一个元素的迭代器；end 成员返回容器最后一个元素的下一个位置（one past the end），也就是指向一个根本不存在的尾后位置，这样的迭代器没什么实际含义，仅是个标记而已，表示已经处理完了容器中的所有元素。所以 begin 和 end 表示的是一个左闭右开的区间 [ begin , end)</p>
<p>迭代器可以用来实现容器的遍历、插入等操作，可以细品下面的例子：</p>
<h3 id="遍历"><a href="#遍历" class="headerlink" title="遍历"></a>遍历</h3><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    vector&lt;string&gt; a&#123;<span class="string">&quot;0&quot;</span>, <span class="string">&quot;1&quot;</span>, <span class="string">&quot;2&quot;</span>, <span class="string">&quot;3&quot;</span>, <span class="string">&quot;4&quot;</span>, <span class="string">&quot;5&quot;</span>, <span class="string">&quot;6&quot;</span>, <span class="string">&quot;7&quot;</span>, <span class="string">&quot;8&quot;</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> it = a.<span class="built_in">begin</span>();  <span class="comment">// 返回一个迭代器类型，一般来说我们并不关心迭代器具体的数据类型</span></span><br><span class="line">    <span class="keyword">while</span>(it != a.<span class="built_in">end</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; *it &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">        it++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>运行结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 1 2 3 4 5 6 7 8</span><br></pre></td></tr></table></figure>
<h3 id="插入"><a href="#插入" class="headerlink" title="插入"></a>插入</h3><p>插入操作的函数：</p>
<ul>
<li><code>v.insert(p, n, val)</code>：在迭代器 p 之前插入 n 个值为 val 的元素，返回新添加的第一个元素的迭代器。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">(<span class="type">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; a&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> it1 = a.<span class="built_in">begin</span>();  <span class="comment">// 返回一个迭代器类型，一般来说我们并不关心迭代器具体的数据类型</span></span><br><span class="line">    <span class="keyword">auto</span> it2 = a.<span class="built_in">insert</span>((it1<span class="number">+1</span>), &#123;<span class="number">6</span>, <span class="number">7</span>, <span class="number">8</span>&#125;);  <span class="comment">// 利用迭代器在第二个元素之前插入数据</span></span><br><span class="line">    cout &lt;&lt; *it2 &lt;&lt; endl;  <span class="comment">// 返回的是新插入元素第一个元素的迭代器</span></span><br><span class="line">    <span class="keyword">auto</span> it = a.<span class="built_in">begin</span>();</span><br><span class="line">    <span class="keyword">while</span>(it != a.<span class="built_in">end</span>())</span><br><span class="line">    &#123;</span><br><span class="line">        cout &lt;&lt; *it &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">        it++;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6</span><br><span class="line">1 6 7 8 2 3</span><br></pre></td></tr></table></figure>
<h3 id="删除"><a href="#删除" class="headerlink" title="删除"></a>删除</h3><p>删除操作的函数：</p>
<ul>
<li><code>v.erase(p)</code>：删除迭代器 p 所指的元素，返回指向被删除元素后一个位置的迭代器。</li>
<li><code>v.erase(p, q)</code>：删除迭代器 p 和 q 之间的元素（包含 p，但不包含 q），返回指向被删除区域后一个位置的迭代器。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; a&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> it = a.<span class="built_in">begin</span>();</span><br><span class="line">    a.<span class="built_in">erase</span>(it + <span class="number">1</span>);  <span class="comment">// 删除第二个元素</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = a.<span class="built_in">begin</span>(); i != a.<span class="built_in">end</span>(); ++i) &#123;</span><br><span class="line">        cout &lt;&lt; *i &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    a.<span class="built_in">erase</span>(it + <span class="number">1</span>, it + <span class="number">3</span>);  <span class="comment">// 删除第二个到第三个元素（不包括第三个）</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i = a.<span class="built_in">begin</span>(); i != a.<span class="built_in">end</span>(); ++i) &#123;</span><br><span class="line">        cout &lt;&lt; *i &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1 3 4 5 </span><br><span class="line">1 5 </span><br></pre></td></tr></table></figure>
<hr>
<h2 id="vector-元素的重排操作（排序、逆序等）"><a href="#vector-元素的重排操作（排序、逆序等）" class="headerlink" title="vector 元素的重排操作（排序、逆序等）"></a>vector 元素的重排操作（排序、逆序等）</h2><h3 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h3><ul>
<li><code>sort(v.begin(), v.end())</code>：对 vector 中的元素进行升序排序。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">3</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>&#125;;</span><br><span class="line">    <span class="built_in">sort</span>(v.<span class="built_in">begin</span>(), v.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i : v) &#123;</span><br><span class="line">        cout &lt;&lt; i &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 2 3 4 5</span><br></pre></td></tr></table></figure>
<h3 id="逆序"><a href="#逆序" class="headerlink" title="逆序"></a>逆序</h3><ul>
<li><code>reverse(v.begin(), v.end())</code>：将 vector 中的元素顺序反转。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line">    <span class="built_in">reverse</span>(v.<span class="built_in">begin</span>(), v.<span class="built_in">end</span>());</span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i : v) &#123;</span><br><span class="line">        cout &lt;&lt; i &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">5 4 3 2 1</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="vector-中找最值"><a href="#vector-中找最值" class="headerlink" title="vector 中找最值"></a>vector 中找最值</h2><h3 id="查找最大值"><a href="#查找最大值" class="headerlink" title="查找最大值"></a>查找最大值</h3><ul>
<li><code>*max_element(v.begin(), v.end())</code>：返回 vector 中最大的元素</li>
</ul>
<p>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> maxElem = *<span class="built_in">max_element</span>(v.<span class="built_in">begin</span>(), v.<span class="built_in">end</span>());</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;最大值: &quot;</span> &lt;&lt; maxElem &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最大值: 5</span><br></pre></td></tr></table></figure>
<h3 id="查找最小值"><a href="#查找最小值" class="headerlink" title="查找最小值"></a>查找最小值</h3><ul>
<li><code>*min_element(v.begin(), v.end())</code>：返回 vector 中最小的元素。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;algorithm&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>&#125;;</span><br><span class="line">    <span class="keyword">auto</span> minElem = *<span class="built_in">min_element</span>(v.<span class="built_in">begin</span>(), v.<span class="built_in">end</span>());</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;最小值: &quot;</span> &lt;&lt; minElem &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">最小值: 1</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="改变-vector-大小及其内存分配机制"><a href="#改变-vector-大小及其内存分配机制" class="headerlink" title="改变 vector 大小及其内存分配机制"></a>改变 vector 大小及其内存分配机制</h2><h3 id="改变大小"><a href="#改变大小" class="headerlink" title="改变大小"></a>改变大小</h3><ul>
<li><code>v.resize(n)</code>：调整 vector 的大小为 n，若当前大小小于 n，会追加默认值，若当前大小大于 n，则多余的元素会被删除。</li>
<li><code>v.resize(n, val)</code>：调整大小为 n，并使用 val 填充新增加的元素。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">    v.<span class="built_in">resize</span>(<span class="number">5</span>, <span class="number">0</span>);  <span class="comment">// 将 vector 的大小扩展到 5，新增的元素填充 0</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i : v) &#123;</span><br><span class="line">        cout &lt;&lt; i &lt;&lt; <span class="string">&quot; &quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    cout &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">1 2 3 0 0</span><br></pre></td></tr></table></figure>
<h3 id="内存分配机制"><a href="#内存分配机制" class="headerlink" title="内存分配机制"></a>内存分配机制</h3><p>vector 在扩容时，并非每次增加一个元素就重新分配内存，而是会按一定的倍数增长。当元素个数达到当前容量时，vector 会重新分配内存并将旧数据拷贝到新的内存块中。</p>
<ul>
<li><code>v.capacity()</code>：返回当前 vector 的容量，即在不重新分配内存的情况下，vector 能存储多少元素。</li>
<li><code>v.shrink_to_fit()</code>：请求收缩容量到与当前大小相符。</li>
</ul>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    vector&lt;<span class="type">int</span>&gt; v&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>&#125;;</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;初始容量: &quot;</span> &lt;&lt; v.<span class="built_in">capacity</span>() &lt;&lt; endl;</span><br><span class="line">    v.<span class="built_in">push_back</span>(<span class="number">4</span>);</span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;新增元素后容量: &quot;</span> &lt;&lt; v.<span class="built_in">capacity</span>() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    v.<span class="built_in">resize</span>(<span class="number">2</span>);  <span class="comment">// 调整大小</span></span><br><span class="line">    cout &lt;&lt; <span class="string">&quot;resize 后容量: &quot;</span> &lt;&lt; v.<span class="built_in">capacity</span>() &lt;&lt; endl;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>输出结果：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">初始容量: 3</span><br><span class="line">新增元素后容量: 4</span><br><span class="line">resize 后容量: 4</span><br></pre></td></tr></table></figure>
<hr>
<h2 id="vector-数组与内置数组的选择问题"><a href="#vector-数组与内置数组的选择问题" class="headerlink" title="vector 数组与内置数组的选择问题"></a>vector 数组与内置数组的选择问题</h2><h3 id="何时使用-vector？"><a href="#何时使用-vector？" class="headerlink" title="何时使用 vector？"></a>何时使用 <code>vector</code>？</h3><ol>
<li><strong>动态大小：</strong> 如果数组的大小在运行时不确定或者会改变，使用 <code>vector</code> 是更好的选择，因为它能动态调整大小，而内置数组的大小在编译时就已经确定。</li>
<li><strong>内存管理：</strong> <code>vector</code> 会自动管理内存的分配与释放，使用起来更方便，避免手动管理内存的复杂性。</li>
<li><strong>更丰富的功能：</strong> <code>vector</code> 提供了许多内建函数（如 <code>push_back</code>、<code>resize</code>、<code>insert</code> 等），使得数据处理更加灵活和高效。</li>
</ol>
<h3 id="何时使用内置数组？"><a href="#何时使用内置数组？" class="headerlink" title="何时使用内置数组？"></a>何时使用内置数组？</h3><ol>
<li><strong>性能考虑：</strong> 内置数组在性能上通常优于 <code>vector</code>，尤其是在没有频繁改变数组大小时。它们不会发生额外的内存分配和拷贝，因此在一些对性能要求高的场景下，内置数组可能会更合适。</li>
<li><strong>固定大小：</strong> 当数组的大小已知并且在程序运行期间不会改变时，内置数组是更简单且更直接的选择。</li>
</ol>
<hr>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><code>vector</code> 是 C++ 中非常强大的数据结构，它不仅提供了动态调整大小的能力，还能在一定程度上避免内存管理的复杂性。在实际开发中，我们应根据需要灵活选择使用 <code>vector</code> 或者内置数组。</p>
<hr>
<p>转载请注明出处。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">这个版本包括了整个文章的内容，已经转为 Markdown 格式。你可以直接使用这个格式在你的编辑器或其他平台上发布。如果有其他需求或修改，请告诉我！</span><br></pre></td></tr></table></figure>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2024/11/11/%E4%BF%A1%E6%81%AF%E4%BC%A0%E6%92%AD%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/11/11/%E4%BF%A1%E6%81%AF%E4%BC%A0%E6%92%AD%E7%9B%B8%E5%85%B3%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="post-title-link" itemprop="url">信息传播相关论文笔记</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-11-11 10:02:24" itemprop="dateCreated datePublished" datetime="2024-11-11T10:02:24+08:00">2024-11-11</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-11-28 21:16:44" itemprop="dateModified" datetime="2024-11-28T21:16:44+08:00">2024-11-28</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">复杂网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a href="./File/基于二元对立信息的谣言传播模型研究_刘云飞.pdf">基于二元对立信息的谣言传播模型研究_刘云飞.pdf</a></p>
<p>这议论文描述了一个带有谣言传播和辟谣信息传播的 CASEIR 模型，其动力学方程式 (1) 表达了不同人群状态之间的转移关系。该模型是为了模拟谣言与辟谣信息在人群中的传播机制，并分析各类个体在谣言和辟谣信息传播过程中的动态变化。以下是公式中各个变量的含义和方程的理解：</p>
<h3 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h3><ul>
<li>( S(t) )：易感者，在当前时刻 ( t ) 未接触过谣言或辟谣信息。</li>
<li>( E<sub>1</sub>(t) )：谣言接触者，已接触到谣言但未传播。</li>
<li>( E<sub>2</sub>(t) )：辟谣信息接触者，已接触到辟谣信息但未传播。</li>
<li>( I<sub>1</sub>(t) )：谣言传播者，正在传播谣言的个体。</li>
<li>( I<sub>2</sub>(t) )：辟谣信息传播者，正在传播辟谣信息的个体。</li>
<li>( R<sub>1</sub>(t) )：谣言免疫者，不再传播谣言的个体。</li>
<li>( R<sub>2</sub>(t) )：辟谣信息免疫者，不再传播辟谣信息的个体。</li>
</ul>
<h3 id="方程的含义"><a href="#方程的含义" class="headerlink" title="方程的含义"></a>方程的含义</h3><p>方程 (1) 中的每个微分方程分别描述了不同状态下的个体数量随时间的变化。每个方程右侧的项代表了各种转移的概率、速率以及个体的动态转移过程。</p>
<ol>
<li><p><strong>易感者的变化</strong> $  \frac{dS(t)}{dt}  $</p>
<ul>
<li>受到谣言传播者影响，以概率$  ( \beta_1 S(t) I_1(t) ) $转变为谣言接触者 ( $ E_1 $)。</li>
<li>受到辟谣信息传播者影响，以概率 ( $ \beta_2 S(t) I_2(t)  $ ) 转变为辟谣信息接触者 $ ( E_2 ) $。</li>
<li>有概率 $ \xi_1 $  直接转变为谣言传播者 $ I_1 ，有概率 $ $ \xi_2  $直接转变为辟谣信息传播者 $  I_2  $。</li>
</ul>
</li>
<li><p><strong>谣言接触者的变化 $ ( \frac{dE_1(t)}{dt} ) $</strong></p>
<ul>
<li>受谣言传播者 $ ( I_1 ) 的影响，以概率 $ ( $ \sigma_1  $) 发展为谣言传播者 $  ( I_1 ) $。</li>
<li>受辟谣信息传播者 $ ( I_2 ) 的影响，以概率 $ ( $ \sigma_2 ) 成为辟谣信息传播者 $$  ( I_2 ) $。</li>
<li>有概率 $ ( \delta_1 ) 直接转变为谣言免疫者 $ ( $ R_1 $ )，有概率 $ ( \rho )  $在接触辟谣信息后直接免疫，不再传播谣言。</li>
<li>有概率 $ ( \alpha_2 ) 在 $ ( $ I_2 $) 的影响下转变为辟谣信息传播者 $ ( I_2 ) $。</li>
</ul>
</li>
<li><p><strong>辟谣信息接触者的变化 $ ( \frac{dE_2(t)}{dt} ) $</strong></p>
<ul>
<li>有概率$  ( \sigma_3 )  $发展为辟谣信息传播者 $ ( I_2 ) $。</li>
<li>有概率$  ( \delta_2 )  $直接变为辟谣信息免疫者$  ( R_2 ) $，不进入传播状态。</li>
</ul>
</li>
<li><p><strong>谣言传播者的变化 $ ( \frac{dI_1(t)}{dt} ) $</strong></p>
<ul>
<li>受遗忘机制的影响，以概率$  ( \gamma_1 ) $ 直接恢复为 ($  R_1 $ )。</li>
<li>在 ($  I_2 $ ) 的影响下，有概率 ($  \alpha_1 $ ) 恢复为 ( $ R_1 $ )，即不再传播谣言。</li>
<li>有 ($ \phi(t)  $) 的概率不再传播信息。</li>
</ul>
</li>
<li><p><strong>辟谣信息传播者的变化$  ( \frac{dI_2(t)}{dt} ) $</strong></p>
<ul>
<li>受遗忘机制的影响，以概率 ($  \gamma_2  $) 恢复为 ( $ R_2  $)。</li>
<li>有 ( $ \phi(t) $ ) 的概率不再传播信息。</li>
</ul>
</li>
<li><p><strong>谣言免疫者和辟谣信息免疫者的变化$  ( \frac{dR_1(t)}{dt} )  $和$  ( \frac{dR_2(t)}{dt} )$</strong></p>
<ul>
<li>这两项分别描述了谣言和辟谣信息的免疫者人数随时间的增加。</li>
</ul>
</li>
</ol>
<h3 id="矩阵-J-E-0"><a href="#矩阵-J-E-0" class="headerlink" title="矩阵 $ ( J(E_0) ) $"></a>矩阵 $ ( J(E_0) ) $</h3><p>($  J(E_0) $ ) 是该系统在平衡状态（即 ($  E_0 $ ) 时刻）下的雅可比矩阵。这个矩阵用于分析平衡点的稳定性，通过特征方程可以得到基本再生数 ($  R_0  $)，即系统中谣言和辟谣传播的基本传播能力。</p>
<h3 id="基本再生数-R-0"><a href="#基本再生数-R-0" class="headerlink" title="基本再生数 ( $ R_0 $ )"></a>基本再生数 ( $ R_0 $ )</h3><p>( $ R_0  $) 是影响系统动力学稳定性的重要参数。如果 ( $ R_0 &gt; 1 $ )，意味着谣言或辟谣信息在系统中会持续传播，否则，谣言和辟谣会逐渐消失。</p>
<p>矩阵 ( $ J(E_0) $ ) 是系统在平衡点 ( $ E_0 $ ) 处的 <strong>雅可比矩阵</strong>，也称为 <strong>Jacobian 矩阵</strong>。它用于分析系统在平衡状态下的稳定性，即考察该系统在谣言和辟谣传播过程中的稳定性。下面是它的来源和具体作用的解释。</p>
<h1 id="矩阵-J-E-0-1"><a href="#矩阵-J-E-0-1" class="headerlink" title="矩阵 $ ( J(E_0) ) $"></a>矩阵 $ ( J(E_0) ) $</h1><h3 id="1-Jacobian-矩阵的定义"><a href="#1-Jacobian-矩阵的定义" class="headerlink" title="1. Jacobian 矩阵的定义"></a>1. Jacobian 矩阵的定义</h3><p>对于一个非线性动力学系统，假设其状态变量$ （如 ( S )、( E_1 )、( E_2 )、( I_1 )、( I_2 )、( R_1 )、( R_2 )）$的动态演变可以用一个向量形式的微分方程来表示：</p>
<p>$ \frac{d\mathbf{X}}{dt} = \mathbf{F}(\mathbf{X}) $,</p>
<p>其中，$ ( \mathbf{X} = [S, E_1, E_2, I_1, I_2, R_1, R_2]^T ) $ 是状态变量的向量，$ ( \mathbf{F}(\mathbf{X}) )  $是状态变量变化的函数。</p>
<p>Jacobian 矩阵 ( J ) 是对这个向量函数 $ ( \mathbf{F}(\mathbf{X}) ) $ 进行一阶泰勒展开得到的偏导数矩阵，即：$ J =  \frac{\partial \mathbf{F}}{\partial \mathbf{X}} $</p>
<p>该矩阵的每个元素$  ( J_{ij} ) $ 表示第 ( i ) 个方程对第 ( j ) 个变量的偏导数，描述了系统在某个状态点（例如 ($  E_0 $) 平衡点）下，每个状态变量的微小变化对其他变量变化的影响。</p>
<h3 id="2-J-E-0-的来源"><a href="#2-J-E-0-的来源" class="headerlink" title="2. ( J$ (E_0) $ ) 的来源"></a>2. ( J$ (E_0) $ ) 的来源</h3><p>在这里，矩阵 ( J$ (E_0)  $) 是对系统在平衡点 ( $ E_0  $) 处的 Jacobian 矩阵。即将所有变量的变化率方程（即方程组 (1)）中的每一项对每个变量分别求偏导，得到如下的矩阵形式：</p>
<p>$ J(E_0) = \begin{pmatrix} \frac{\partial f_1}{\partial S} &amp; \frac{\partial f_1}{\partial E_1} &amp; \dots &amp; \frac{\partial f_1}{\partial R_2} \\ \frac{\partial f_2}{\partial S} &amp; \frac{\partial f_2}{\partial E_1} &amp; \dots &amp; \frac{\partial f_2}{\partial R_2} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ \frac{\partial f_7}{\partial S} &amp; \frac{\partial f_7}{\partial E_1} &amp; \dots &amp; \frac{\partial f_7}{\partial R_2} \end{pmatrix} $</p>
<p>其中 ($  f_i  $) 表示第 ( i ) 个微分方程的右侧表达式。</p>
<p>在 ( $ E_0 $ ) 点，即平衡状态下的 Jacobian 矩阵 ( $ J(E_0)  $)，描述了系统在该平衡状态附近的局部线性行为。通常，平衡点 ( $ E_0  $) 是一个无传播状态，例如 ( S ) 等于总人口，所有其他状态变量都为零，表示没有谣言和辟谣传播的状态。</p>
<h3 id="3-Jacobian-矩阵的作用"><a href="#3-Jacobian-矩阵的作用" class="headerlink" title="3. Jacobian 矩阵的作用"></a>3. Jacobian 矩阵的作用</h3><ul>
<li><strong>稳定性分析</strong>：通过计算 ($  J(E_0)  $) 的特征值，可以判断该平衡点的稳定性。如果所有特征值的实部都是负的，则平衡点是局部稳定的；反之，如果有特征值的实部为正，则该平衡点是不稳定的。</li>
<li><strong>基本再生数 ( $ R_0 $ ) 的计算</strong>：在流行病学和传播动力学模型中，Jacobian 矩阵的特征值也常用于计算基本再生数 ($  R_0 $ )。这里，基本再生数 ( $ R_0  $) 是传播过程中的一个关键参数，它衡量了谣言或辟谣在系统中的平均传播能力。若 ($  R_0 &gt; 1  $)，则传播过程可以在群体中持续存在；若 ( $ R_0 \leq 1 $ )，传播过程会逐渐消失。</li>
</ul>
<h3 id="4-在该模型中的应用"><a href="#4-在该模型中的应用" class="headerlink" title="4. 在该模型中的应用"></a>4. 在该模型中的应用</h3><p>在这个谣言传播模型中，Jacobian 矩阵 ( $ J(E_0) $ ) 的特征值为$ \lambda = -(\sigma_1 + \delta_1 - \alpha_1), \quad -(\sigma_3 + \delta_2 - \alpha_2), \quad -(\gamma_1 - \phi), \quad -(\gamma_2 - \phi), \quad -( \beta_1 S k), \quad -( \beta_2 S k) $</p>
<p>根据特征值的符号，可以使用 Hurwitz 判据分析系统在无传播状态的稳定性。此外，通过特征值，可以进一步计算和定义该系统的基本再生数 ( R_0 )，用于描述谣言传播或辟谣信息传播的潜力。</p>
<h1 id="论文中的-J-E-0-矩阵"><a href="#论文中的-J-E-0-矩阵" class="headerlink" title="论文中的 $  ( J(E_0) )  $ 矩阵"></a>论文中的 $  ( J(E_0) )  $ 矩阵</h1><p>论文中的 $  ( J(E_0) )  $ 矩阵是通过对模型的每一个微分方程分别对所有变量求偏导得到的。</p>
<p>假设状态向量为$  ( \mathbf{X} = [S, E_1, E_2, I_1, I_2, R_1, R_2]^T ) $，每一个变量代表一个状态，比如 ( S ) 表示易感者，$ ( E_1 ) $ 表示谣言接触者等。模型的每一个微分方程描述了各个变量随时间的变化率。</p>
<p>为了得到雅可比矩阵 $ ( J(E_0) ) $，我们对方程组中的每一个微分方程分别对所有变量求偏导，构建偏导数矩阵。矩阵$ ( J(E_0) ) $的元素 $ ( J_{ij} )  $表示第 ( i ) 个方程对第 ( j ) 个变量的偏导。</p>
<h3 id="逐行逐列推导"><a href="#逐行逐列推导" class="headerlink" title="逐行逐列推导"></a>逐行逐列推导</h3><p>我们将模型方程组（即图片中的方程组）每一行的导数求出，得到对应矩阵的行和列。</p>
<h4 id="1-对-frac-dS-t-dt-的求导"><a href="#1-对-frac-dS-t-dt-的求导" class="headerlink" title="1. 对 $ ( \frac{dS(t)}{dt} )  $的求导"></a>1. 对 $ ( \frac{dS(t)}{dt} )  $的求导</h4><p>方程：$ \frac{dS(t)}{dt} = -\beta_1 S(t) I_1(t) k - \beta_2 S(t) I_2(t) k - \xi_1 S(t) - \xi_2 S(t) $</p>
<p>对每个变量求偏导：</p>
<ul>
<li>对 $  S ： -\beta_1 I_1 k - \beta_2 I_2 k - \xi_1 - \xi_2  $</li>
<li>对$   E_1, E_2, R_1, R_2 ：0 $</li>
<li>对 $  I_1 ： -\beta_1 S k  $</li>
<li>对$   I_2 ： -\beta_2 S k  $</li>
</ul>
<h4 id="2-对-frac-dE-1-t-dt-的求导"><a href="#2-对-frac-dE-1-t-dt-的求导" class="headerlink" title="2. 对 $ ( \frac{dE_1(t)}{dt} )  $的求导"></a>2. 对 $ ( \frac{dE_1(t)}{dt} )  $的求导</h4><p>方程：$ \frac{dE_1(t)}{dt} = \beta_1 S(t) I_1(t) k - \sigma_1 E_1(t) - \sigma_2 E_1(t) - \alpha_2 E_1(t) I_2(t) k - \delta_1 E_1(t) - \rho E_1(t) $</p>
<p>对每个变量求偏导：</p>
<ul>
<li>对$   S ： \beta_1 I_1 k  $</li>
<li>对$   E_1 ： -\sigma_1 - \sigma_2 - \alpha_2 I_2 k - \delta_1 - \rho  $</li>
<li>对 $  I_1 ： \beta_1 S k  $</li>
<li>对 $  I_2 ： -\alpha_2 E_1 k $</li>
</ul>
<h4 id="3-对-frac-dE-2-t-dt-的求导"><a href="#3-对-frac-dE-2-t-dt-的求导" class="headerlink" title="3. 对 $ ( \frac{dE_2(t)}{dt} )  $的求导"></a>3. 对 $ ( \frac{dE_2(t)}{dt} )  $的求导</h4><p>方程：$ \frac{dE_2(t)}{dt} = \beta_2 S(t) I_2(t) k - \sigma_3 E_2(t) - \delta_2 E_2(t) $</p>
<p>对每个变量求偏导：</p>
<ul>
<li>对 $  S ： \beta_2 I_2 k  $</li>
<li>对$   E_2 ： -\sigma_3 - \delta_2  $</li>
<li>对$   I_2 ： \beta_2 S k  $</li>
</ul>
<h4 id="4-对-frac-dI-1-t-dt-的求导"><a href="#4-对-frac-dI-1-t-dt-的求导" class="headerlink" title="4. 对 $ ( \frac{dI_1(t)}{dt} )  $的求导"></a>4. 对 $ ( \frac{dI_1(t)}{dt} )  $的求导</h4><h4 id="方程：-frac-dI-1-t-dt-sigma-1-E-1-t-xi-1-S-t-gamma-1-I-1-t-alpha-1-I-1-t-I-2-t-k-phi-t-I-1-t"><a href="#方程：-frac-dI-1-t-dt-sigma-1-E-1-t-xi-1-S-t-gamma-1-I-1-t-alpha-1-I-1-t-I-2-t-k-phi-t-I-1-t" class="headerlink" title="方程：$ \frac{dI_1(t)}{dt} = \sigma_1 E_1(t) + \xi_1 S(t) - \gamma_1 I_1(t) - \alpha_1 I_1(t) I_2(t) k - \phi(t) I_1(t) $"></a>方程：$ \frac{dI_1(t)}{dt} = \sigma_1 E_1(t) + \xi_1 S(t) - \gamma_1 I_1(t) - \alpha_1 I_1(t) I_2(t) k - \phi(t) I_1(t) $</h4><p>对每个变量求偏导：</p>
<ul>
<li>对 $  S ： \xi_1 $</li>
<li>对$   E_1 ： \sigma_1 $</li>
<li>对 $  I_1 ： -\gamma_1 - \alpha_1 I_2 k - \phi(t) $</li>
<li>对$   I_2 ： -\alpha_1 I_1 k  $</li>
</ul>
<h4 id="5-对-frac-dI-2-t-dt-的求导"><a href="#5-对-frac-dI-2-t-dt-的求导" class="headerlink" title="5. 对  $ ( \frac{dI_2(t)}{dt} )  $的求导"></a>5. 对  $ ( \frac{dI_2(t)}{dt} )  $的求导</h4><p>方程：$ \frac{dI_2(t)}{dt} = \sigma_2 E_1(t) + \sigma_3 E_2(t) + \xi_2 S(t) + \alpha_2 E_1(t) I_2(t) k - \gamma_2 I_2(t) - \phi(t) I_2(t) $</p>
<p>对每个变量求偏导：</p>
<ul>
<li>对$   S ： \xi_2  $</li>
<li>对$   E_1 ： \sigma_2  $</li>
<li>对$   E_2 ： \sigma_3  $</li>
<li>对$   I_2 ： -\gamma_2 - \phi(t) + \alpha_2 E_1 k  $</li>
</ul>
<h4 id="6-对-frac-dR-1-t-dt-和-frac-dR-2-t-dt"><a href="#6-对-frac-dR-1-t-dt-和-frac-dR-2-t-dt" class="headerlink" title="6. 对 $ ( \frac{dR_1(t)}{dt} ) 和 ( \frac{dR_2(t)}{dt} ) $"></a>6. 对 $ ( \frac{dR_1(t)}{dt} ) 和 ( \frac{dR_2(t)}{dt} ) $</h4><p>这两行表示免疫者的增长方程：</p>
<ul>
<li>对于$  ( R_1 )：来自 ( I_1 ) 和 ( E_1 ) $ 的流入。</li>
<li>对于$  ( R_2 )：来自 ( I_2 ) 和 ( E_2 ) $ 的流入。</li>
</ul>
<p>通过对以上步骤的系统性求导，将每个偏导结果填入对应的$  ( J(E_0) ) $ 矩阵的元素位置，就得到了矩阵的每一行和每一列。</p>
<h1 id="python代码复现（论文图二）"><a href="#python代码复现（论文图二）" class="headerlink" title="python代码复现（论文图二）"></a>python代码复现（论文图二）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.integrate <span class="keyword">import</span> odeint</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型参数</span></span><br><span class="line">N = <span class="number">1e6</span>  <span class="comment"># 总人口数 (用作初始条件，后面转换为相对密度)</span></span><br><span class="line">k_avg = <span class="number">20</span>  <span class="comment"># 平均度</span></span><br><span class="line">beta1 = <span class="number">0.06</span>  <span class="comment"># 谣言传播接触率</span></span><br><span class="line">beta2 = <span class="number">0.04</span>  <span class="comment"># 辟谣信息接触率</span></span><br><span class="line">xi1 = <span class="number">0.001</span>  <span class="comment"># 易感者直接变为谣言传播者的概率</span></span><br><span class="line">xi2 = <span class="number">0.001</span>  <span class="comment"># 易感者直接变为辟谣传播者的概率</span></span><br><span class="line">sigma1 = <span class="number">0.08</span>  <span class="comment"># 谣言接触者变为谣言传播者的概率</span></span><br><span class="line">sigma2 = <span class="number">0.005</span>  <span class="comment"># 谣言接触者变为辟谣传播者的概率</span></span><br><span class="line">sigma3 = <span class="number">0.06</span>  <span class="comment"># 辟谣接触者变为辟谣传播者的概率</span></span><br><span class="line">delta1 = <span class="number">0.001</span>  <span class="comment"># 谣言接触者免疫的概率</span></span><br><span class="line">delta2 = <span class="number">0.001</span>  <span class="comment"># 辟谣接触者免疫的概率</span></span><br><span class="line">alpha1 = <span class="number">0.02</span>  <span class="comment"># 谣言传播者受辟谣影响转为免疫的概率</span></span><br><span class="line">alpha2 = <span class="number">0.01</span>  <span class="comment"># 谣言接触者转为辟谣传播者的概率</span></span><br><span class="line">gamma1 = <span class="number">0.02</span>  <span class="comment"># 谣言传播者遗忘谣言的概率</span></span><br><span class="line">gamma2 = <span class="number">0.02</span>  <span class="comment"># 辟谣传播者遗忘的概率</span></span><br><span class="line">lambda_val = <span class="number">0.001</span>  <span class="comment"># 传播疲劳函数的衰减系数</span></span><br><span class="line">rho = <span class="number">0.01</span>  <span class="comment"># 谣言接触者受辟谣影响转为免疫的概率</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义传播疲劳函数 φ(t)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fatigue</span>(<span class="params">t, lambda_val</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - np.exp(-lambda_val * t)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义微分方程组</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">caseir_model</span>(<span class="params">y, t, k_avg, beta1, beta2, xi1, xi2, sigma1, sigma2, sigma3, delta1, delta2, alpha1, alpha2, gamma1,</span></span><br><span class="line"><span class="params">                 gamma2, lambda_val, rho</span>):</span><br><span class="line">    S, E1, E2, I1, I2, R1, R2 = y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 传播疲劳函数 φ(t)</span></span><br><span class="line">    phi = fatigue(t, lambda_val)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断当前时间是否开启辟谣</span></span><br><span class="line">    <span class="keyword">if</span> t &lt; <span class="number">10</span>:</span><br><span class="line">        current_beta2 = <span class="number">0</span></span><br><span class="line">        current_alpha2 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        current_beta2 = beta2</span><br><span class="line">        current_alpha2 = alpha2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 微分方程组</span></span><br><span class="line">    dSdt = -beta1 * S * I1 * k_avg - current_beta2 * S * I2 * k_avg - xi1 * S - xi2 * S</span><br><span class="line">    dE1dt = beta1 * S * I1 * k_avg - sigma1 * E1 - sigma2 * E1 - current_alpha2 * E1 * I2 * k_avg - delta1 * E1 - rho * E1</span><br><span class="line">    dE2dt = current_beta2 * S * I2 * k_avg - sigma3 * E2 - delta2 * E2</span><br><span class="line">    dI1dt = sigma1 * E1 + xi1 * S - gamma1 * I1 - alpha1 * I1 * I2 * k_avg - phi * I1</span><br><span class="line">    dI2dt = sigma2 * E1 + sigma3 * E2 + xi2 * S + current_alpha2 * E1 * I2 * k_avg - gamma2 * I2 - phi * I2</span><br><span class="line">    dR1dt = gamma1 * I1 + delta1 * E1 + alpha1 * I1 * I2 * k_avg + rho * E1</span><br><span class="line">    dR2dt = gamma2 * I2 + delta2 * E2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [dSdt, dE1dt, dE2dt, dI1dt, dI2dt, dR1dt, dR2dt]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始条件：S, E1, E2, I1, I2, R1, R2 的相对密度</span></span><br><span class="line">I1_initial = <span class="number">10</span> / N</span><br><span class="line">S_initial = <span class="number">1</span> - I1_initial  <span class="comment"># 初始所有人口都为易感者，除去谣言传播者的密度</span></span><br><span class="line">initial_conditions = [S_initial, <span class="number">0.0</span>, <span class="number">0.0</span>, I1_initial, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间范围</span></span><br><span class="line">t = np.linspace(<span class="number">0</span>, <span class="number">100</span>, <span class="number">1000</span>)  <span class="comment"># 模拟 100 天，1000 个时间点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用 odeint 来求解微分方程</span></span><br><span class="line">result = odeint(caseir_model, initial_conditions, t, args=(</span><br><span class="line">k_avg, beta1, beta2, xi1, xi2, sigma1, sigma2, sigma3, delta1, delta2, alpha1, alpha2, gamma1, gamma2, lambda_val, rho))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 分离结果</span></span><br><span class="line">S, E1, E2, I1, I2, R1, R2 = result.T</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制结果</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">plt.plot(t, S, label=<span class="string">&quot;S (易感者)&quot;</span>)</span><br><span class="line">plt.plot(t, E1, label=<span class="string">&quot;E1 (谣言接触者)&quot;</span>)</span><br><span class="line">plt.plot(t, E2, label=<span class="string">&quot;E2 (辟谣接触者)&quot;</span>)</span><br><span class="line">plt.plot(t, I1, label=<span class="string">&quot;I1 (谣言传播者)&quot;</span>)</span><br><span class="line">plt.plot(t, I2, label=<span class="string">&quot;I2 (辟谣传播者)&quot;</span>)</span><br><span class="line">plt.plot(t, R1, label=<span class="string">&quot;R1 (谣言免疫者)&quot;</span>)</span><br><span class="line">plt.plot(t, R2, label=<span class="string">&quot;R2 (辟谣免疫者)&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;时间 (天)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;密度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;CASEIR 模型传播模拟（考虑传播疲劳函数）&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure9001.png" alt=""></p>
<h1 id="python代码复现（3a3b图像）"><a href="#python代码复现（3a3b图像）" class="headerlink" title="python代码复现（3a3b图像）"></a>python代码复现（3a3b图像）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">from</span> scipy.integrate <span class="keyword">import</span> solve_ivp</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用黑体显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决负号显示问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置参数</span></span><br><span class="line">params = &#123;</span><br><span class="line">    <span class="string">&#x27;beta1&#x27;</span>: <span class="number">0.06</span>, <span class="string">&#x27;beta2&#x27;</span>: <span class="number">0.04</span>, <span class="string">&#x27;sigma1&#x27;</span>: <span class="number">0.08</span>, <span class="string">&#x27;sigma2&#x27;</span>: <span class="number">0.005</span>,</span><br><span class="line">    <span class="string">&#x27;sigma3&#x27;</span>: <span class="number">0.06</span>, <span class="string">&#x27;gamma1&#x27;</span>: <span class="number">0.02</span>, <span class="string">&#x27;gamma2&#x27;</span>: <span class="number">0.02</span>,</span><br><span class="line">    <span class="string">&#x27;delta1&#x27;</span>: <span class="number">0.001</span>, <span class="string">&#x27;delta2&#x27;</span>: <span class="number">0.001</span>, <span class="string">&#x27;xi1&#x27;</span>: <span class="number">0.001</span>, <span class="string">&#x27;xi2&#x27;</span>: <span class="number">0.001</span>,</span><br><span class="line">    <span class="string">&#x27;lambda&#x27;</span>: <span class="number">0.001</span>, <span class="string">&#x27;alpha1&#x27;</span>: <span class="number">0.02</span>, <span class="string">&#x27;alpha2&#x27;</span>: <span class="number">0.01</span>, <span class="string">&#x27;rho&#x27;</span>: <span class="number">0.01</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 网络参数</span></span><br><span class="line">N = <span class="built_in">int</span>(<span class="number">1e6</span>)  <span class="comment"># 设置节点数为100万</span></span><br><span class="line">average_degree = <span class="number">10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 WS 小世界网络</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_ws_network</span>(<span class="params">N, k=<span class="number">10</span>, p=<span class="number">0.1</span></span>):</span><br><span class="line">    G = nx.watts_strogatz_graph(N, k, p)</span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 BA 无标度网络</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_ba_network</span>(<span class="params">N, m=<span class="number">10</span></span>):</span><br><span class="line">    G = nx.barabasi_albert_graph(N, m)</span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line"><span class="comment"># 传播方程</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">caseir_ode</span>(<span class="params">t, y, params, G</span>):</span><br><span class="line">    S, E1, E2, I1, I2, R1, R2 = y</span><br><span class="line">    beta1, beta2 = params[<span class="string">&#x27;beta1&#x27;</span>], params[<span class="string">&#x27;beta2&#x27;</span>]</span><br><span class="line">    sigma1, sigma2, sigma3 = params[<span class="string">&#x27;sigma1&#x27;</span>], params[<span class="string">&#x27;sigma2&#x27;</span>], params[<span class="string">&#x27;sigma3&#x27;</span>]</span><br><span class="line">    gamma1, gamma2 = params[<span class="string">&#x27;gamma1&#x27;</span>], params[<span class="string">&#x27;gamma2&#x27;</span>]</span><br><span class="line">    delta1, delta2 = params[<span class="string">&#x27;delta1&#x27;</span>], params[<span class="string">&#x27;delta2&#x27;</span>]</span><br><span class="line">    xi1, xi2 = params[<span class="string">&#x27;xi1&#x27;</span>], params[<span class="string">&#x27;xi2&#x27;</span>]</span><br><span class="line">    lambd, alpha1, alpha2, rho = params[<span class="string">&#x27;lambda&#x27;</span>], params[<span class="string">&#x27;alpha1&#x27;</span>], params[<span class="string">&#x27;alpha2&#x27;</span>], params[<span class="string">&#x27;rho&#x27;</span>]</span><br><span class="line"></span><br><span class="line">    fatigue = <span class="number">1</span> - np.exp(-lambd * t)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断辟谣信息的传播是否开始</span></span><br><span class="line">    <span class="keyword">if</span> t &lt; <span class="number">10</span>:</span><br><span class="line">        beta2, sigma3, alpha2 = <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个节点的邻居数，并按邻居数更新传播率</span></span><br><span class="line">    degree_dict = <span class="built_in">dict</span>(G.degree())</span><br><span class="line">    degree_factor = <span class="built_in">sum</span>(degree_dict.values()) / <span class="built_in">len</span>(degree_dict)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 微分方程</span></span><br><span class="line">    dS_dt = -beta1 * S * I1 * degree_factor - beta2 * S * I2 * degree_factor - xi1 * S - xi2 * S</span><br><span class="line">    dE1_dt = beta1 * S * I1 * degree_factor - sigma1 * E1 - sigma2 * E1 - alpha2 * E1 * I2 * degree_factor - delta1 * E1 - rho * E1 * fatigue</span><br><span class="line">    dE2_dt = beta2 * S * I2 * degree_factor - sigma3 * E2 - delta2 * E2</span><br><span class="line">    dI1_dt = sigma1 * E1 + xi1 * S - gamma1 * I1 - alpha1 * I1 * I2 * degree_factor - fatigue * I1</span><br><span class="line">    dI2_dt = sigma2 * E1 + sigma3 * E2 + xi2 * S + alpha2 * E1 * I2 * degree_factor - gamma2 * I2 - fatigue * I2</span><br><span class="line">    dR1_dt = gamma1 * I1 + delta1 * E1 + alpha1 * I1 * I2 * degree_factor + rho * E1 * fatigue</span><br><span class="line">    dR2_dt = gamma2 * I2 + delta2 * E2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [dS_dt, dE1_dt, dE2_dt, dI1_dt, dI2_dt, dR1_dt, dR2_dt]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始条件</span></span><br><span class="line">initial_conditions = [<span class="number">1</span> - <span class="number">10</span> / N, <span class="number">0</span>, <span class="number">0</span>, <span class="number">10</span> / N, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>]  <span class="comment"># S(0), E1(0), E2(0), I1(0), I2(0), R1(0), R2(0)</span></span><br><span class="line">t_span = (<span class="number">0</span>, <span class="number">100</span>)  <span class="comment"># 时间范围</span></span><br><span class="line">t_eval = np.linspace(<span class="number">0</span>, <span class="number">100</span>, <span class="number">1000</span>)  <span class="comment"># 评估时间点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 蒙特卡洛模拟实验</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">monte_carlo_simulation</span>(<span class="params">N, network_type=<span class="string">&quot;ws&quot;</span>, num_simulations=<span class="number">10</span></span>):</span><br><span class="line">    all_results = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(num_simulations):</span><br><span class="line">        <span class="comment"># 创建网络</span></span><br><span class="line">        <span class="keyword">if</span> network_type == <span class="string">&quot;ws&quot;</span>:</span><br><span class="line">            G = create_ws_network(N)</span><br><span class="line">        <span class="keyword">elif</span> network_type == <span class="string">&quot;ba&quot;</span>:</span><br><span class="line">            G = create_ba_network(N)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">raise</span> ValueError(<span class="string">&quot;Network type must be &#x27;ws&#x27; or &#x27;ba&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 求解ODE</span></span><br><span class="line">        result = solve_ivp(caseir_ode, t_span, initial_conditions, args=(params, G), t_eval=t_eval)</span><br><span class="line">        all_results.append(result.y)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算所有模拟的平均结果</span></span><br><span class="line">    avg_results = np.mean(np.array(all_results), axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> avg_results</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行蒙特卡洛模拟并绘制结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_monte_carlo_results</span>(<span class="params">N, network_type=<span class="string">&quot;ws&quot;</span>, num_simulations=<span class="number">10</span></span>):</span><br><span class="line">    avg_results = monte_carlo_simulation(N, network_type, num_simulations)</span><br><span class="line">    S, E1, E2, I1, I2, R1, R2 = avg_results</span><br><span class="line"></span><br><span class="line">    plt.figure(figsize=(<span class="number">12</span>, <span class="number">8</span>))</span><br><span class="line">    plt.plot(t_eval, S, label=<span class="string">&quot;S (易感者)&quot;</span>)</span><br><span class="line">    plt.plot(t_eval, E1, label=<span class="string">&quot;E1 (谣言接触者)&quot;</span>)</span><br><span class="line">    plt.plot(t_eval, E2, label=<span class="string">&quot;E2 (辟谣接触者)&quot;</span>)</span><br><span class="line">    plt.plot(t_eval, I1, label=<span class="string">&quot;I1 (谣言传播者)&quot;</span>)</span><br><span class="line">    plt.plot(t_eval, I2, label=<span class="string">&quot;I2 (辟谣传播者)&quot;</span>)</span><br><span class="line">    plt.plot(t_eval, R1, label=<span class="string">&quot;R1 (谣言免疫者)&quot;</span>)</span><br><span class="line">    plt.plot(t_eval, R2, label=<span class="string">&quot;R2 (辟谣免疫者)&quot;</span>)</span><br><span class="line"></span><br><span class="line">    plt.xlabel(<span class="string">&quot;时间 (天)&quot;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&quot;密度&quot;</span>)</span><br><span class="line">    plt.title(<span class="string">f&quot;CASEIR 模型传播模拟 - <span class="subst">&#123;network_type.upper()&#125;</span> 网络&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> network_type.upper() == <span class="string">&quot;ws&quot;</span>:</span><br><span class="line">        G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure9002.png&#x27;</span></span><br><span class="line">        plt.savefig(G_patch)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure9003.png&#x27;</span></span><br><span class="line">        plt.savefig(G_patch)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行WS小世界网络的蒙特卡洛模拟</span></span><br><span class="line">plot_monte_carlo_results(N, network_type=<span class="string">&quot;ws&quot;</span>, num_simulations=<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进行BA无标度网络的蒙特卡洛模拟</span></span><br><span class="line">plot_monte_carlo_results(N, network_type=<span class="string">&quot;ba&quot;</span>, num_simulations=<span class="number">10</span>)</span><br></pre></td></tr></table></figure>
<p><img src="images/figure9009.png" alt=""></p>
<p><img src="images/figure9006.png" alt=""></p>
<h1 id="python代码复现（5a5b图像）"><a href="#python代码复现（5a5b图像）" class="headerlink" title="python代码复现（5a5b图像）"></a>python代码复现（5a5b图像）</h1><p>通过数值仿真以探索传播疲劳系数λ对易感者 S 和谣言传播者𝐼1密度影响，如图 5a 及图 5b 所示。随着传播疲劳系数 λ 的增加，系统趋于稳定后，易感者（S）</p>
<p>的比例大幅增加，越来越多的人未接触过相关谣言。对于谣言传播者𝐼1，随着传播疲劳系数的增加而显著降低其峰值密度，这表明传播疲劳可以有效减缓谣言的传播范围。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.integrate <span class="keyword">import</span> odeint</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置字体</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用黑体显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决负号显示问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型参数</span></span><br><span class="line">N = <span class="number">1e6</span>  <span class="comment"># 总人口数 (用作初始条件，后面转换为相对密度)</span></span><br><span class="line">k_avg = <span class="number">20</span>  <span class="comment"># 平均度</span></span><br><span class="line">beta1 = <span class="number">0.06</span>  <span class="comment"># 谣言传播接触率</span></span><br><span class="line">beta2 = <span class="number">0.04</span>  <span class="comment"># 辟谣信息接触率</span></span><br><span class="line">xi1 = <span class="number">0.001</span>  <span class="comment"># 易感者直接变为谣言传播者的概率</span></span><br><span class="line">xi2 = <span class="number">0.001</span>  <span class="comment"># 易感者直接变为辟谣传播者的概率</span></span><br><span class="line">sigma1 = <span class="number">0.08</span>  <span class="comment"># 谣言接触者变为谣言传播者的概率</span></span><br><span class="line">sigma2 = <span class="number">0.005</span>  <span class="comment"># 谣言接触者变为辟谣传播者的概率</span></span><br><span class="line">sigma3 = <span class="number">0.06</span>  <span class="comment"># 辟谣接触者变为辟谣传播者的概率</span></span><br><span class="line">delta1 = <span class="number">0.001</span>  <span class="comment"># 谣言接触者免疫的概率</span></span><br><span class="line">delta2 = <span class="number">0.001</span>  <span class="comment"># 辟谣接触者免疫的概率</span></span><br><span class="line">alpha1 = <span class="number">0.02</span>  <span class="comment"># 谣言传播者受辟谣影响转为免疫的概率</span></span><br><span class="line">alpha2 = <span class="number">0.01</span>  <span class="comment"># 谣言接触者转为辟谣传播者的概率</span></span><br><span class="line">gamma1 = <span class="number">0.02</span>  <span class="comment"># 谣言传播者遗忘谣言的概率</span></span><br><span class="line">gamma2 = <span class="number">0.02</span>  <span class="comment"># 辟谣传播者遗忘的概率</span></span><br><span class="line">rho = <span class="number">0.01</span>  <span class="comment"># 谣言接触者受辟谣影响转为免疫的概率</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义传播疲劳函数 φ(t)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fatigue</span>(<span class="params">t, lambda_val</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - np.exp(-lambda_val * t)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义微分方程组</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">caseir_model</span>(<span class="params">y, t, k_avg, beta1, beta2, xi1, xi2, sigma1, sigma2, sigma3, delta1, delta2, alpha1, alpha2, gamma1,</span></span><br><span class="line"><span class="params">                 gamma2, lambda_val, rho</span>):</span><br><span class="line">    S, E1, E2, I1, I2, R1, R2 = y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 传播疲劳函数 φ(t)</span></span><br><span class="line">    phi = fatigue(t, lambda_val)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断当前时间是否开启辟谣</span></span><br><span class="line">    <span class="keyword">if</span> t &lt; <span class="number">10</span>:</span><br><span class="line">        current_beta2 = <span class="number">0</span></span><br><span class="line">        current_alpha2 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        current_beta2 = beta2</span><br><span class="line">        current_alpha2 = alpha2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 微分方程组</span></span><br><span class="line">    dSdt = -beta1 * S * I1 * k_avg - current_beta2 * S * I2 * k_avg - xi1 * S - xi2 * S</span><br><span class="line">    dE1dt = beta1 * S * I1 * k_avg - sigma1 * E1 - sigma2 * E1 - current_alpha2 * E1 * I2 * k_avg - delta1 * E1 - rho * E1</span><br><span class="line">    dE2dt = current_beta2 * S * I2 * k_avg - sigma3 * E2 - delta2 * E2</span><br><span class="line">    dI1dt = sigma1 * E1 + xi1 * S - gamma1 * I1 - alpha1 * I1 * I2 * k_avg - phi * I1</span><br><span class="line">    dI2dt = sigma2 * E1 + sigma3 * E2 + xi2 * S + current_alpha2 * E1 * I2 * k_avg - gamma2 * I2 - phi * I2</span><br><span class="line">    dR1dt = gamma1 * I1 + delta1 * E1 + alpha1 * I1 * I2 * k_avg + rho * E1</span><br><span class="line">    dR2dt = gamma2 * I2 + delta2 * E2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [dSdt, dE1dt, dE2dt, dI1dt, dI2dt, dR1dt, dR2dt]</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始条件：S, E1, E2, I1, I2, R1, R2 的相对密度</span></span><br><span class="line">I1_initial = <span class="number">10</span> / N</span><br><span class="line">S_initial = <span class="number">1</span> - I1_initial  <span class="comment"># 初始所有人口都为易感者，除去谣言传播者的密度</span></span><br><span class="line">initial_conditions = [S_initial, <span class="number">0.0</span>, <span class="number">0.0</span>, I1_initial, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间范围</span></span><br><span class="line">t = np.linspace(<span class="number">0</span>, <span class="number">100</span>, <span class="number">1000</span>)  <span class="comment"># 模拟 100 天，1000 个时间点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置不同的传播疲劳系数 λ</span></span><br><span class="line">lambda_values = [<span class="number">0.001</span>, <span class="number">0.005</span>, <span class="number">0.01</span>, <span class="number">0.015</span>, <span class="number">0.02</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储不同 λ 值的结果</span></span><br><span class="line">S_results = []</span><br><span class="line">I1_results = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个 λ 进行仿真</span></span><br><span class="line"><span class="keyword">for</span> lambda_val <span class="keyword">in</span> lambda_values:</span><br><span class="line">    result = odeint(caseir_model, initial_conditions, t, args=(</span><br><span class="line">        k_avg, beta1, beta2, xi1, xi2, sigma1, sigma2, sigma3, delta1, delta2, alpha1, alpha2, gamma1, gamma2,</span><br><span class="line">        lambda_val, rho))</span><br><span class="line"></span><br><span class="line">    S_results.append(result[:, <span class="number">0</span>])  <span class="comment"># 保存 S 的结果</span></span><br><span class="line">    I1_results.append(result[:, <span class="number">3</span>])  <span class="comment"># 保存 I1 的结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制不同 λ 对易感者 S 密度的影响</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i, lambda_val <span class="keyword">in</span> <span class="built_in">enumerate</span>(lambda_values):</span><br><span class="line">    plt.plot(t, S_results[i], label=<span class="string">f&quot;λ=<span class="subst">&#123;lambda_val&#125;</span>&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;时间 (天)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;易感者 S 的密度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;不同传播疲劳系数 λ 对易感者 S 的影响&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure9010.png&#x27;</span></span><br><span class="line">plt.savefig(G_patch)</span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制不同 λ 对谣言传播者 I1 密度的影响</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i, lambda_val <span class="keyword">in</span> <span class="built_in">enumerate</span>(lambda_values):</span><br><span class="line">    plt.plot(t, I1_results[i], label=<span class="string">f&quot;λ=<span class="subst">&#123;lambda_val&#125;</span>&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;时间 (天)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;谣言传播者 I1 的密度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;不同传播疲劳系数 λ 对谣言传播者 I1 的影响&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure9011.png&#x27;</span></span><br><span class="line">plt.savefig(G_patch)</span><br><span class="line">plt.grid()</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure9010.png" alt=""></p>
<p><img src="images/figure9011.png" alt=""></p>
<h1 id="谣言逆转率𝜎2对𝐼1和𝐼2密度的影响-6a6b"><a href="#谣言逆转率𝜎2对𝐼1和𝐼2密度的影响-6a6b" class="headerlink" title="谣言逆转率𝜎2对𝐼1和𝐼2密度的影响(6a6b)"></a>谣言逆转率𝜎2对𝐼1和𝐼2密度的影响(6a6b)</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy.integrate <span class="keyword">import</span> odeint</span><br><span class="line"></span><br><span class="line">plt.rcParams[<span class="string">&#x27;font.sans-serif&#x27;</span>] = [<span class="string">&#x27;SimHei&#x27;</span>]  <span class="comment"># 用黑体显示中文</span></span><br><span class="line">plt.rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span>  <span class="comment"># 解决负号显示问题</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义模型参数</span></span><br><span class="line">N = <span class="number">1e6</span>  <span class="comment"># 总人口数 (用作初始条件，后面转换为相对密度)</span></span><br><span class="line">k_avg = <span class="number">20</span>  <span class="comment"># 平均度</span></span><br><span class="line">beta1 = <span class="number">0.06</span>  <span class="comment"># 谣言传播接触率</span></span><br><span class="line">beta2 = <span class="number">0.04</span>  <span class="comment"># 辟谣信息接触率</span></span><br><span class="line">xi1 = <span class="number">0.001</span>  <span class="comment"># 易感者直接变为谣言传播者的概率</span></span><br><span class="line">xi2 = <span class="number">0.001</span>  <span class="comment"># 易感者直接变为辟谣传播者的概率</span></span><br><span class="line">sigma1 = <span class="number">0.08</span>  <span class="comment"># 谣言接触者变为谣言传播者的概率</span></span><br><span class="line">sigma3 = <span class="number">0.06</span>  <span class="comment"># 辟谣接触者变为辟谣传播者的概率</span></span><br><span class="line">delta1 = <span class="number">0.001</span>  <span class="comment"># 谣言接触者免疫的概率</span></span><br><span class="line">delta2 = <span class="number">0.001</span>  <span class="comment"># 辟谣接触者免疫的概率</span></span><br><span class="line">alpha1 = <span class="number">0.02</span>  <span class="comment"># 谣言传播者受辟谣影响转为免疫的概率</span></span><br><span class="line">alpha2 = <span class="number">0.01</span>  <span class="comment"># 谣言接触者转为辟谣传播者的概率</span></span><br><span class="line">gamma1 = <span class="number">0.02</span>  <span class="comment"># 谣言传播者遗忘谣言的概率</span></span><br><span class="line">gamma2 = <span class="number">0.02</span>  <span class="comment"># 辟谣传播者遗忘的概率</span></span><br><span class="line">lambda_val = <span class="number">0.001</span>  <span class="comment"># 传播疲劳函数的衰减系数</span></span><br><span class="line">rho = <span class="number">0.01</span>  <span class="comment"># 谣言接触者受辟谣影响转为免疫的概率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义传播疲劳函数 φ(t)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fatigue</span>(<span class="params">t, lambda_val</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="number">1</span> - np.exp(-lambda_val * t)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义微分方程组</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">caseir_model</span>(<span class="params">y, t, k_avg, beta1, beta2, xi1, xi2, sigma1, sigma2, sigma3, delta1, delta2, alpha1, alpha2, gamma1,</span></span><br><span class="line"><span class="params">                 gamma2, lambda_val, rho</span>):</span><br><span class="line">    S, E1, E2, I1, I2, R1, R2 = y</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 传播疲劳函数 φ(t)</span></span><br><span class="line">    phi = fatigue(t, lambda_val)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 判断当前时间是否开启辟谣</span></span><br><span class="line">    <span class="keyword">if</span> t &lt; <span class="number">10</span>:</span><br><span class="line">        current_beta2 = <span class="number">0</span></span><br><span class="line">        current_alpha2 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        current_beta2 = beta2</span><br><span class="line">        current_alpha2 = alpha2</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 微分方程组</span></span><br><span class="line">    dSdt = -beta1 * S * I1 * k_avg - current_beta2 * S * I2 * k_avg - xi1 * S - xi2 * S</span><br><span class="line">    dE1dt = beta1 * S * I1 * k_avg - sigma1 * E1 - sigma2 * E1 - current_alpha2 * E1 * I2 * k_avg - delta1 * E1 - rho * E1</span><br><span class="line">    dE2dt = current_beta2 * S * I2 * k_avg - sigma3 * E2 - delta2 * E2</span><br><span class="line">    dI1dt = sigma1 * E1 + xi1 * S - gamma1 * I1 - alpha1 * I1 * I2 * k_avg - phi * I1</span><br><span class="line">    dI2dt = sigma2 * E1 + sigma3 * E2 + xi2 * S + current_alpha2 * E1 * I2 * k_avg - gamma2 * I2 - phi * I2</span><br><span class="line">    dR1dt = gamma1 * I1 + delta1 * E1 + alpha1 * I1 * I2 * k_avg + rho * E1</span><br><span class="line">    dR2dt = gamma2 * I2 + delta2 * E2</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> [dSdt, dE1dt, dE2dt, dI1dt, dI2dt, dR1dt, dR2dt]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始条件：S, E1, E2, I1, I2, R1, R2 的相对密度</span></span><br><span class="line">I1_initial = <span class="number">10</span> / N</span><br><span class="line">S_initial = <span class="number">1</span> - I1_initial  <span class="comment"># 初始所有人口都为易感者，除去谣言传播者的密度</span></span><br><span class="line">initial_conditions = [S_initial, <span class="number">0.0</span>, <span class="number">0.0</span>, I1_initial, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 时间范围</span></span><br><span class="line">t = np.linspace(<span class="number">0</span>, <span class="number">100</span>, <span class="number">1000</span>)  <span class="comment"># 模拟 100 天，1000 个时间点</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置不同的 σ2 值</span></span><br><span class="line">sigma2_values = [<span class="number">0.001</span>, <span class="number">0.005</span>, <span class="number">0.01</span>, <span class="number">0.015</span>, <span class="number">0.02</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 存储不同 σ2 值的结果</span></span><br><span class="line">I1_results = []</span><br><span class="line">I2_results = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对每个 σ2 进行仿真</span></span><br><span class="line"><span class="keyword">for</span> sigma2_val <span class="keyword">in</span> sigma2_values:</span><br><span class="line">    result = odeint(caseir_model, initial_conditions, t, args=(</span><br><span class="line">        k_avg, beta1, beta2, xi1, xi2, sigma1, sigma2_val, sigma3, delta1, delta2, alpha1, alpha2, gamma1, gamma2, lambda_val, rho))</span><br><span class="line"></span><br><span class="line">    I1_results.append(result[:, <span class="number">3</span>])  <span class="comment"># 保存 I1 的结果</span></span><br><span class="line">    I2_results.append(result[:, <span class="number">4</span>])  <span class="comment"># 保存 I2 的结果</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制不同 σ2 对谣言传播者 I1 的影响</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i, sigma2_val <span class="keyword">in</span> <span class="built_in">enumerate</span>(sigma2_values):</span><br><span class="line">    plt.plot(t, I1_results[i], label=<span class="string">f&quot;σ2=<span class="subst">&#123;sigma2_val&#125;</span>&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;时间 (天)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;谣言传播者 I1 的密度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;不同谣言逆转率 σ2 对谣言传播者 I1 的影响&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure9021.png&#x27;</span></span><br><span class="line">plt.savefig(G_patch)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制不同 σ2 对辟谣传播者 I2 的影响</span></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i, sigma2_val <span class="keyword">in</span> <span class="built_in">enumerate</span>(sigma2_values):</span><br><span class="line">    plt.plot(t, I2_results[i], label=<span class="string">f&quot;σ2=<span class="subst">&#123;sigma2_val&#125;</span>&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;时间 (天)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;辟谣传播者 I2 的密度&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;不同谣言逆转率 σ2 对辟谣传播者 I2 的影响&quot;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid()</span><br><span class="line">G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure9022.png&#x27;</span></span><br><span class="line">plt.savefig(G_patch)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure9021.png" alt="figure9021"></p>
<p><img src="images/figure9022.png" alt=""></p>
<p><a href="./File/Information Propagation in Hypergraph-Based Social Networks.pdf">Information Propagation in Hypergraph-Based Social Networks.pdf</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2024/10/09/%E8%AE%BA%E6%96%87%E7%9F%A5%E8%AF%86%E7%82%B9/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/10/09/%E8%AE%BA%E6%96%87%E7%9F%A5%E8%AF%86%E7%82%B9/" class="post-title-link" itemprop="url">论文知识点</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-10-09 10:11:02" itemprop="dateCreated datePublished" datetime="2024-10-09T10:11:02+08:00">2024-10-09</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-10-16 22:20:24" itemprop="dateModified" datetime="2024-10-16T22:20:24+08:00">2024-10-16</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%8D%E6%9D%82%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">复杂网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h1><h2 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h2><h3 id="一、超网络的结构测度指标体系"><a href="#一、超网络的结构测度指标体系" class="headerlink" title="一、超网络的结构测度指标体系"></a>一、超网络的结构测度指标体系</h3><p>超网络（<strong>hypernetwork</strong>）的结构测度指标体系是网络科学中的一个研究热点，旨在宽松和分析超网络的结构特性。超网络是一种特殊类型的网络，其中的边可以连接多个节点，而不仅仅是节点。这种复杂性的关系拓展了两个传统图论的边连接形式，因此需要专门的测度指标来描述其结构。</p>
<p>以下是一些常用的超网络结构测度指标：</p>
<h4 id="1-度分布（Degree-Distribution）"><a href="#1-度分布（Degree-Distribution）" class="headerlink" title="1.度分布（Degree Distribution）"></a>1.<strong>度分布（Degree Distribution）</strong></h4><ul>
<li><h5 id="节点度（Node-Degree）：表示一个节点参与的超边数量。在超网络中，节点的度可以表示为其参与的超边数量。"><a href="#节点度（Node-Degree）：表示一个节点参与的超边数量。在超网络中，节点的度可以表示为其参与的超边数量。" class="headerlink" title="节点度（Node Degree）：表示一个节点参与的超边数量。在超网络中，节点的度可以表示为其参与的超边数量。"></a><strong>节点度（Node Degree）</strong>：表示一个节点参与的超边数量。在超网络中，节点的度可以表示为其参与的超边数量。</h5></li>
<li><h5 id="超边度（Hyperedge-Degree）：表示每个超边连接的节点数量，也即每条超边的维度大小。"><a href="#超边度（Hyperedge-Degree）：表示每个超边连接的节点数量，也即每条超边的维度大小。" class="headerlink" title="超边度（Hyperedge Degree）：表示每个超边连接的节点数量，也即每条超边的维度大小。"></a><strong>超边度（Hyperedge Degree）</strong>：表示每个超边连接的节点数量，也即每条超边的维度大小。</h5></li>
</ul>
<h4 id="2-节点中心性（Node-Centrality）"><a href="#2-节点中心性（Node-Centrality）" class="headerlink" title="2.节点中心性（Node Centrality）"></a>2.<strong>节点中心性（Node Centrality）</strong></h4><p>是图论中的一个基本概念，用于衡量网络中某个节点的重要性或影响力。中心度指标反映了一个节点在网络结构中的相对位置和作用，不同的中心度定义从不同角度衡量节点的重要性。</p>
<ul>
<li><strong>度中心性（Degree Centrality）</strong>：根据节点参与的超边数量来降低其重要性。</li>
<li><strong>接近中心性（Closeness Centrality）</strong>：通过计算节点与其他节点的最短路径距离，反映节点的传递效率。</li>
<li><strong>内部中心性（Betweenness Centrality）</strong>：一个反映节点在最短路径中充当“桥梁”的程度，即该节点在网络中信息流动的枢纽角色。</li>
</ul>
<h4 id="3-聚类系数（Clustering-Coefficient）"><a href="#3-聚类系数（Clustering-Coefficient）" class="headerlink" title="3.聚类系数（Clustering Coefficient）"></a>3.<strong>聚类系数（Clustering Coefficient）</strong></h4><p>传统网络中的迭代次数被用于计算节点间和邻居节点之间的加权程度。而在超网络中，迭代次数的定义更复杂，可能涉及计算节点间通过共享超边进行连接的概率。</p>
<h4 id="4-模块性（Modularity）"><a href="#4-模块性（Modularity）" class="headerlink" title="4.模块性（Modularity）"></a>4.<strong>模块性（Modularity）</strong></h4><p>模块性用于最简单网络中的社区结构，即网络能否划分为若干模块或子群体，使得相同模块内的节点比外部模块之间的节点连接更紧密。超网络中的模块性测度可以扩展为考虑多节点超边的影响。</p>
<h4 id="5-连通性（Connectivity）"><a href="#5-连通性（Connectivity）" class="headerlink" title="5.连通性（Connectivity）"></a>5.<strong>连通性（Connectivity）</strong></h4><p>替代性是指网络中节点通过超边的连接情况：</p>
<ul>
<li><strong>强干扰性（Strong Connectivity）</strong>：表示是否存在强弱的子图，使得所有节点都通过超边相互相邻。</li>
<li><strong>弱感知性（Weak Connectivity）</strong>：不要求所有节点之间都直接关联，而是可以通过多跳超边连通。</li>
</ul>
<h4 id="6-路径长度（Path-Length）"><a href="#6-路径长度（Path-Length）" class="headerlink" title="6.路径长度（Path Length）"></a>6.<strong>路径长度（Path Length）</strong></h4><p>在超网络中，路径长度可以通过多个节点的超边来定义和关注。例如，在两个节点间，是否存在通过一系列超边的路径。</p>
<h4 id="7-超边的覆盖度和重叠度（Hyperedge-Coverage-and-Overlap）"><a href="#7-超边的覆盖度和重叠度（Hyperedge-Coverage-and-Overlap）" class="headerlink" title="7.超边的覆盖度和重叠度（Hyperedge Coverage and Overlap）"></a>7.<strong>超边的覆盖度和重叠度（Hyperedge Coverage and Overlap）</strong></h4><ul>
<li><strong>覆盖度</strong>：最小网络中的节点被超边覆盖的程度。即某个节点的所有可能的邻居是否都在节点条父条超边中。</li>
<li><strong>重叠度</strong>：不同超边之间的节点重叠程度，表示网络中节点在多个超边之间共享的程度。</li>
</ul>
<h4 id="8-子结构与模式识别（子结构和基序分析）"><a href="#8-子结构与模式识别（子结构和基序分析）" class="headerlink" title="8.子结构与模式识别（子结构和基序分析）"></a>8.<strong>子结构与模式识别（子结构和基序分析）</strong></h4><p>超网络中的子结构或模式分析旨在识别网络中经常出现的结构特征。这可以帮助我们了解超网络的功能特性或设置规律。</p>
<h4 id="9-信息传播效率（Information-Diffusion-Efficiency）"><a href="#9-信息传播效率（Information-Diffusion-Efficiency）" class="headerlink" title="9.信息传播效率（Information Diffusion Efficiency）"></a>9.<strong>信息传播效率（Information Diffusion Efficiency）</strong></h4><p>信息传播的效率是指信息在超网络中通过节点和超边缘传播的速度和范围。这涉及计算信息在不同超网络结构中的传播路径和扩散模型。</p>
<h4 id="10-超边维度（Hyperedge-Dimension）"><a href="#10-超边维度（Hyperedge-Dimension）" class="headerlink" title="10.超边维度（Hyperedge Dimension）"></a>10.<strong>超边维度（Hyperedge Dimension）</strong></h4><p>超边维度是超网络中超边连接的节点数量的分布情况，它反映了每条超边的复杂程度。</p>
<p>这些结构测度指标有助于研究人员理解超网络的复杂性和行为，尤其是在大规模、多层次的网络关系中，这些指标可以揭示隐藏的网络模式或特性。</p>
<h3 id="二、强度、超边度、超边强度、超边基数等概念的定义和内涵"><a href="#二、强度、超边度、超边强度、超边基数等概念的定义和内涵" class="headerlink" title="二、强度、超边度、超边强度、超边基数等概念的定义和内涵"></a>二、强度、超边度、超边强度、超边基数等概念的定义和内涵</h3><p>超网络中，<strong>强度</strong>、<strong>超边度</strong>、<strong>超边强度</strong>、和<strong>超边基数</strong>等概念都是用来描述节点和超边之间复杂关系的关键指标。它们与传统网络中的概念有所不同，具体的定义和内涵如下：</p>
<h4 id="1-强度（Strength）"><a href="#1-强度（Strength）" class="headerlink" title="1. 强度（Strength）"></a>1. <strong>强度（Strength）</strong></h4><p>   在超网络中，节点的强度通常是指一个节点与其他节点通过超边相连接的<strong>总权重</strong>。这一概念与传统网络中的“节点强度”相似，但在超网络中，超边的权重可以根据连接的节点数、连接的重要性等进行加权计算。</p>
<ul>
<li><strong>定义</strong>：某个节点强度是该节点所参与的超边的权重之和。</li>
<li><strong>内涵</strong>：强度描述了节点在网络中的参与度和影响力，强度越大，表明该节点在网络中与其他节点的关联越多或越强。</li>
</ul>
<h4 id="2-超边度（Hyperedge-Degree）"><a href="#2-超边度（Hyperedge-Degree）" class="headerlink" title="2. 超边度（Hyperedge Degree）"></a>2. <strong>超边度（Hyperedge Degree）</strong></h4><p>   超边度是指某个超边中所包含的<strong>节点的数量</strong>。在传统网络中，一条边连接两个节点，而在超网络中，超边可以连接多个节点，因此超边度描述了这条超边的“多度性”。</p>
<ul>
<li><strong>定义</strong>：某条超边度是该超边所连接的节点数量。</li>
<li><strong>内涵</strong>：超边度反映了超边的复杂程度，也可以反映超边在网络中连接多个节点的能力，超边度越高，表示该超边涉及的节点越多。</li>
</ul>
<h4 id="3-超边强度（Hyperedge-Strength）"><a href="#3-超边强度（Hyperedge-Strength）" class="headerlink" title="3. 超边强度（Hyperedge Strength）"></a>3. <strong>超边强度（Hyperedge Strength）</strong></h4><p>   超边强度表示的是某一超边的<strong>总权重</strong>。这一概念与节点强度类似，但针对的是超边本身。超边强度可以通过超边连接的节点间的交互频率、关系重要性等因素来加权计算。</p>
<ul>
<li><strong>定义</strong>：某条超边强度是该超边中所有节点对之间关系的权重总和。</li>
<li><strong>内涵</strong>：超边强度反映了超边中节点之间关联的强弱程度，强度越高，说明该超边内节点的关系越紧密或相互影响力越大。</li>
</ul>
<h4 id="4-超边基数（Hyperedge-Cardinality）"><a href="#4-超边基数（Hyperedge-Cardinality）" class="headerlink" title="4. 超边基数（Hyperedge Cardinality）"></a>4. <strong>超边基数（Hyperedge Cardinality）</strong></h4><p>   超边基数是超网络中的一个基础概念，指的是某一条超边连接的<strong>节点的数目</strong>。与超边度相似，但“基数”更侧重于表示这条超边在形式上的“连接数量”属性，而非具体的网络结构含义。</p>
<ul>
<li><strong>定义</strong>：超边基数是指某条超边所连接的节点数量。</li>
<li><strong>内涵</strong>：超边基数是一个纯粹的集合论概念，直接反映了超边的规模。它与超边度的内涵相似，但可以更直接地用于一些集合论形式化的分析中。</li>
</ul>
<h4 id="这四个概念的关系："><a href="#这四个概念的关系：" class="headerlink" title="这四个概念的关系："></a>这四个概念的关系：</h4><ol>
<li><strong>强度</strong>和<strong>超边强度</strong>都涉及权重，但强度是针对<strong>节点</strong>，而超边强度是针对<strong>超边</strong>。</li>
<li><strong>超边度</strong>和<strong>超边基数</strong>都描述了超边的节点数目，两者在定义上非常接近，但基数通常在集合论上下文中使用，表示形式化的节点数，而超边度则更多用于结构性分析。</li>
<li>强度和超边度共同影响网络的整体拓扑结构，尤其是在研究网络中节点的影响力或网络中的信息传递时，它们是重要的衡量指标。</li>
</ol>
<p>这些指标对于理解超网络的复杂结构非常重要，有助于揭示节点在超网络中扮演的角色以及节点之间关系的强度。</p>
<h3 id="三、聚集指标"><a href="#三、聚集指标" class="headerlink" title="三、聚集指标"></a>三、聚集指标</h3><p><strong>聚集指标（Aggregation Measures）</strong> 是用来衡量网络中节点及其邻居之间的连通性或凝聚性，通常用来描述节点之间形成紧密团体或子结构的程度。在网络科学中，聚集性是理解节点间局部结构特性的一个重要方面，尤其是在社交网络或合作网络中，它反映了节点间相互依赖或协作的强度。</p>
<p>对于<strong>传统网络</strong>，最常见的聚集性指标是<strong>聚类系数（Clustering Coefficient）</strong>，而在<strong>超网络</strong>中，由于超边可以连接多个节点，聚集性指标的计算和含义会更加复杂。下面是聚集性相关的主要指标和它们的内涵：</p>
<h4 id="1-聚类系数（Clustering-Coefficient）"><a href="#1-聚类系数（Clustering-Coefficient）" class="headerlink" title="1. 聚类系数（Clustering Coefficient）"></a>1. <strong>聚类系数（Clustering Coefficient）</strong></h4><p>   聚类系数衡量网络中节点的邻居之间互相连接的紧密程度。它是局部聚集性的常用度量，通常分为以下两种类型：</p>
<ul>
<li><p><strong>局部聚类系数（Local Clustering Coefficient）</strong>：</p>
<ul>
<li><strong>定义</strong>：对于某个节点，局部聚类系数是其邻居节点之间实际存在的连边数量与可能存在的连边数量的比值。</li>
<li><strong>内涵</strong>：局部聚类系数反映了某个节点周围形成“团体”或“圈子”的程度。值越大，说明该节点的邻居节点之间的连接越紧密。</li>
<li><strong>公式</strong>（传统网络）：<br><img src="./images/efigure02.png" alt="图" style="zoom:50%;" /></li>
</ul>
</li>
<li><p><strong>全局聚类系数（Global Clustering Coefficient）</strong>：</p>
<ul>
<li><strong>定义</strong>：全局聚类系数是网络中所有节点的局部聚类系数的平均值，或者通过三角形与三节点子图的比例来计算。</li>
<li><strong>内涵</strong>：全局聚类系数反映整个网络中的聚集性特征，描述网络整体上节点是否倾向于形成聚集的小团体。</li>
</ul>
</li>
</ul>
<p>   在<strong>超网络</strong>中，聚类系数的计算更加复杂，因为超边可以连接多个节点。常见的扩展方式包括：</p>
<ul>
<li><strong>超边聚类系数（Hyperedge Clustering Coefficient）</strong>：基于共享超边来定义，计算节点与其邻居之间通过共同超边连接的概率。</li>
<li><strong>超网络的高阶聚集性</strong>：考虑超边与超边之间的相互交叠和共享节点的关系，用来描述超边之间的紧密度。</li>
</ul>
<h4 id="2-三角形闭合率（Triangle-Closure-Rate）"><a href="#2-三角形闭合率（Triangle-Closure-Rate）" class="headerlink" title="2. 三角形闭合率（Triangle Closure Rate）"></a>2. <strong>三角形闭合率（Triangle Closure Rate）</strong></h4><ul>
<li><strong>定义</strong>：三角形闭合率是网络中两两节点与第三个共同邻居形成三角形的概率。它是另一种衡量聚集性的指标，尤其在社交网络中，朋友的朋友往往也会成为朋友，这种现象就体现在三角形闭合率上。</li>
<li><strong>超网络中的扩展</strong>：超网络中的三角形闭合可以扩展为多节点子结构的闭合，或者通过分析某些节点与其他多个节点共同形成的紧密结构来计算。</li>
</ul>
<h4 id="3-模块度（Modularity）"><a href="#3-模块度（Modularity）" class="headerlink" title="3. 模块度（Modularity）"></a>3. <strong>模块度（Modularity）</strong></h4><p>   虽然模块度通常用于衡量网络的社区结构，但它也与聚集性紧密相关，因为高模块度的网络意味着网络中存在高度聚集的子群体。模块度高的网络倾向于形成社区，即网络中的节点分为若干个内部连接紧密而外部连接稀疏的群体。</p>
<ul>
<li><strong>定义</strong>：模块度通过衡量网络中的实际边数与随机分配边数之间的差异，来评价网络划分为社区的优劣。</li>
<li><strong>公式</strong>：<br><img src="./images/efigure01.png" alt="图1"></li>
</ul>
<h4 id="4-超边重叠度（Hyperedge-Overlap）"><a href="#4-超边重叠度（Hyperedge-Overlap）" class="headerlink" title="4. 超边重叠度（Hyperedge Overlap）"></a>4. <strong>超边重叠度（Hyperedge Overlap）</strong></h4><ul>
<li><strong>定义</strong>：超边重叠度反映超网络中不同超边之间共享节点的程度。两个超边之间如果共享更多的节点，它们之间的重叠度就越高。</li>
<li><strong>内涵</strong>：超边重叠度是超网络中高阶聚集性的反映，说明网络中的节点倾向于通过多个超边彼此紧密联系。</li>
</ul>
<h4 id="5-社团系数（Community-Coefficient）"><a href="#5-社团系数（Community-Coefficient）" class="headerlink" title="5. 社团系数（Community Coefficient）"></a>5. <strong>社团系数（Community Coefficient）</strong></h4><ul>
<li><strong>定义</strong>：社团系数是描述网络中节点聚集成若干社区的能力。它是通过分析网络的模块结构，计算网络在不同社区中节点连接的紧密程度。</li>
<li><strong>内涵</strong>：社团系数较高意味着网络有明显的聚集性，形成了多个社区或群体。</li>
</ul>
<h4 id="6-凝聚子图（Cohesive-Subgraphs）"><a href="#6-凝聚子图（Cohesive-Subgraphs）" class="headerlink" title="6. 凝聚子图（Cohesive Subgraphs）"></a>6. <strong>凝聚子图（Cohesive Subgraphs）</strong></h4><ul>
<li><strong>定义</strong>：凝聚子图是指节点之间相互连接紧密的子结构。k-核心（k-core）是一个典型的凝聚子图，它是由所有度至少为 ( k ) 的节点及其连边构成的子图。</li>
<li><strong>内涵</strong>：凝聚子图反映了网络中节点局部聚集性，k-核心分析可以帮助识别网络中高度凝聚的子结构。</li>
</ul>
<h4 id="7-过度连通性（Hyperconnectivity）"><a href="#7-过度连通性（Hyperconnectivity）" class="headerlink" title="7. 过度连通性（Hyperconnectivity）"></a>7. <strong>过度连通性（Hyperconnectivity）</strong></h4><ul>
<li><strong>定义</strong>：过度连通性是超网络中节点通过超边的连接程度，即节点之间不仅通过直接超边相连，而且与多个其他节点共享相同的超边，形成紧密的聚集结构。</li>
<li><strong>内涵</strong>：过度连通性体现了超网络中节点间多维度的连接关系，反映了网络的复杂聚集性。</li>
</ul>
<h4 id="8-超网络的k-核心（k-core-in-Hypernetwork）"><a href="#8-超网络的k-核心（k-core-in-Hypernetwork）" class="headerlink" title="8. 超网络的k-核心（k-core in Hypernetwork）"></a>8. <strong>超网络的k-核心（k-core in Hypernetwork）</strong></h4><ul>
<li><strong>定义</strong>：超网络中的k-核心是由所有度至少为 ( k ) 的节点构成的子结构，它表示节点的局部密集区域。由于超网络中的边可以是多节点连接，因此k-核心的定义需要扩展以适应超边的复杂性。</li>
<li><strong>内涵</strong>：超网络的k-核心分析帮助识别网络中最具凝聚力的区域，通常用于识别网络中最核心的子群体。</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>聚集指标反映了网络中的节点及其邻居之间的连通性，尤其在超网络中，这种聚集性更为复杂，涉及多个节点通过超边进行连接的多维度结构。通过这些聚集性指标，我们可以更深入地理解网络的局部特性和群体结构，从而发现隐藏在网络中的紧密关系和社区模式。</p>
<h3 id="四、超边相似性的个性化推荐框架"><a href="#四、超边相似性的个性化推荐框架" class="headerlink" title="四、超边相似性的个性化推荐框架"></a>四、超边相似性的个性化推荐框架</h3><p>在超网络中，<strong>超边相似性</strong>可以为个性化推荐提供新的视角。与传统网络中基于节点之间的连接不同，超网络中的超边连接多个节点，因此可以捕捉到多节点之间的复杂关系。这使得基于超边相似性构建的个性化推荐框架更适合复杂数据集中的推荐任务，如社交媒体、电子商务、科研合作等场景。</p>
<p>超边相似性在个性化推荐中可以通过度量用户或物品的行为模式相似性，从而为用户提供更为精准的推荐。以下是超边相似性推荐框架的核心组成部分：</p>
<h4 id="1-数据表示与超网络构建"><a href="#1-数据表示与超网络构建" class="headerlink" title="1. 数据表示与超网络构建"></a>1. <strong>数据表示与超网络构建</strong></h4><p>   在个性化推荐系统中，数据通常包含用户与物品的交互，如用户点击、购买、评论等。在超网络中，这些交互可以通过<strong>超边</strong>来表示，例如：</p>
<ul>
<li>用户-物品-类别的多重关系可以构建为超网络中的一个超边，连接用户、物品以及其类别标签。</li>
<li><p>用户之间共享的行为（如共同参与某个活动）也可以通过超边表示，超边连接了所有参与同一活动的用户。</p>
<p><strong>步骤</strong>：</p>
</li>
<li><strong>节点表示</strong>：用户、物品和相关属性（如类别、标签等）作为超网络的节点。</li>
<li><strong>超边构建</strong>：通过分析用户行为的共同特征（如同时购买的物品或参与的活动），构建超边，将多个相关节点连接起来。</li>
</ul>
<h4 id="2-超边相似性计算"><a href="#2-超边相似性计算" class="headerlink" title="2. 超边相似性计算"></a>2. <strong>超边相似性计算</strong></h4><p>   要进行个性化推荐，关键是定义和计算超边的相似性。超边相似性可以通过以下方法计算：</p>
<ul>
<li><p><strong>基于节点的相似性</strong>：</p>
<ul>
<li><strong>节点交叠度</strong>：如果两个超边共享相同的节点（例如，用户参与了多个相同的物品），可以认为它们具有较高的相似性。相似性可以通过计算超边共享节点的数量来定义：<br><img src="./images/efigure03.png" alt="图3"></li>
</ul>
</li>
<li><p><strong>基于特征向量的相似性</strong>：</p>
<ul>
<li>对每个超边中的节点进行嵌入表示，将节点的属性和行为编码为向量。然后使用余弦相似性、欧几里得距离等方法计算超边之间的相似性：<br><img src="./images/efigure04.png" alt="图4"></li>
</ul>
</li>
<li><p><strong>基于信息传播的相似性</strong>：</p>
<ul>
<li>考虑超网络中信息传播的路径。如果信息从一个超边传播到另一个超边的效率较高（例如通过短路径、多节点传播等），那么可以认为它们相似性较高。信息传播效率可以通过随机游走、图卷积等方法进行计算。</li>
</ul>
</li>
</ul>
<h4 id="3-推荐算法设计"><a href="#3-推荐算法设计" class="headerlink" title="3. 推荐算法设计"></a>3. <strong>推荐算法设计</strong></h4><p>基于超边相似性，可以设计多种个性化推荐算法，核心思想是利用相似的超边来为用户生成个性化的推荐列表：</p>
<ul>
<li><p><strong>基于邻居的协同过滤（Neighborhood-based Collaborative Filtering）</strong>：</p>
<ul>
<li>为每个用户构建一个包含与其相关的超边集合，基于这些超边找到与之最相似的超边集合。然后推荐这些相似超边中的物品或服务给用户。</li>
<li>具体步骤：先找到用户所在的超边，然后根据超边相似性找到最相似的超边，从中提取新的物品并推荐给用户。</li>
</ul>
</li>
<li><p><strong>矩阵分解方法（Matrix Factorization）</strong>：</p>
<ul>
<li>将超网络中的节点和超边转化为用户-物品矩阵，通过矩阵分解来学习潜在的用户和物品的特征表示。通过超边的相似性，优化矩阵分解过程，预测用户对未见物品的评分。</li>
<li>与传统矩阵分解不同，超边的高维连接性使得在分解过程中需要考虑更多的上下文信息，适合捕捉复杂的用户行为模式。</li>
</ul>
</li>
<li><p><strong>图嵌入与深度学习（Graph Embedding &amp; Deep Learning）</strong>：</p>
<ul>
<li>基于超边构建用户和物品的特征向量，通过深度学习模型（如图神经网络 GNN）对超网络进行嵌入学习。通过训练模型学习到节点和超边的高维表示，然后基于超边相似性进行推荐。</li>
<li>例如，使用图卷积网络（GCN）在超网络中传播信息，更新节点的嵌入表示，从而更好地捕捉用户和物品之间的复杂关系。</li>
</ul>
</li>
</ul>
<h4 id="4-个性化推荐生成"><a href="#4-个性化推荐生成" class="headerlink" title="4. 个性化推荐生成"></a>4. <strong>个性化推荐生成</strong></h4><ul>
<li><strong>Top-N推荐</strong>：基于超边相似性，为每个用户生成与其行为最相关的超边推荐列表，然后从这些超边中提取出最有可能吸引用户的物品，最终生成Top-N推荐列表。</li>
<li><strong>推荐多样性</strong>：通过控制推荐中的超边相似性阈值，增加推荐结果的多样性。例如，除了推荐与用户行为最相似的超边，也可以适当推荐相似度较低但潜在兴趣较大的超边。</li>
</ul>
<h4 id="5-评价与优化"><a href="#5-评价与优化" class="headerlink" title="5. 评价与优化"></a>5. <strong>评价与优化</strong></h4><ul>
<li><strong>精确率和召回率</strong>：衡量推荐系统的准确性，精确率反映推荐结果的准确程度，召回率表示推荐覆盖了多少用户潜在感兴趣的物品。</li>
<li><strong>覆盖率</strong>：衡量系统推荐的物品范围是否广泛，即推荐是否过于集中于少数流行物品。</li>
<li><strong>新颖性与多样性</strong>：评价系统是否能够推荐给用户一些新颖的或不太常见的物品，避免推荐同质化。</li>
</ul>
<h4 id="案例应用："><a href="#案例应用：" class="headerlink" title="案例应用："></a>案例应用：</h4><ol>
<li><strong>电商推荐</strong>：在电子商务平台中，超边可以表示用户的购物行为和商品的多属性信息（如品牌、类别）。基于超边相似性，可以为用户推荐符合其历史购买偏好的新商品。</li>
<li><strong>社交媒体推荐</strong>：在社交媒体中，超边可以表示用户的社交群体和内容互动行为（如共同参与的活动、点赞的内容等）。基于超边相似性，可以推荐用户感兴趣的帖子、群组或好友。</li>
</ol>
<h4 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h4><p>基于超边相似性的个性化推荐框架通过分析用户、物品及其复杂的多维关系，能够捕捉到传统网络难以揭示的用户兴趣模式和行为特征。这一框架在电子商务、社交媒体、科研合作等多个领域具有广泛的应用潜力，并且能够通过灵活的超网络构建和相似性度量方法，进一步提高推荐系统的精准性和多样性。</p>
<h3 id="五、合作网络、竞争网络、交通网络"><a href="#五、合作网络、竞争网络、交通网络" class="headerlink" title="五、合作网络、竞争网络、交通网络"></a>五、合作网络、竞争网络、交通网络</h3><p><strong>合作网络</strong>、<strong>竞争网络</strong>和<strong>交通网络</strong>是复杂网络研究中的典型应用领域，它们反映了不同系统中节点（如个体、组织或地点）之间的特定交互关系。以下是对这三类网络的介绍及其主要特性：</p>
<h4 id="1-合作网络（Collaboration-Network）"><a href="#1-合作网络（Collaboration-Network）" class="headerlink" title="1. 合作网络（Collaboration Network）"></a>1. <strong>合作网络（Collaboration Network）</strong></h4><p>   <strong>定义</strong>：合作网络是描述个体或组织之间协作关系的网络，节点代表个体或组织，边表示它们之间的合作关系。这类网络常见于科研、商业和创新等领域。</p>
<p>   <strong>应用场景</strong>：</p>
<ul>
<li><strong>科研合作</strong>：科研人员之间的合作构成了典型的合作网络，边表示他们在同一篇论文或项目上的合作。</li>
<li><strong>商业合作</strong>：企业或公司之间的合作、联盟构成商业合作网络，例如公司共同开发产品、分享技术。</li>
<li><p><strong>创新生态系统</strong>：在技术创新领域，企业、研发机构等通过合作共同推动创新，形成复杂的合作网络。</p>
<p><strong>特性</strong>：</p>
</li>
<li><strong>高聚集性</strong>：在合作网络中，合作伙伴往往倾向于形成三角关系或更紧密的团体，合作网络的聚集系数较高。</li>
<li><strong>中心性</strong>：一些节点（如科研领军人物、核心企业）会成为合作网络的中心节点，拥有较高的度和中心性。</li>
<li><p><strong>小世界效应</strong>：合作网络通常表现出小世界效应，意味着通过少数中介节点，两个任意节点之间的距离很短。</p>
<p><strong>研究方法</strong>：</p>
</li>
<li><strong>节点中心性分析</strong>：识别网络中最具影响力的个体或组织（如具有高度中心性的科研人员或企业）。</li>
<li><strong>社团检测</strong>：分析网络中的合作群体，找出具有紧密合作关系的子网络（如科研领域中的特定研究团队）。</li>
</ul>
<h4 id="2-竞争网络（Competition-Network）"><a href="#2-竞争网络（Competition-Network）" class="headerlink" title="2. 竞争网络（Competition Network）"></a>2. <strong>竞争网络（Competition Network）</strong></h4><p>   <strong>定义</strong>：竞争网络描述个体或组织之间的竞争关系。节点代表竞争主体（如企业、个体等），边表示它们之间的竞争。与合作网络不同，竞争网络中的关系具有对抗性。</p>
<p>   <strong>应用场景</strong>：</p>
<ul>
<li><strong>市场竞争</strong>：企业之间在产品市场上的竞争，边表示企业之间争夺同一市场份额的关系。</li>
<li><strong>生态竞争</strong>：在生物学中，物种之间为资源而竞争也构成竞争网络，物种通过争夺栖息地、食物等资源进行竞争。</li>
<li><p><strong>社交竞争</strong>：个人在社交网络中的地位竞争，例如影响力、关注度的争夺，形成竞争关系。</p>
<p><strong>特性</strong>：</p>
</li>
<li><strong>异质性</strong>：竞争网络通常由不同规模、不同实力的节点构成，节点的度分布可能高度不均匀，少数节点（如行业巨头）可能与许多节点存在竞争关系。</li>
<li><strong>对抗性结构</strong>：竞争网络中的关系更多表现为负向关系（即“竞争”），而不是协作；因此，网络中可能会形成相互竞争的团体或结构。</li>
<li><p><strong>权力法则分布</strong>：竞争网络中的度分布常常遵循幂律分布，表明大多数节点只有少数竞争对手，而少数节点有大量的竞争对手。</p>
<p><strong>研究方法</strong>：</p>
</li>
<li><strong>对抗性图模型</strong>：使用正负边表示竞争和合作关系的对抗性图来分析竞争网络中的动态变化和稳定结构。</li>
<li><strong>博弈论分析</strong>：在竞争网络中，通过博弈论分析参与者的竞争策略，预测网络中竞争平衡的演化趋势。</li>
</ul>
<h4 id="3-交通网络（Transportation-Network）"><a href="#3-交通网络（Transportation-Network）" class="headerlink" title="3. 交通网络（Transportation Network）"></a>3. <strong>交通网络（Transportation Network）</strong></h4><p>   <strong>定义</strong>：交通网络描述了地理位置之间的运输或通信连接，节点代表地点（如城市、站点），边代表连接这些地点的交通路线（如道路、铁路、航线等）。交通网络广泛存在于实际生活中的各种运输和物流系统中。</p>
<p>   <strong>应用场景</strong>：</p>
<ul>
<li><strong>城市交通系统</strong>：城市中的公交线路、地铁线路、道路系统构成了典型的交通网络，边表示站点之间的道路或轨道连接。</li>
<li><strong>航空网络</strong>：机场之间的航班航线构成了全球航空交通网络，节点是机场，边表示航线。</li>
<li><p><strong>物流网络</strong>：企业的供应链或物流网络也是一种交通网络，节点为仓库或配送中心，边表示货物的运输路径。</p>
<p><strong>特性</strong>：</p>
</li>
<li><strong>空间嵌入性</strong>：交通网络中的节点和边通常依赖于空间位置，网络中的连接与地理距离有关。</li>
<li><strong>网络效率</strong>：交通网络的效率非常重要，它衡量货物、人员或信息能否快速、便捷地从一个节点传递到另一个节点。</li>
<li><p><strong>层级结构</strong>：交通网络往往具有层级结构，少数枢纽节点（如大型机场或交通枢纽）承担着连接大量边的作用，而大多数节点与枢纽节点相连。</p>
<p><strong>研究方法</strong>：</p>
</li>
<li><strong>最短路径算法</strong>：交通网络中最常用的分析方法，用于寻找节点之间的最优路径，以最小化运输成本或时间。</li>
<li><strong>网络鲁棒性分析</strong>：分析交通网络在面对突发事件（如道路中断、天气影响等）时的稳定性和应对能力。</li>
<li><strong>中心性分析</strong>：识别交通网络中的重要节点（如交通枢纽），这些节点往往具有较高的度中心性或介数中心性。</li>
</ul>
<h4 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h4><ul>
<li><strong>合作网络</strong>强调个体或组织间的协作与共赢关系，常见于科研、商业等领域，具有高聚集性和小世界效应。</li>
<li><strong>竞争网络</strong>侧重于个体或组织间的竞争与对抗关系，广泛存在于经济、生态等系统中，具有异质性和对抗性。</li>
<li><strong>交通网络</strong>则描述了地理位置之间的连接，重点在于如何高效、安全地进行运输或通信，通常依赖于空间嵌入性和层级结构。</li>
</ul>
<p>三者的主要区别在于节点之间的关系性质：合作网络以协作为主，竞争网络以对抗为主，而交通网络则注重连接与运输效率。这三种网络的研究对理解复杂系统中的不同交互模式具有重要意义。</p>
<h3 id="六、网络演化的因素"><a href="#六、网络演化的因素" class="headerlink" title="六、网络演化的因素"></a>六、网络演化的因素</h3><p>驱动网络演化的因素是指影响网络结构随时间变化的主要原因或机制。不同类型的网络（如合作网络、竞争网络、社交网络、生态网络等）会受到不同的因素驱动，但通常以下几个关键因素在多种网络演化过程中起着重要作用：</p>
<h4 id="1-节点增长（Node-Growth）"><a href="#1-节点增长（Node-Growth）" class="headerlink" title="1. 节点增长（Node Growth）"></a>1. <strong>节点增长（Node Growth）</strong></h4><p><strong>定义</strong>：网络中的新节点不断加入，导致网络规模逐渐扩大。</p>
<p><strong>影响</strong>：</p>
<ul>
<li><strong>社交网络</strong>：随着时间推移，新用户不断加入社交平台，形成新的连接关系，网络规模迅速扩展。</li>
<li><strong>交通网络</strong>：新城市、站点的加入扩展了网络的地理覆盖范围，增加了交通线路的复杂性。</li>
<li><strong>科研合作网络</strong>：随着新研究人员进入某个领域，他们与现有科研人员合作，形成新的合作关系。</li>
</ul>
<p><strong>机制</strong>：</p>
<ul>
<li><strong>优先连接机制</strong>：即“富者愈富”现象，新节点倾向于连接已有网络中的高度中心节点，导致度分布呈现幂律分布，这种机制广泛存在于互联网、社交网络、科学合作网络等系统中。</li>
</ul>
<h4 id="2-边的重组和丢失（Edge-Rewiring-and-Loss）"><a href="#2-边的重组和丢失（Edge-Rewiring-and-Loss）" class="headerlink" title="2. 边的重组和丢失（Edge Rewiring and Loss）"></a>2. <strong>边的重组和丢失（Edge Rewiring and Loss）</strong></h4><p><strong>定义</strong>：现有的连接（边）可以被重新排列或丢失，改变了网络中的连接结构。</p>
<p><strong>影响</strong>：</p>
<ul>
<li><strong>合作网络</strong>：企业或科研团队之间的合作关系可能随项目结束或战略变化而终止，同时可能与新的合作伙伴建立联系。</li>
<li><strong>社交网络</strong>：人与人之间的社交关系可能随时间淡化或断裂，老朋友的联系可能减少，新朋友的联系增加。</li>
<li><strong>生态网络</strong>：物种间的竞争或协作关系可能随着生态环境的变化而调整，导致某些物种间的交互关系发生变化。</li>
</ul>
<p><strong>机制</strong>：</p>
<ul>
<li><strong>连接偏好变化</strong>：节点的连接偏好（如合作对象、竞争对手等）可能随着时间变化而发生改变，这会导致边的重新分配。</li>
<li><strong>资源竞争与合作演化</strong>：在竞争和合作网络中，随着资源或市场变化，竞争或合作关系可能发生转变，影响边的存在与否。</li>
</ul>
<h4 id="3-网络中的局部相互作用（Local-Interaction）"><a href="#3-网络中的局部相互作用（Local-Interaction）" class="headerlink" title="3. 网络中的局部相互作用（Local Interaction）"></a>3. <strong>网络中的局部相互作用（Local Interaction）</strong></h4><p><strong>定义</strong>：节点通过与邻居的局部交互，影响到整个网络的演化。</p>
<p><strong>影响</strong>：</p>
<ul>
<li><strong>社交网络</strong>：朋友之间的意见影响力、模仿行为等会促使个体改变连接行为，例如通过共同朋友认识新的人，形成新的连接。</li>
<li><strong>生态网络</strong>：物种的局部相互作用（如捕食、竞争）会影响网络的稳定性和演化趋势，局部互动可能导致物种灭绝或繁荣。</li>
</ul>
<p><strong>机制</strong>：</p>
<ul>
<li><strong>同质性偏好（Homophily）</strong>：个体更倾向于与相似的个体建立联系，导致网络中节点之间的相似性不断增强。</li>
<li><strong>三角闭合（Triadic Closure）</strong>：如果两个节点有共同的邻居，那么它们更有可能建立连接，形成闭合三角形的关系。</li>
</ul>
<h4 id="4-外部冲击与干扰（External-Shocks-and-Disturbances）"><a href="#4-外部冲击与干扰（External-Shocks-and-Disturbances）" class="headerlink" title="4. 外部冲击与干扰（External Shocks and Disturbances）"></a>4. <strong>外部冲击与干扰（External Shocks and Disturbances）</strong></h4><p><strong>定义</strong>：外部环境的变化或重大事件会对网络结构产生深远影响。</p>
<p><strong>影响</strong>：</p>
<ul>
<li><strong>交通网络</strong>：自然灾害、战争、政策变化等外部因素可能导致部分交通线路中断、重建或扩展，改变网络的整体结构。</li>
<li><strong>金融网络</strong>：市场崩溃、金融危机等外部冲击会导致网络中的企业、银行破产或重组，改变它们之间的金融依赖关系。</li>
<li><strong>生态网络</strong>：气候变化、物种入侵或人类活动等外部干扰会导致物种灭绝或迁移，进而改变生态网络中的关系。</li>
</ul>
<p><strong>机制</strong>：</p>
<ul>
<li><strong>脆弱性与鲁棒性</strong>：网络中某些节点或边对外部冲击特别敏感，这些关键节点或边的变化会对网络整体结构产生深远影响。</li>
<li><strong>适应性演化</strong>：某些网络（如生物网络或社会网络）具有适应外部冲击的能力，能够通过内部调整来缓冲外部影响。</li>
</ul>
<h4 id="5-节点属性和偏好的变化（Node-Attributes-and-Preferences-Changes）"><a href="#5-节点属性和偏好的变化（Node-Attributes-and-Preferences-Changes）" class="headerlink" title="5. 节点属性和偏好的变化（Node Attributes and Preferences Changes）"></a>5. <strong>节点属性和偏好的变化（Node Attributes and Preferences Changes）</strong></h4><p><strong>定义</strong>：节点的属性（如年龄、偏好、资源等）或其偏好随着时间推移发生变化，影响其连接行为。</p>
<p><strong>影响</strong>：</p>
<ul>
<li><strong>社交网络</strong>：随着时间推移，人的兴趣、职业、居住地发生变化，可能导致社交关系的调整和重组。</li>
<li><strong>科研合作网络</strong>：科研人员的研究方向或兴趣发生变化，会促使他们寻找新的合作伙伴，改变科研网络的结构。</li>
<li><strong>竞争网络</strong>：公司或个体的策略、资源发生变化，可能使得它们从一个竞争对手转向另一个竞争对手。</li>
</ul>
<p><strong>机制</strong>：</p>
<ul>
<li><strong>兴趣趋同效应</strong>：节点的偏好趋同会导致它们更容易相互连接，例如在社交网络中，拥有相似兴趣的用户更容易形成联系。</li>
<li><strong>节点成熟度与演化</strong>：一些网络中节点随着“成长”而改变连接行为，例如新公司进入市场时可能与小公司竞争，但随着扩展会与大公司竞争。</li>
</ul>
<h4 id="6-随机性与噪声（Randomness-and-Noise）"><a href="#6-随机性与噪声（Randomness-and-Noise）" class="headerlink" title="6. 随机性与噪声（Randomness and Noise）"></a>6. <strong>随机性与噪声（Randomness and Noise）</strong></h4><p><strong>定义</strong>：网络的演化过程有时受到随机因素或噪声的影响，导致不可预测的变化。</p>
<p><strong>影响</strong>：</p>
<ul>
<li><strong>社交网络</strong>：个体之间的联系可能由于偶然的事件或短暂的交互而形成，形成随机连接。</li>
<li><strong>交通网络</strong>：道路建设或关闭可能并非完全计划内，而是受到偶然事件（如突发需求、政治决策）的影响。</li>
<li><strong>生态网络</strong>：物种关系的演化过程中存在一定的随机性，例如突发事件导致某个物种灭绝或迁移。</li>
</ul>
<p><strong>机制</strong>：</p>
<ul>
<li><strong>随机图模型</strong>：在某些网络中，随机连接或断裂可能会随着网络增长而发生，导致结构演化呈现一定的随机特性。</li>
<li><strong>随机游走模型</strong>：某些网络演化模型考虑节点随机游走来寻找连接伙伴，这种随机性影响网络的最终结构。</li>
</ul>
<h4 id="7-反馈机制（Feedback-Mechanisms）"><a href="#7-反馈机制（Feedback-Mechanisms）" class="headerlink" title="7. 反馈机制（Feedback Mechanisms）"></a>7. <strong>反馈机制（Feedback Mechanisms）</strong></h4><p><strong>定义</strong>：网络中节点的行为会反馈到整个网络，进而推动网络的演化。</p>
<p><strong>影响</strong>：</p>
<ul>
<li><strong>经济网络</strong>：企业间的合作或竞争关系会影响市场的反馈，进而调整企业的竞争策略，导致网络结构随之变化。</li>
<li><strong>社交网络</strong>：个体的行为（如发帖、评论等）影响其社交反馈（如点赞、评论数），这又进一步影响其未来的连接行为。</li>
<li><strong>生态网络</strong>：物种间的捕食和竞争关系会形成生态反馈，导致物种之间的关系动态调整。</li>
</ul>
<p><strong>机制</strong>：</p>
<ul>
<li><strong>正反馈循环</strong>：节点之间的某种行为（如合作）会产生增强该行为的反馈，导致网络中的合作关系更加紧密。</li>
<li><strong>负反馈机制</strong>：竞争或资源限制导致的负反馈可能会抑制某些关系的进一步发展，促使网络中的节点或边进行调整。</li>
</ul>
<h4 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h4><p>网络的演化通常是由多种因素共同作用的结果，这些因素既包括网络内部节点和边的行为（如节点增长、局部相互作用），也包括外部环境变化（如外部冲击、随机事件）。网络的结构在这些驱动因素的影响下，不断进行调整、扩展或收缩，从而展现出复杂的演化模式。理解这些驱动因素有助于预测网络未来的演化趋势，并为实际系统中的问题（如社交网络的增长、交通网络的优化、生态网络的保护）提供参考。</p>
<h3 id="七、连接机制、竞争驱动机制、节点状态转换机制"><a href="#七、连接机制、竞争驱动机制、节点状态转换机制" class="headerlink" title="七、连接机制、竞争驱动机制、节点状态转换机制"></a>七、连接机制、竞争驱动机制、节点状态转换机制</h3><ol>
<li><h4 id="混合连接机制："><a href="#混合连接机制：" class="headerlink" title="混合连接机制："></a><strong>混合连接机制</strong>：</h4><ul>
<li>这种机制结合了不同类型的连接方式，旨在提高系统的灵活性和效率。在网络中，它可能涉及将有线和无线连接结合在一起，利用各自的优势来满足不同的需求。混合连接机制可以在数据传输、网络负载均衡和资源分配等方面发挥重要作用。</li>
</ul>
</li>
<li><h4 id="竞争驱动机制："><a href="#竞争驱动机制：" class="headerlink" title="竞争驱动机制："></a><strong>竞争驱动机制</strong>：</h4><ul>
<li>该机制涉及多个参与者之间的竞争，驱动它们优化自身的行为，以获得资源或达成目标。在经济学和博弈论中，这种机制常用于描述市场竞争。在技术系统中，竞争驱动机制可以促使不同的算法或技术不断改进，以便在特定任务中表现更好。</li>
</ul>
</li>
<li><h4 id="节点状态转换机制："><a href="#节点状态转换机制：" class="headerlink" title="节点状态转换机制："></a><strong>节点状态转换机制</strong>：</h4><ul>
<li>这个机制描述了系统中节点如何在不同状态之间转换。通常用于图论和网络理论中，节点可能根据特定的规则或事件（如接收到的信息、时间变化等）在不同状态（如激活、待机、故障等）之间切换。节点状态转换机制可以用于建模复杂系统的动态行为，如计算机网络、社交网络或生物网络。</li>
</ul>
</li>
</ol>
<h3 id="八、邻域择优机制、允许老节点互连机制、断边重连机制驱"><a href="#八、邻域择优机制、允许老节点互连机制、断边重连机制驱" class="headerlink" title="八、邻域择优机制、允许老节点互连机制、断边重连机制驱"></a>八、邻域择优机制、允许老节点互连机制、断边重连机制驱</h3><p>这三种机制通常与网络结构、拓扑优化以及动态系统中的节点管理相关。以下是对每个机制的简要解释：</p>
<ol>
<li><h4 id="邻域择优机制："><a href="#邻域择优机制：" class="headerlink" title="邻域择优机制："></a><strong>邻域择优机制</strong>：</h4><ul>
<li>该机制涉及在网络中选择最佳邻居节点进行连接或通信。在多种应用中，例如无线网络、社交网络或分布式计算中，节点通常会基于某些标准（如信号强度、节点性能、延迟等）来选择邻居。这种机制可以提高网络的整体效率和性能，确保信息在网络中有效传递。</li>
</ul>
</li>
<li><h4 id="允许老节点互连机制："><a href="#允许老节点互连机制：" class="headerlink" title="允许老节点互连机制："></a><strong>允许老节点互连机制</strong>：</h4><ul>
<li>这个机制允许网络中较老的节点之间建立直接连接。这种设计有助于维持网络的稳定性和可靠性，尤其是在节点频繁失效或更新的情况下。通过促进老节点的互连，网络可以增强信息传递的冗余性，并确保系统能够继续运行，即使部分新节点出现问题。</li>
</ul>
</li>
<li><h4 id="断边重连机制："><a href="#断边重连机制：" class="headerlink" title="断边重连机制："></a><strong>断边重连机制</strong>：</h4><ul>
<li>该机制描述了在网络中如何处理断开的连接（边）。当节点之间的连接因故障或其他原因中断时，断边重连机制允许这些节点尝试重新建立连接，或者选择新的邻居节点进行连接。通过灵活的重连策略，网络能够适应动态变化，保持其连通性和稳定性。这在动态网络（如移动自组织网络）中尤为重要。</li>
</ul>
</li>
</ol>
<h3 id="九、Poisson-过程理论和平均场方法"><a href="#九、Poisson-过程理论和平均场方法" class="headerlink" title="九、Poisson 过程理论和平均场方法"></a>九、Poisson 过程理论和平均场方法</h3><p><strong>Poisson过程理论</strong>和<strong>平均场方法</strong>是概率论和统计物理中的两个重要概念，分别用于建模随机事件和分析复杂系统的行为。下面是对这两个理论的简要介绍：</p>
<h4 id="Poisson过程理论"><a href="#Poisson过程理论" class="headerlink" title="Poisson过程理论"></a>Poisson过程理论</h4><p><strong>定义</strong>：</p>
<ul>
<li>Poisson过程是一种随机过程，用于描述在固定时间间隔内发生独立事件的数量。它被广泛应用于排队论、信号处理、网络流量等领域。</li>
</ul>
<p><strong>主要特性</strong>：</p>
<ol>
<li><strong>事件发生的独立性</strong>：在任意两个不重叠的时间区间内发生事件的数量是相互独立的。</li>
<li><strong>均匀性</strong>：在单位时间内发生事件的期望数量是一个常数，通常记为 λ（lambda），称为事件的强度或速率。</li>
<li><strong>概率分布</strong>：在时间区间 [0, t] 内发生的事件数量服从 Poisson 分布，其概率质量函数为：<br><img src="./images/efigure05.png" alt="图5"></li>
</ol>
<p><strong>应用</strong>：</p>
<ul>
<li>该理论在各种领域中应用广泛，如电话呼叫的到达、交通流量、网络数据包的到达等。</li>
</ul>
<h4 id="平均场方法"><a href="#平均场方法" class="headerlink" title="平均场方法"></a>平均场方法</h4><p><strong>定义</strong>：</p>
<ul>
<li>平均场方法是一种用于分析复杂系统（如统计物理、网络和生物系统）行为的技术。该方法通过假设系统中每个单元（如粒子、节点等）在某种平均条件下相互作用，从而简化系统的分析。</li>
</ul>
<p><strong>主要特性</strong>：</p>
<ol>
<li><strong>均匀假设</strong>：假设系统中的每个单元都与所有其他单元相互作用，并且每个单元的行为都是在平均场中进行的。</li>
<li><strong>简化模型</strong>：通过引入均值或平均场变量，平均场方法能够将复杂的相互作用转化为简化的方程，从而使得求解问题更加可行。</li>
<li><strong>动态系统的分析</strong>：平均场方法常用于分析动态系统的稳定性和相变行为，可以帮助理解系统的全局性质。</li>
</ol>
<p><strong>应用</strong>：</p>
<ul>
<li>在统计物理中，平均场理论被用来分析相变和临界现象。在机器学习中，平均场方法用于推断和优化算法。</li>
</ul>
<h4 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h4><p><strong>Poisson过程理论</strong>主要用于描述和建模独立随机事件的发生，而<strong>平均场方法</strong>则用于分析复杂系统中单元之间的相互作用，尤其是在系统规模较大时。这两者可以结合使用，以更好地理解随机过程和动态系统中的行为。</p>
<h3 id="十、传染病动力学的-SIS-模型和-SIR-模型"><a href="#十、传染病动力学的-SIS-模型和-SIR-模型" class="headerlink" title="十、传染病动力学的 SIS 模型和 SIR 模型"></a>十、传染病动力学的 SIS 模型和 SIR 模型</h3><p>在传染病动力学中，<strong>SIS模型</strong>和<strong>SIR模型</strong>是两个基本且广泛使用的数学模型，用于描述疾病传播过程。它们通过将人口划分为不同的状态（如易感、感染、康复等）来分析疾病的传播特征和动态变化。以下是这两个模型的详细介绍：</p>
<h4 id="SIS模型（易感-感染-易感）"><a href="#SIS模型（易感-感染-易感）" class="headerlink" title="SIS模型（易感-感染-易感）"></a>SIS模型（易感-感染-易感）</h4><p><strong>基本概念</strong>：</p>
<ul>
<li>在SIS模型中，个体在感染后不会获得长期免疫力。感染个体在治愈后会重新回到易感状态，因此整个过程是循环的。</li>
</ul>
<p><strong>状态定义</strong>：</p>
<ul>
<li><strong>S</strong>（易感者）：个体未感染，但有可能感染。</li>
<li><strong>I</strong>（感染者）：个体正在感染，并能传染给易感者。</li>
</ul>
<p><strong>模型方程</strong>：</p>
<p><img src="./images/efigure06.png" alt="图6"></p>
<p><strong>特点</strong>：</p>
<ul>
<li>在该模型中，个体在感染后会在一段时间后恢复并返回易感状态，形成一个封闭的循环。</li>
</ul>
<h4 id="SIR模型（易感-感染-康复）"><a href="#SIR模型（易感-感染-康复）" class="headerlink" title="SIR模型（易感-感染-康复）"></a>SIR模型（易感-感染-康复）</h4><p><strong>基本概念</strong>：</p>
<ul>
<li>SIR模型描述了个体在感染后会获得长期免疫力，感染后不会再返回易感状态。</li>
</ul>
<p><strong>状态定义</strong>：</p>
<ul>
<li><strong>S</strong>（易感者）：个体未感染，能被感染。</li>
<li><strong>I</strong>（感染者）：个体正在感染，能传播给易感者。</li>
<li><strong>R</strong>（康复者）：个体已经感染并康复，获得免疫，无法再次感染。</li>
</ul>
<p><strong>模型方程</strong>：</p>
<p><img src="./images/efigure07.png" alt="图7" style="zoom: 80%;" /></p>
<p><strong>特点</strong>：</p>
<ul>
<li>在该模型中，感染者一旦康复后，会转移到康复者状态，并获得免疫，不再返回易感状态。</li>
</ul>
<h4 id="比较和应用"><a href="#比较和应用" class="headerlink" title="比较和应用"></a>比较和应用</h4><ul>
<li><strong>循环性</strong>：SIS模型适用于没有长期免疫的疾病（如某些细菌性感染），而SIR模型适用于有免疫的疾病（如流感、麻疹等）。</li>
<li><strong>传播动力学</strong>：两者都可以通过基本再生数 ( R<sub>0</sub> )（传染病在易感者中的传播能力）来分析疾病的传播。如果 ( R<sub>0</sub> &gt; 1 )，疾病将持续传播；如果 ( R<sub>0</sub> &lt; 1 )，疾病将最终消失。</li>
</ul>
<h4 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h4><p>SIS模型和SIR模型是理解传染病传播的重要工具。通过这些模型，研究人员可以分析疾病的传播动态、预测流行趋势，并评估干预措施的效果。</p>
<h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><h3 id="一、复杂系统的拓扑特征"><a href="#一、复杂系统的拓扑特征" class="headerlink" title="一、复杂系统的拓扑特征"></a>一、复杂系统的拓扑特征</h3><p>复杂系统的拓扑特征是研究复杂系统（如社交网络、生物网络、生态系统等）中元素（节点）之间关系（边）的结构和性质的重要方面。以下是一些关键的拓扑特征及其解释：</p>
<h4 id="1-节点度分布"><a href="#1-节点度分布" class="headerlink" title="1. 节点度分布"></a>1. <strong>节点度分布</strong></h4><ul>
<li><strong>定义</strong>：节点度是指与该节点相连的边的数量。度分布描述了网络中各节点度的分布情况。</li>
<li><strong>特点</strong>：<ul>
<li>在许多复杂网络中，节点度分布往往呈现幂律分布（scale-free distribution），即大多数节点的度较小，而少数节点的度极大，形成“枢纽”节点。</li>
</ul>
</li>
</ul>
<h4 id="2-聚类系数"><a href="#2-聚类系数" class="headerlink" title="2. 聚类系数"></a>2. <strong>聚类系数</strong></h4><ul>
<li><strong>定义</strong>：聚类系数衡量的是一个节点的邻居之间相互连接的程度。它反映了网络的局部结构。</li>
<li><strong>特点</strong>：<ul>
<li>高聚类系数意味着节点的邻居之间连接紧密，这种特征在社交网络和生物网络中很常见。</li>
</ul>
</li>
</ul>
<h4 id="3-平均路径长度"><a href="#3-平均路径长度" class="headerlink" title="3. 平均路径长度"></a>3. <strong>平均路径长度</strong></h4><ul>
<li><strong>定义</strong>：网络中任意两个节点之间最短路径的平均长度。</li>
<li><strong>特点</strong>：<ul>
<li>较短的平均路径长度通常表明网络中信息传播效率高，节点之间的连接性强。例如，许多社交网络的平均路径长度相对较短，显示了“六度分隔”理论。</li>
</ul>
</li>
</ul>
<h4 id="4-连通性"><a href="#4-连通性" class="headerlink" title="4. 连通性"></a>4. <strong>连通性</strong></h4><ul>
<li><strong>定义</strong>：网络的连通性是指网络中任意两个节点之间是否存在路径。</li>
<li><strong>特点</strong>：<ul>
<li>连通性可以分为强连通（所有节点都可以到达）和弱连通（存在路径，但方向不一致）两种类型。复杂网络通常具有强连通性，即使在节点失效或故障的情况下。</li>
</ul>
</li>
</ul>
<h4 id="5-社区结构"><a href="#5-社区结构" class="headerlink" title="5. 社区结构"></a>5. <strong>社区结构</strong></h4><ul>
<li><strong>定义</strong>：社区是指网络中节点的集群，通常内部节点之间的连接密集，而与其他集群的连接较少。</li>
<li><strong>特点</strong>：<ul>
<li>社区结构在社交网络、生态系统和信息网络中普遍存在，识别社区可以帮助理解网络的功能和组织。</li>
</ul>
</li>
</ul>
<h4 id="6-小世界性质"><a href="#6-小世界性质" class="headerlink" title="6. 小世界性质"></a>6. <strong>小世界性质</strong></h4><ul>
<li><strong>定义</strong>：小世界网络具有较短的平均路径长度和较高的聚类系数。</li>
<li><strong>特点</strong>：<ul>
<li>这意味着在大规模网络中，任何两个节点之间的距离相对较短，同时局部的紧密性较强，这一特性在许多自然和人造网络中被观察到。</li>
</ul>
</li>
</ul>
<h4 id="7-网络的异质性"><a href="#7-网络的异质性" class="headerlink" title="7. 网络的异质性"></a>7. <strong>网络的异质性</strong></h4><ul>
<li><strong>定义</strong>：网络的异质性指的是网络中节点和连接的不均匀性。</li>
<li><strong>特点</strong>：<ul>
<li>许多复杂网络表现出异质性，表现在节点的度、性质和连接模式上，这种特性影响了网络的动态行为和稳定性。</li>
</ul>
</li>
</ul>
<h4 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h4><p>复杂系统的拓扑特征在多个领域中有重要应用，例如：</p>
<ul>
<li><strong>社交网络分析</strong>：了解社交网络中信息传播和影响力的机制。</li>
<li><strong>生物网络</strong>：揭示生物体内不同分子（如蛋白质、基因）之间的相互作用。</li>
<li><strong>交通网络</strong>：优化交通流，降低拥堵和提高效率。</li>
</ul>
<h4 id="总结-6"><a href="#总结-6" class="headerlink" title="总结"></a>总结</h4><p>复杂系统的拓扑特征为我们理解和分析这些系统的结构和动态提供了重要的视角。通过这些特征，可以更好地理解复杂系统的行为、传播过程及其对外部干扰的响应。</p>
<h3 id="二、二分图的异质性"><a href="#二、二分图的异质性" class="headerlink" title="二、二分图的异质性"></a>二、二分图的异质性</h3><p><strong>二分图</strong>（Bipartite Graph）是一种特殊类型的图，其节点可以分为两个不相交的集合，且图中的边仅连接两个不同集合中的节点。二分图的异质性指的是两个集合之间的差异性和多样性，这种差异性可能体现在节点的性质、连接方式、度分布等方面。以下是二分图异质性的几个关键特征和应用：</p>
<h4 id="1-节点特性异质性"><a href="#1-节点特性异质性" class="headerlink" title="1. 节点特性异质性"></a>1. <strong>节点特性异质性</strong></h4><ul>
<li><strong>定义</strong>：在二分图中，两个集合的节点可能具有不同的特性，例如在社交网络中，一个集合可以代表用户，另一个集合可以代表兴趣或活动。不同节点的属性可能导致其在网络中的行为和连接方式存在显著差异。</li>
<li><strong>示例</strong>：在推荐系统中，用户和产品之间的二分图中，用户的购买偏好（如性别、年龄、消费习惯等）与产品的属性（如类别、价格、品牌等）可能表现出异质性。</li>
</ul>
<h4 id="2-连接模式异质性"><a href="#2-连接模式异质性" class="headerlink" title="2. 连接模式异质性"></a>2. <strong>连接模式异质性</strong></h4><ul>
<li><strong>定义</strong>：二分图中节点之间的连接方式可能不均匀。某些节点可能与许多其他节点连接，而其他节点则可能连接较少，这种连接的差异性可以影响网络的整体结构和功能。</li>
<li><strong>示例</strong>：在学术合作网络中，研究人员（一个集合）和研究主题（另一个集合）之间的连接可能显示出异质性，某些研究主题可能吸引了更多研究人员的关注。</li>
</ul>
<h4 id="3-度分布异质性"><a href="#3-度分布异质性" class="headerlink" title="3. 度分布异质性"></a>3. <strong>度分布异质性</strong></h4><ul>
<li><strong>定义</strong>：二分图中的度分布可以显示出异质性特征。在一个二分图中，一个集合的节点的连接数量（度）可能呈现出较大的变化。例如，有些用户可能与许多产品连接，而有些用户则仅与少数产品连接。</li>
<li><strong>示例</strong>：在社交网络中，某些用户（如网红）可能与大量其他用户或活动连接，而普通用户的连接较少。</li>
</ul>
<h4 id="4-功能异质性"><a href="#4-功能异质性" class="headerlink" title="4. 功能异质性"></a>4. <strong>功能异质性</strong></h4><ul>
<li><strong>定义</strong>：在二分图中，不同节点的功能或角色可能存在显著差异。一个集合中的节点可能承担某种特定角色，而另一个集合中的节点可能扮演不同的角色。</li>
<li><strong>示例</strong>：在二分图中，病人（一个集合）和医生（另一个集合）之间的连接可以反映医疗服务的异质性，不同医生可能专注于不同领域，服务于不同类型的病人。</li>
</ul>
<h4 id="应用-1"><a href="#应用-1" class="headerlink" title="应用"></a>应用</h4><ul>
<li><strong>推荐系统</strong>：通过分析用户和物品之间的二分图，可以更好地理解用户偏好，从而提高推荐效果。</li>
<li><strong>社交网络分析</strong>：识别网络中的关键节点（如影响者），分析信息传播路径。</li>
<li><strong>生物信息学</strong>：在基因和疾病之间的二分图中，分析特定基因与特定疾病之间的关系。</li>
</ul>
<h4 id="总结-7"><a href="#总结-7" class="headerlink" title="总结"></a>总结</h4><p>二分图的异质性提供了深入分析复杂网络结构和动态行为的框架。通过研究节点特性、连接模式和度分布的异质性，可以更好地理解网络的结构和功能。</p>
<h3 id="三、二分图的投影图"><a href="#三、二分图的投影图" class="headerlink" title="三、二分图的投影图"></a>三、二分图的投影图</h3><p>二分图的<strong>投影图</strong>是将二分图中的一个集合的节点与另一个集合的节点之间的关系“投影”到一个新的图中，从而形成新的图结构。投影图可以帮助我们更好地理解二分图中两个集合之间的交互关系。</p>
<h3 id="二分图的定义"><a href="#二分图的定义" class="headerlink" title="二分图的定义"></a>二分图的定义</h3><p>一个<strong>二分图</strong> ( G = (U, V, E) ) 由两个不相交的节点集合 ( U ) 和 ( V ) 组成，其中的边 ( E ) 仅连接 ( U ) 中的节点与 ( V ) 中的节点。</p>
<h3 id="投影图的构建"><a href="#投影图的构建" class="headerlink" title="投影图的构建"></a>投影图的构建</h3><p>对于二分图 ( G )，我们可以根据其中一个集合（例如 ( U ) 或 ( V )）来构建投影图。以下是投影图的构建步骤：</p>
<ol>
<li><strong>选择投影的集合</strong>：决定要投影的集合，例如选择 ( U )。</li>
<li><strong>创建新的图</strong>：创建一个新的图 ( G<sub>U</sub> )，其节点集合等于 ( U )。</li>
<li><strong>添加边</strong>：<ul>
<li>对于 ( U ) 中的任意两个节点 ( u<sub>1</sub>, u<sub>2</sub> )，如果它们在二分图 G 中通过同一个节点 ( v \in V ) 连接（即 ( (u<br><sub>1</sub>, v) \in E ) 且 ( (u<sub>2</sub>, v) \in E )），则在投影图 ( G<sub>U</sub> ) 中添加一条边 ( (u<sub>1</sub>, u<sub>2</sub>) )。</li>
</ul>
</li>
</ol>
<h3 id="投影图的性质"><a href="#投影图的性质" class="headerlink" title="投影图的性质"></a>投影图的性质</h3><ul>
<li><strong>聚类</strong>：投影图中的边表示原始二分图中两个节点通过共同的连接建立的关系，通常会形成聚类结构。</li>
<li><strong>多重边</strong>：如果 ( u<sub>1</sub> ) 和 ( u<sub>2</sub> ) 通过多个 ( v ) 节点连接，那么在投影图中可能会出现多条边。</li>
<li><strong>节点度</strong>：投影图中节点的度数表示该节点与多少个其他节点通过同一节点相连。</li>
</ul>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>假设我们有一个简单的二分图 ( G )：</p>
<ul>
<li>( U = \{A, B, C\} )</li>
<li>( V = \{1, 2, 3\} )</li>
<li>边集 ( E = \{(A, 1), (A, 2), (B, 2), (B, 3), (C, 1)\} )</li>
</ul>
<p><strong>投影图 ( G<sub>U</sub> )</strong>：</p>
<ul>
<li>节点集合为 ( U = \{A, B, C\} )。</li>
<li>边：<ul>
<li>( A ) 和 ( B ) 通过 ( 2 ) 连接，添加边 ( (A, B) )。</li>
<li>( A ) 和 ( C ) 通过 ( 1 ) 连接，添加边 ( (A, C) )。</li>
<li>( B ) 和 ( C ) 没有通过同一个 ( V ) 节点连接，因此不添加边。</li>
</ul>
</li>
</ul>
<p>投影图 ( G<sub>U</sub> ) 的结构为：</p>
<ul>
<li>节点：( A, B, C )</li>
<li>边：( (A, B), (A, C) )</li>
</ul>
<h3 id="应用-2"><a href="#应用-2" class="headerlink" title="应用"></a>应用</h3><ul>
<li><strong>社交网络</strong>：在社交网络分析中，投影图可以帮助识别社交群体。例如，用户和事件之间的二分图可以转化为用户之间的互动图。</li>
<li><strong>推荐系统</strong>：在推荐系统中，可以通过商品和用户的二分图构建用户之间的相似度图，便于进行推荐。</li>
<li><strong>生物信息学</strong>：在基因和疾病的二分图中，投影图可以揭示基因之间的相互关系。</li>
</ul>
<h3 id="总结-8"><a href="#总结-8" class="headerlink" title="总结"></a>总结</h3><p>二分图的投影图是分析和理解复杂网络的重要工具。通过投影，可以更好地揭示节点之间的关系和结构特征，从而支持各种应用。</p>
<h3 id="四、基于网络的超网络-Supernetwork，Network-of-Network-和基于超图的超网络-Hypernetwork"><a href="#四、基于网络的超网络-Supernetwork，Network-of-Network-和基于超图的超网络-Hypernetwork" class="headerlink" title="四、基于网络的超网络(Supernetwork，Network of Network)和基于超图的超网络(Hypernetwork)"></a>四、基于网络的超网络(Supernetwork，Network of Network)和基于超图的超网络(Hypernetwork)</h3><p><strong>基于网络的超网络</strong>（Supernetwork或Network of Networks）和<strong>基于超图的超网络</strong>（Hypernetwork）是描述复杂系统中高阶关系的两种不同概念。以下是对这两者的详细比较和解释：</p>
<h4 id="基于网络的超网络（Supernetwork-Network-of-Networks）"><a href="#基于网络的超网络（Supernetwork-Network-of-Networks）" class="headerlink" title="基于网络的超网络（Supernetwork / Network of Networks）"></a>基于网络的超网络（Supernetwork / Network of Networks）</h4><p><strong>定义</strong>：</p>
<ul>
<li>基于网络的超网络是一种复杂网络模型，它将多个网络作为节点，通过它们之间的连接形成一个更高层次的网络。也就是说，每个网络可以是不同的类型，且它们之间可以通过边相连。</li>
</ul>
<p><strong>特性</strong>：</p>
<ol>
<li><strong>多层结构</strong>：每个网络代表一个系统的不同部分，例如交通网络、社交网络、信息网络等。</li>
<li><strong>互联性</strong>：网络之间的连接可以是多样的，表示它们之间的相互影响和相互作用。</li>
<li><strong>动态性</strong>：网络的拓扑结构可能会随着时间变化，节点和边可以动态添加或删除。</li>
<li><strong>复杂性</strong>：能够捕捉到系统中不同网络之间的复杂关系和依赖性。</li>
</ol>
<p><strong>应用示例</strong>：</p>
<ul>
<li>在城市基础设施中，交通网络、水管网络和电力网络可以构成一个超网络，各个网络之间的交互影响了城市的运作。</li>
<li>社交网络和信息网络的结合可以帮助理解信息传播和社会影响。</li>
</ul>
<h4 id="基于超图的超网络（Hypernetwork）"><a href="#基于超图的超网络（Hypernetwork）" class="headerlink" title="基于超图的超网络（Hypernetwork）"></a>基于超图的超网络（Hypernetwork）</h4><p><strong>定义</strong>：</p>
<ul>
<li>基于超图的超网络是一种特殊的网络结构，允许超边连接多个节点。超图是一个包含多个节点集合和连接这些节点的边（超边）的图。</li>
</ul>
<p><strong>特性</strong>：</p>
<ol>
<li><strong>超边</strong>：超边可以连接两个以上的节点，表示高阶关系。例如，在科学合作中，一个超边可以代表多个作者共同撰写的一篇论文。</li>
<li><strong>灵活性</strong>：能够表达节点之间的复杂关系，适用于多方协作的场景。</li>
<li><strong>简单性</strong>：通常超图的结构比基于网络的超网络更简单，因为它只涉及节点和超边的关系。</li>
</ol>
<p><strong>应用示例</strong>：</p>
<ul>
<li>在生物信息学中，基因与疾病之间的关系可以用超图表示，基因可能通过多个超边同时影响多个疾病。</li>
</ul>
<h4 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h4><div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>基于网络的超网络</th>
<th>基于超图的超网络</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>节点表示</strong></td>
<td>多个独立网络</td>
<td>单个网络中的多个节点</td>
</tr>
<tr>
<td><strong>边的类型</strong></td>
<td>网络之间的连接</td>
<td>超边连接多个节点</td>
</tr>
<tr>
<td><strong>复杂性</strong></td>
<td>更复杂，涉及多个网络和相互作用</td>
<td>相对简单，主要涉及节点和超边的关系</td>
</tr>
<tr>
<td><strong>动态性</strong></td>
<td>网络结构和连接可以动态变化</td>
<td>超图结构通常是静态的</td>
</tr>
<tr>
<td><strong>应用场景</strong></td>
<td>城市基础设施、社交网络与信息网络的结合</td>
<td>科学合作、生态网络、推荐系统</td>
</tr>
</tbody>
</table>
</div>
<h4 id="总结-9"><a href="#总结-9" class="headerlink" title="总结"></a>总结</h4><ul>
<li><strong>基于网络的超网络</strong>强调多个网络之间的关系，适合描述复杂系统中不同部分的互联性和动态性。</li>
<li><strong>基于超图的超网络</strong>则关注于节点之间的高阶关系，通过超边连接多个节点，适用于表达多方协作和复杂交互的场景。</li>
</ul>
<p>这两者各有优势，具体应用取决于研究的具体问题和数据结构。</p>
<h3 id="五、同质与异质节点"><a href="#五、同质与异质节点" class="headerlink" title="五、同质与异质节点"></a>五、同质与异质节点</h3><p>在网络科学中，节点的同质性和异质性是描述网络中节点特性差异的重要概念。以下是对同质节点和异质节点的详细介绍及其在复杂网络中的应用。</p>
<h4 id="同质节点（Homogeneous-Nodes）"><a href="#同质节点（Homogeneous-Nodes）" class="headerlink" title="同质节点（Homogeneous Nodes）"></a>同质节点（Homogeneous Nodes）</h4><p><strong>定义</strong>：</p>
<ul>
<li>同质节点是指在某一特征或属性上相似或相同的节点。这些节点在网络中的角色、功能或行为基本一致。</li>
</ul>
<p><strong>特性</strong>：</p>
<ol>
<li><strong>相似性</strong>：同质节点通常在某些属性（如度、功能、行为等）上表现出高度相似性。</li>
<li><strong>简化模型</strong>：在分析和建模中，同质节点可以简化网络的复杂性，因为它们可以被视为一个整体。</li>
<li><strong>均匀性</strong>：同质节点的连接模式通常较为一致。</li>
</ol>
<p><strong>应用示例</strong>：</p>
<ul>
<li>在社交网络中，某个特定群体（如同学、同事）可以被视为同质节点，它们在社交行为和互动方式上可能比较相似。</li>
<li>在生物网络中，同一种类的基因或蛋白质可以被视为同质节点，因为它们在功能和属性上较为相似。</li>
</ul>
<h4 id="异质节点（Heterogeneous-Nodes）"><a href="#异质节点（Heterogeneous-Nodes）" class="headerlink" title="异质节点（Heterogeneous Nodes）"></a>异质节点（Heterogeneous Nodes）</h4><p><strong>定义</strong>：</p>
<ul>
<li>异质节点是指在特征或属性上存在显著差异的节点。这些节点在网络中的角色、功能或行为表现出多样性。</li>
</ul>
<p><strong>特性</strong>：</p>
<ol>
<li><strong>多样性</strong>：异质节点通常在许多属性上具有不同的特征，可能导致不同的连接模式和行为。</li>
<li><strong>复杂性</strong>：网络的异质性增加了分析的复杂性，因为不同类型的节点可能在不同的上下文中发挥不同的作用。</li>
<li><strong>功能差异</strong>：异质节点在网络中的功能和影响力可能各不相同。</li>
</ol>
<p><strong>应用示例</strong>：</p>
<ul>
<li>在社交网络中，用户、品牌和活动可以被视为异质节点，因为它们在影响力、连接模式和交互行为上存在显著差异。</li>
<li>在生态系统中，植物、动物和微生物可以被视为异质节点，它们在生态平衡中发挥不同的角色。</li>
</ul>
<h4 id="比较-1"><a href="#比较-1" class="headerlink" title="比较"></a>比较</h4><div class="table-container">
<table>
<thead>
<tr>
<th>特性</th>
<th>同质节点</th>
<th>异质节点</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>相似性</strong></td>
<td>属性、行为一致</td>
<td>属性、行为多样</td>
</tr>
<tr>
<td><strong>网络复杂性</strong></td>
<td>简化网络分析</td>
<td>增加网络分析复杂性</td>
</tr>
<tr>
<td><strong>功能</strong></td>
<td>扮演相似角色</td>
<td>扮演不同角色</td>
</tr>
<tr>
<td><strong>连接模式</strong></td>
<td>通常一致</td>
<td>通常多样</td>
</tr>
</tbody>
</table>
</div>
<h4 id="在复杂网络中的影响"><a href="#在复杂网络中的影响" class="headerlink" title="在复杂网络中的影响"></a>在复杂网络中的影响</h4><ul>
<li><p><strong>同质网络</strong>：同质节点有助于形成紧密的社区结构，因为相似的节点之间更容易建立连接。这种网络通常具有较高的聚类系数。</p>
</li>
<li><p><strong>异质网络</strong>：异质节点可以促进信息传播和创新，因为不同类型的节点可以提供多样的视角和资源。异质性有助于增强网络的鲁棒性和适应性，但也可能导致连接不均匀。</p>
</li>
</ul>
<h4 id="总结-10"><a href="#总结-10" class="headerlink" title="总结"></a>总结</h4><p>节点的同质性和异质性是理解复杂网络结构和动态行为的关键因素。通过分析网络中的同质和异质节点，可以揭示网络的特性、功能及其在不同应用场景中的表现。</p>
<h3 id="六、三元超图结构"><a href="#六、三元超图结构" class="headerlink" title="六、三元超图结构"></a>六、三元超图结构</h3><p><strong>三元超图结构</strong>是一种扩展的图结构，旨在捕捉节点之间更复杂的关系。在这种结构中，边（称为超边）可以连接三个或多个节点。三元超图特别适合于表示高阶关系，如三元关系或多方互动。</p>
<h3 id="三元超图的定义"><a href="#三元超图的定义" class="headerlink" title="三元超图的定义"></a>三元超图的定义</h3><ul>
<li><strong>节点</strong>：在三元超图中，节点代表系统中的个体或实体。</li>
<li><strong>超边</strong>：超边连接三个或更多节点，表示这些节点之间的特定关系或互动。</li>
</ul>
<h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><ol>
<li><p><strong>高阶关系</strong>：与传统图（每条边连接两个节点）相比，三元超图能够捕捉更复杂的关系。例如，超边可以表示三人合作、三种资源共享等。</p>
</li>
<li><p><strong>灵活性</strong>：三元超图允许任意数量的节点参与同一超边，使其适合于多种复杂网络的建模。</p>
</li>
<li><p><strong>多样性</strong>：三元超图的超边可以表示多种关系类型，可以是无向或有向的，具体取决于应用场景。</p>
</li>
</ol>
<h3 id="数学表示"><a href="#数学表示" class="headerlink" title="数学表示"></a>数学表示</h3><p>一个三元超图 ( H ) 可以表示为一个三元组：<br>[ H = (V, E, f) ]</p>
<ul>
<li>( V )：节点集合。</li>
<li>( E )：超边集合，每个超边连接三个或更多节点。例如，一个超边 ( e<sub>i</sub> ) 可能连接节点 ( v<sub>j</sub>, v<sub>k</sub>, v<sub>l</sub> )。</li>
<li>( f )：一个函数，将每个超边与其连接的节点对应起来。</li>
</ul>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><ol>
<li><p><strong>社交网络</strong>：</p>
<ul>
<li>在社交网络中，三元超图可以表示三人之间的关系，例如三人共同参加的活动或共同发表的研究。</li>
</ul>
</li>
<li><p><strong>推荐系统</strong>：</p>
<ul>
<li>在产品推荐中，三元超图可以用来表示用户、产品和评价之间的关系，帮助推荐算法更好地理解用户偏好。</li>
</ul>
</li>
<li><p><strong>生态系统</strong>：</p>
<ul>
<li>在生态学中，三元超图可以用来描述物种之间的相互作用，如捕食、竞争或共生关系。</li>
</ul>
</li>
<li><p><strong>数据挖掘</strong>：</p>
<ul>
<li>在数据挖掘中，三元超图可以用来识别多方关系模式，例如在商业交易中，客户、产品和交易之间的关系。</li>
</ul>
</li>
</ol>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><p>假设我们有三个节点 ( A, B, C )，以及一个超边 ( e<sub>1</sub> )，连接这三个节点。在三元超图中，表示为：</p>
<ul>
<li>节点集合 ( V = \{ A, B, C \} )</li>
<li>超边集合 ( E = \{ e<sub>1</sub> \} )，其中 ( e<sub>1</sub> ) 连接节点 ( A, B, C )</li>
</ul>
<h3 id="相关概念"><a href="#相关概念" class="headerlink" title="相关概念"></a>相关概念</h3><ol>
<li><p><strong>三元关系</strong>：在数据库或知识图谱中，三元超图可以用于表示三元关系，例如“用户-产品-评价”。</p>
</li>
<li><p><strong>超图的分解</strong>：可以将三元超图分解为多个二元超图，以便进行更简单的分析和处理。</p>
</li>
</ol>
<h3 id="总结-11"><a href="#总结-11" class="headerlink" title="总结"></a>总结</h3><p>三元超图结构提供了一种灵活的方式来建模复杂关系，尤其是涉及三个或多个参与者的场景。它在社交网络、推荐系统、生态学等多个领域有广泛的应用。通过理解三元超图的结构和特性，可以更好地分析和设计复杂系统。</p>
<h3 id="七、新陈代谢网络"><a href="#七、新陈代谢网络" class="headerlink" title="七、新陈代谢网络"></a>七、新陈代谢网络</h3><p><strong>新陈代谢网络</strong>是生物学中的一个重要概念，通常用于描述细胞内的代谢过程。它通过网络模型来展示细胞内的化学反应、代谢物（如小分子）和酶之间的相互作用。以下是对新陈代谢网络的详细介绍，包括其定义、特性、应用及分析方法。</p>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><p>新陈代谢网络是一个图结构，节点代表代谢物或酶，边代表化学反应或代谢路径。这种网络有助于理解生物体如何进行能量转换、物质合成和分解。</p>
<h4 id="组成要素"><a href="#组成要素" class="headerlink" title="组成要素"></a>组成要素</h4><ol>
<li><p><strong>节点</strong>：</p>
<ul>
<li><strong>代谢物</strong>：网络中的化学物质，如葡萄糖、氨基酸、脂肪酸等。</li>
<li><strong>酶</strong>：催化生化反应的蛋白质，帮助将底物转化为产品。</li>
</ul>
</li>
<li><p><strong>边</strong>：</p>
<ul>
<li><strong>化学反应</strong>：连接代谢物和酶的边表示生化反应。每条边通常表示一个特定的反应过程。</li>
</ul>
</li>
</ol>
<h4 id="特性-1"><a href="#特性-1" class="headerlink" title="特性"></a>特性</h4><ol>
<li><p><strong>网络拓扑</strong>：新陈代谢网络的结构通常具有复杂的拓扑特性，如小世界性质、高聚类系数等，这反映了代谢反应的高度连接性和协同作用。</p>
</li>
<li><p><strong>代谢通路</strong>：新陈代谢网络包含多个代谢通路，路径由一系列连续的反应构成，反映了从底物到产品的转化过程。</p>
</li>
<li><p><strong>模块性</strong>：许多代谢网络具有模块化结构，即一些反应和代谢物的组合可以形成独立的功能单位。</p>
</li>
</ol>
<h4 id="应用-3"><a href="#应用-3" class="headerlink" title="应用"></a>应用</h4><ol>
<li><p><strong>系统生物学</strong>：新陈代谢网络用于研究细胞的整体代谢行为，帮助理解代谢调控和信号传导。</p>
</li>
<li><p><strong>疾病研究</strong>：通过分析代谢网络，可以识别与疾病相关的代谢异常，帮助开发新的治疗策略。</p>
</li>
<li><p><strong>生物工程</strong>：在代谢工程中，通过设计和优化代谢网络，可以提高细胞的生产能力，制造生物燃料和药物。</p>
</li>
<li><p><strong>生态系统建模</strong>：新陈代谢网络在生态系统中用于理解物种之间的相互作用，特别是在食物链和物质循环中。</p>
</li>
</ol>
<h4 id="分析方法"><a href="#分析方法" class="headerlink" title="分析方法"></a>分析方法</h4><ol>
<li><p><strong>网络建模</strong>：通过实验数据和生物信息学工具构建代谢网络模型，通常使用图论方法表示代谢通路。</p>
</li>
<li><p><strong>网络分析</strong>：应用图论指标（如度分布、聚类系数、路径长度等）分析网络的拓扑特性，揭示代谢网络的结构特征。</p>
</li>
<li><p><strong>动态模拟</strong>：使用动态模型（如代谢流分析、动态系统建模）模拟代谢网络的行为，预测在不同条件下的代谢反应。</p>
</li>
<li><p><strong>比较分析</strong>：比较不同生物体或不同条件下的代谢网络，以识别保守的代谢途径和特异性反应。</p>
</li>
</ol>
<h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h4><p>以下是新陈代谢网络的一些典型实例：</p>
<ul>
<li><p><strong>糖酵解途径</strong>：糖酵解是细胞代谢中的一个重要过程，涉及多个代谢物（如葡萄糖、丙酮酸）和酶的反应。该途径的网络图展示了从葡萄糖到丙酮酸的转化过程，以及涉及的关键酶。</p>
</li>
<li><p><strong>三羧酸循环（Krebs Cycle）</strong>：这是细胞呼吸的核心途径，包含一系列反应，将丙酮酸转化为能量。在代谢网络中，该循环的节点和边展示了能量代谢的重要环节。</p>
</li>
</ul>
<h4 id="总结-12"><a href="#总结-12" class="headerlink" title="总结"></a>总结</h4><p>新陈代谢网络是生物学研究中不可或缺的一部分，通过网络模型，可以更深入地理解代谢过程的复杂性和调控机制。这种分析方法在基础研究、药物开发和生物工程等领域具有广泛的应用。</p>
<h3 id="八、网络的拓扑性质、演化模型和动力学机制"><a href="#八、网络的拓扑性质、演化模型和动力学机制" class="headerlink" title="八、网络的拓扑性质、演化模型和动力学机制"></a>八、网络的拓扑性质、演化模型和动力学机制</h3><p>网络的拓扑性质、演化模型和动力学机制是网络科学中的三个核心概念，彼此相互关联，共同影响网络的结构和行为。以下是对这三者的详细探讨，包括定义、特性和相互关系。</p>
<h4 id="1-网络的拓扑性质"><a href="#1-网络的拓扑性质" class="headerlink" title="1. 网络的拓扑性质"></a>1. 网络的拓扑性质</h4><p><strong>定义</strong>：<br>网络的拓扑性质是指网络结构的基本特征，包括节点之间的连接方式和模式。这些性质可以用来描述网络的整体形态以及节点间的相互关系。</p>
<p><strong>主要拓扑性质</strong>：</p>
<ul>
<li><p><strong>度分布</strong>：</p>
<ul>
<li>表示每个节点的连接数（度）的分布情况。常见的度分布类型包括泊松分布（随机网络）、幂律分布（无标度网络）等。</li>
</ul>
</li>
<li><p><strong>聚类系数</strong>：</p>
<ul>
<li>描述节点之间形成三角形（即邻居之间的连接）的程度。高聚类系数通常表示网络中存在较多的局部紧密群体。</li>
</ul>
</li>
<li><p><strong>路径长度</strong>：</p>
<ul>
<li>网络中任意两个节点之间的最短路径的平均长度。小世界网络通常具有短路径长度和高聚类系数。</li>
</ul>
</li>
<li><p><strong>连通性</strong>：</p>
<ul>
<li>描述网络的整体连通性程度，包括强连通性（每个节点都能到达其他节点）和弱连通性（忽略方向的连通性）。</li>
</ul>
</li>
</ul>
<p><strong>应用</strong>：<br>网络的拓扑性质对于理解网络的功能、韧性和信息传播等方面至关重要。不同类型的网络（如社交网络、生物网络、交通网络等）往往具有不同的拓扑特征。</p>
<h4 id="2-演化模型"><a href="#2-演化模型" class="headerlink" title="2. 演化模型"></a>2. 演化模型</h4><p><strong>定义</strong>：<br>演化模型用于描述网络随时间变化的过程，通常关注节点和边的添加、删除以及网络结构的演化。</p>
<p><strong>主要演化模型</strong>：</p>
<ul>
<li><p><strong>巴尔巴西-阿尔伯特模型（BA模型）</strong>：</p>
<ul>
<li>无标度网络的经典模型，通过“优先连接”机制（即新节点倾向于连接已有较多连接的节点）生成幂律度分布。</li>
</ul>
</li>
<li><p><strong>小世界模型</strong>：</p>
<ul>
<li>通过随机重连边的方式将规则网络转变为小世界网络，具有短路径和高聚类特性。</li>
</ul>
</li>
<li><p><strong>动态网络模型</strong>：</p>
<ul>
<li>描述网络结构在时间上的变化，节点和边可以动态添加或删除，考虑复杂的交互作用。</li>
</ul>
</li>
</ul>
<p><strong>应用</strong>：<br>演化模型用于预测和分析网络如何随时间发展，帮助理解社交网络的形成、流行病传播的动态过程等。</p>
<h4 id="3-动力学机制"><a href="#3-动力学机制" class="headerlink" title="3. 动力学机制"></a>3. 动力学机制</h4><p><strong>定义</strong>：<br>动力学机制指的是网络中节点和边之间的相互作用如何驱动系统行为和演化的过程。这些机制通常涉及个体行为、交互模式和外部环境等因素。</p>
<p><strong>主要动力学机制</strong>：</p>
<ul>
<li><p><strong>传播机制</strong>：</p>
<ul>
<li>包括信息传播、病毒传播等，通过节点之间的连接和状态变化（如感染、传播、接收等）影响网络的动态行为。</li>
</ul>
</li>
<li><p><strong>竞争与合作机制</strong>：</p>
<ul>
<li>描述网络中个体之间的竞争与合作行为，影响网络中资源的分配和信息的流动。</li>
</ul>
</li>
<li><p><strong>反馈机制</strong>：</p>
<ul>
<li>网络中个体对其他个体行为的反应，可能导致自增强或自抑制的效应，影响网络的稳定性和演化。</li>
</ul>
</li>
</ul>
<p><strong>应用</strong>：<br>动力学机制用于分析和建模网络中的各种动态过程，如流行病传播、创新扩散、舆论形成等。</p>
<h4 id="三者的相互关系"><a href="#三者的相互关系" class="headerlink" title="三者的相互关系"></a>三者的相互关系</h4><ul>
<li><p><strong>拓扑性质与演化模型</strong>：</p>
<ul>
<li>网络的拓扑性质影响其演化模型的设计。例如，无标度网络的特性促使研究者发展基于优先连接的演化模型。</li>
</ul>
</li>
<li><p><strong>演化模型与动力学机制</strong>：</p>
<ul>
<li>演化模型提供了网络的结构变化框架，而动力学机制则通过节点和边的交互驱动这些变化。例如，信息传播机制可以通过修改网络的结构（如增加新连接）来影响信息的传播效率。</li>
</ul>
</li>
<li><p><strong>拓扑性质与动力学机制</strong>：</p>
<ul>
<li>网络的拓扑性质会影响其动力学行为。例如，具有高聚类系数的网络在信息传播方面可能更高效，而度分布的变化会影响个体之间的交互模式。</li>
</ul>
</li>
</ul>
<h3 id="总结-13"><a href="#总结-13" class="headerlink" title="总结"></a>总结</h3><p>网络的拓扑性质、演化模型和动力学机制是理解复杂网络行为的关键要素。通过结合这三者，可以深入探讨网络在不同环境和条件下的表现，从而为实际应用（如社交网络分析、流行病建模和资源管理等）提供重要的理论支持。</p>
<h3 id="九、度及其相关指标"><a href="#九、度及其相关指标" class="headerlink" title="九、度及其相关指标"></a>九、度及其相关指标</h3><p>“度”（Degree）是网络分析中最基本的中心性度量之一，表示节点与其他节点的直接连接数。在网络图中，节点的度能够反映该节点的基本活跃度和重要性。根据网络的类型，度可以分为几种不同的形式：</p>
<h4 id="1-度（Degree）"><a href="#1-度（Degree）" class="headerlink" title="1. 度（Degree）"></a>1. <strong>度（Degree）</strong></h4><ul>
<li><p><strong>无向网络</strong>：在无向网络中，节点的度就是与该节点相连的边的数量。如果一个节点与3个其他节点相连，则其度为3。<br><img src="./images/efigure09.png" alt="图九"></p>
</li>
<li><p>A<sub>vi</sub>是邻接矩阵中的元素，表示节点 (v) 和节点 (i) 之间是否存在连边。</p>
</li>
<li><p><strong>有向网络</strong>：在有向网络中，度可以分为入度（in-degree）和出度（out-degree）。</p>
<ul>
<li><strong>入度</strong>：指向该节点的边的数量，表示该节点接收的连接数。</li>
<li><strong>出度</strong>：从该节点指向其他节点的边的数量，表示该节点发出的连接数。</li>
</ul>
<p><img src="./images/efigure10.png" alt="图10"></p>
</li>
</ul>
<h4 id="2-度分布（Degree-Distribution）"><a href="#2-度分布（Degree-Distribution）" class="headerlink" title="2. 度分布（Degree Distribution）"></a>2. <strong>度分布（Degree Distribution）</strong></h4><p>度分布描述了网络中各个节点的度的分布情况。度分布常用于了解网络的全局结构特性。对于一个网络，度分布 (P(k)) 表示度为 (k) 的节点的比例。常见的度分布包括：</p>
<ul>
<li><strong>泊松分布</strong>：随机图中节点度通常服从泊松分布。</li>
<li><strong>幂律分布</strong>：许多现实网络（如社交网络、互联网等）往往呈现幂律分布，即大多数节点度较小，但少数节点具有非常高的度。这些高度节点被称为<strong>枢纽节点</strong>（hubs）。</li>
</ul>
<h4 id="3-平均度（Average-Degree）"><a href="#3-平均度（Average-Degree）" class="headerlink" title="3. 平均度（Average Degree）"></a>3. <strong>平均度（Average Degree）</strong></h4><p>整个网络的平均度表示网络中节点的平均连接数，计算方式为：<br><img src="./images/efigure11.png" alt="图10"><br>其中 (E) 是边的数量，(N) 是节点的数量。平均度可以用来衡量网络的稠密性。</p>
<h4 id="4-加权度（Weighted-Degree）"><a href="#4-加权度（Weighted-Degree）" class="headerlink" title="4. 加权度（Weighted Degree）"></a>4. <strong>加权度（Weighted Degree）</strong></h4><p>在加权网络中，边不只是简单的0或1，而是有权重。加权度反映了与一个节点相连的边的权重总和。对于节点 (v)，其加权度为：<br><img src="./images/efigure12.png" alt="图11"><br>其中 (W<sup>vi</sup>) 是节点 (v) 和节点 (i) 之间边的权重。</p>
<h4 id="5-度中心性（Degree-Centrality）"><a href="#5-度中心性（Degree-Centrality）" class="headerlink" title="5. 度中心性（Degree Centrality）"></a>5. <strong>度中心性（Degree Centrality）</strong></h4><p>度中心性是最简单的一种中心性度量，直接使用节点的度来衡量其重要性。度中心性 (C<sub>D</sub>(v)) 表示节点 (v) 的度与网络中其他节点数的比值：<br><img src="./images/efigure13.png" alt="图13"><br>度中心性反映了节点在网络中的直接连接数量，度越高的节点通常被视为更具影响力或更为活跃。</p>
<h4 id="6-相关度量"><a href="#6-相关度量" class="headerlink" title="6. 相关度量"></a>6. <strong>相关度量</strong></h4><ul>
<li><p><strong>邻居数（Neighbors）</strong>：某个节点的邻居数即为其度数，表示该节点直接相连的节点数。</p>
</li>
<li><p><strong>邻居的度（Neighbors’ Degree）</strong>：网络中的高度节点通常倾向于与其他高度节点相连，这一特性被称为<strong>同配性</strong>（assortativity）。可以通过计算邻居节点的平均度来评估某个节点的连接特性。</p>
<p>平均邻居度（average neighbor degree）为：<br><img src="./images/efigure13.png" alt="图14"></p>
</li>
<li><p><strong>聚类系数（Clustering Coefficient）</strong>：度与聚类系数结合在一起能更好地描述节点所处的局部网络结构。聚类系数衡量节点邻居间彼此相连的程度，反映了网络的团簇性。</p>
</li>
<li><p><strong>度关联性（Degree Assortativity）</strong>：表示节点的度是否倾向于与具有相似度的其他节点相连。如果高度节点倾向于与其他高度节点相连，则网络是同配的；反之则为异配。</p>
</li>
</ul>
<h4 id="7-度的应用"><a href="#7-度的应用" class="headerlink" title="7. 度的应用"></a>7. <strong>度的应用</strong></h4><p>度及其相关度量在很多领域有广泛的应用：</p>
<ul>
<li><strong>社交网络</strong>：节点度可以用来衡量用户的社交活跃度或信息传播能力。</li>
<li><strong>生物网络</strong>：在蛋白质相互作用网络中，节点的度可以帮助识别关键的蛋白质。</li>
<li><strong>互联网</strong>：在互联网拓扑中，度用于衡量网站或服务器的连接性。</li>
</ul>
<h3 id="十、节点的余平均超度"><a href="#十、节点的余平均超度" class="headerlink" title="十、节点的余平均超度"></a>十、节点的余平均超度</h3><p><strong>余平均超度</strong>（Residual Average Hyperdegree）是超图（hypergraph）中的一个节点度量，用于衡量某个节点在其邻域中与其他节点的平均连接强度。它是传统图中的“余平均度”在超图中的推广。</p>
<h4 id="1-超度（Hyperdegree）"><a href="#1-超度（Hyperdegree）" class="headerlink" title="1. 超度（Hyperdegree）"></a>1. <strong>超度（Hyperdegree）</strong></h4><p>在超图中，节点的<strong>超度</strong>指的是与该节点相关联的超边数量。每个超边可以连接多个节点，因此一个节点的超度衡量的是它参与的超边数量。例如，如果某节点 (v) 出现在5条超边中，则它的超度为5。</p>
<h4 id="2-余平均超度（Residual-Average-Hyperdegree）"><a href="#2-余平均超度（Residual-Average-Hyperdegree）" class="headerlink" title="2. 余平均超度（Residual Average Hyperdegree）"></a>2. <strong>余平均超度（Residual Average Hyperdegree）</strong></h4><p>余平均超度反映的是一个节点的邻居节点的超度的平均值，类似于图中的“余平均度”，即“某个节点的邻居节点的平均度”。在超图中，对于一个节点 (v)，其余平均超度定义为该节点在与它相连的所有超边中，其他节点的平均超度。这能够揭示该节点在其局部结构中所处的位置和影响力。</p>
<h4 id="公式："><a href="#公式：" class="headerlink" title="公式："></a>公式：</h4><p>假设节点 (v) 与 (k(v)) 个超边相连，且每个超边 (e_i) 包含若干节点。节点 (v) 的余平均超度 (r(v)) 可以表示为：<br><img src="./images/efigure14.png" alt="图14"><br>其中：</p>
<ul>
<li>(E(v)) 是节点 (v) 所连接的超边集合；</li>
<li>(|e|) 是超边 (e) 中的节点总数；</li>
<li>(k(u)) 是节点 (u) 的超度，表示节点 (u) 参与的超边数。</li>
</ul>
<h4 id="解释："><a href="#解释：" class="headerlink" title="解释："></a>解释：</h4><ol>
<li>对于每个与节点 (v) 相连的超边 (e)，计算除了节点 (v) 以外的其他节点的超度。</li>
<li>对每条超边中的这些邻居节点的超度进行平均，然后对所有超边的结果取平均。</li>
</ol>
<p>这样计算出的余平均超度衡量了节点 (v) 所连接的邻居节点的活跃度。换句话说，如果节点的余平均超度较高，说明它的邻居节点都参与了较多的超边，节点所处的网络区域较为活跃。</p>
<h4 id="3-余平均超度的意义"><a href="#3-余平均超度的意义" class="headerlink" title="3. 余平均超度的意义"></a>3. <strong>余平均超度的意义</strong></h4><ul>
<li><p><strong>本地网络结构</strong>：余平均超度反映了节点周围的超图结构。如果一个节点的余平均超度较高，则说明它所连接的其他节点在超图中也相对活跃，表明节点所在的区域连接紧密、互动频繁。</p>
</li>
<li><p><strong>网络的异质性</strong>：如果余平均超度与超度之间存在较大的差异，则意味着节点的邻居节点之间的连接模式不同，超图呈现异质性特征。相反，如果超度与余平均超度接近，则意味着网络的局部结构较为均匀。</p>
</li>
</ul>
<h4 id="4-应用场景"><a href="#4-应用场景" class="headerlink" title="4. 应用场景"></a>4. <strong>应用场景</strong></h4><ul>
<li><p><strong>社交网络</strong>：在社交超图中，一个节点的余平均超度可以用来衡量该节点的朋友（邻居节点）的社交活跃度。比如，某人在多个社交群体中活动，而这些群体中的其他成员都较为活跃，则该人的余平均超度可能较高。</p>
</li>
<li><p><strong>合作网络</strong>：在科研合作网络中，科研人员通过合作论文形成超边。如果某科研人员的余平均超度较高，则意味着该科研人员的合作者往往是多产且活跃的研究者。</p>
</li>
<li><p><strong>生物网络</strong>：在生物分子超图中，一个分子的余平均超度可以反映其相互作用分子的关联度和重要性，帮助理解其在分子网络中的功能角色。</p>
</li>
</ul>
<h4 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h4><p>余平均超度是对节点局部结构的度量，反映了节点的邻居节点的活跃度和连接强度。在超图中，它通过考虑节点连接的超边中的其他节点来更全面地描述节点在网络中的重要性和影响力。</p>
<h3 id="十一、中心性指标"><a href="#十一、中心性指标" class="headerlink" title="十一、中心性指标"></a>十一、中心性指标</h3><p><strong>中心性指标</strong>（Centrality Metrics）是网络分析中用于衡量节点在网络中重要性、影响力或位置的指标。不同的中心性指标强调节点在网络结构中的不同特征，适用于不同的分析目的。常见的中心性指标包括<strong>度中心性</strong>、<strong>介数中心性</strong>、<strong>接近中心性</strong>、<strong>特征向量中心性</strong>等。以下是几种主要的中心性指标及其定义和应用场景：</p>
<h4 id="1-度中心性（Degree-Centrality）"><a href="#1-度中心性（Degree-Centrality）" class="headerlink" title="1. 度中心性（Degree Centrality）"></a>1. <strong>度中心性（Degree Centrality）</strong></h4><p>度中心性是最基本的中心性度量，表示一个节点的连接数，即该节点与多少其他节点直接相连。</p>
<ul>
<li><p><strong>公式</strong>：对于无向网络，节点 (v) 的度中心性为：<br>C<sub>D</sub>(v) = k(v)<br>对于有向网络，分别有入度中心性（in-degree）和出度中心性（out-degree）。</p>
</li>
<li><p><strong>解释</strong>：度中心性表示节点的局部影响力。度越高的节点直接连接的其他节点越多，通常被认为更活跃或重要。</p>
</li>
<li><p><strong>应用</strong>：社交网络中，度中心性可以用于衡量某人有多少直接的朋友或联系人。在互联网拓扑中，度中心性可以表示服务器或网站的连接数。</p>
</li>
</ul>
<h4 id="2-介数中心性（Betweenness-Centrality）"><a href="#2-介数中心性（Betweenness-Centrality）" class="headerlink" title="2. 介数中心性（Betweenness Centrality）"></a>2. <strong>介数中心性（Betweenness Centrality）</strong></h4><p>介数中心性衡量一个节点在网络中作为其他节点对之间最短路径的中介程度。节点的介数中心性越高，说明该节点越多地处于其他节点之间的最短路径上。</p>
<ul>
<li><p><strong>公式</strong>：<br><img src="./images/efigure15.png" alt="图15"></p>
</li>
<li><p><strong>解释</strong>：介数中心性反映了节点作为“桥梁”或“中介”的作用，重要性体现在信息传播和控制流通上。</p>
</li>
<li><p><strong>应用</strong>：在交通网络中，介数中心性高的节点可以是交通枢纽。在社交网络中，介数中心性可以用来识别在不同群体间起到桥梁作用的人物。</p>
</li>
</ul>
<h4 id="3-接近中心性（Closeness-Centrality）"><a href="#3-接近中心性（Closeness-Centrality）" class="headerlink" title="3. 接近中心性（Closeness Centrality）"></a>3. <strong>接近中心性（Closeness Centrality）</strong></h4><p>接近中心性度量的是一个节点与网络中其他所有节点的距离的倒数，表示一个节点能以多快的速度触达网络中所有其他节点。接近中心性越高，说明节点距离其他节点越近。</p>
<ul>
<li><p><strong>公式</strong>：<br>[<br>C_C(v) = \frac{1}{\sum_{u} d(v, u)}<br>]<br>其中 (d(v, u)) 表示节点 (v) 和 (u) 之间的最短路径距离。</p>
</li>
<li><p><strong>解释</strong>：接近中心性反映了节点在网络中的整体位置，离其他节点越近，其在网络中的信息传播能力越强。</p>
</li>
<li><p><strong>应用</strong>：接近中心性适合分析信息传播网络或电信网络中的节点，可以用来衡量信息传播的效率。</p>
</li>
</ul>
<h4 id="4-特征向量中心性（Eigenvector-Centrality）"><a href="#4-特征向量中心性（Eigenvector-Centrality）" class="headerlink" title="4. 特征向量中心性（Eigenvector Centrality）"></a>4. <strong>特征向量中心性（Eigenvector Centrality）</strong></h4><p>特征向量中心性不仅考虑节点的度，还考虑与其相连的节点的重要性。如果一个节点与很多高重要性的节点相连，则其特征向量中心性会更高。换句话说，特征向量中心性衡量了节点的“影响力”。</p>
<ul>
<li><p><strong>公式</strong>：<br><img src="./../images/efigure16.png" alt="图6"></p>
</li>
<li><p><strong>解释</strong>：特征向量中心性与度中心性类似，但更强调节点所连接的节点的权重。通过迭代计算，最终得到网络中所有节点的相对重要性。</p>
</li>
<li><p><strong>应用</strong>：特征向量中心性在社交网络和网页排名（如Google的PageRank算法）中有广泛应用，能够识别不仅活跃而且连接有影响力节点的节点。</p>
</li>
</ul>
<h4 id="5-PageRank"><a href="#5-PageRank" class="headerlink" title="5. PageRank"></a>5. <strong>PageRank</strong></h4><p>PageRank 是特征向量中心性的特例，最初由Google用于网页排名。PageRank 计算的是通过随机游走，一个节点被访问的概率。它不仅考虑节点的连接数，还考虑与其相连的节点的重要性。</p>
<ul>
<li><p><strong>公式</strong>：<br><img src="./images/efigure17.png" alt="图"><br>其中，(d) 是阻尼因子（通常设为 0.85），(N(v)) 是节点 (v) 的邻居，(k(u)) 是邻居节点 (u) 的度。</p>
</li>
<li><p><strong>应用</strong>：PageRank 常用于排序网页的重要性，也可以用于社交网络中衡量节点的重要性。</p>
</li>
</ul>
<h4 id="6-Katz-中心性（Katz-Centrality）"><a href="#6-Katz-中心性（Katz-Centrality）" class="headerlink" title="6. Katz 中心性（Katz Centrality）"></a>6. <strong>Katz 中心性（Katz Centrality）</strong></h4><p>Katz 中心性度量一个节点的影响力，考虑节点的直接连接和间接连接（通过其他节点的连接）。它通过加权的方式，将距离较远的节点影响力降低。</p>
<ul>
<li><p><strong>公式</strong>：<br><img src="./images/efigure18.png" alt="图"></p>
</li>
<li><p><strong>应用</strong>：适用于分析权力分布和信息流通的场景。</p>
</li>
</ul>
<h4 id="7-近邻中心性（Local-Centrality）"><a href="#7-近邻中心性（Local-Centrality）" class="headerlink" title="7. 近邻中心性（Local Centrality）"></a>7. <strong>近邻中心性（Local Centrality）</strong></h4><p>近邻中心性是节点在其局部网络中的影响力，常用于分析节点在其邻居中所占据的中心位置。</p>
<h4 id="8-传播中心性（Propagation-Centrality）"><a href="#8-传播中心性（Propagation-Centrality）" class="headerlink" title="8. 传播中心性（Propagation Centrality）"></a>8. <strong>传播中心性（Propagation Centrality）</strong></h4><p>这种中心性衡量节点在网络中传播信息的能力，特别适用于动态传播网络，例如疾病传播或信息扩散。</p>
<h4 id="总结-14"><a href="#总结-14" class="headerlink" title="总结"></a><strong>总结</strong></h4><p>不同的中心性指标从不同的角度揭示了网络中节点的重要性：</p>
<ul>
<li><strong>度中心性</strong>：反映直接连接的数量；</li>
<li><strong>介数中心性</strong>：反映节点在网络中起到桥梁作用的程度；</li>
<li><strong>接近中心性</strong>：表示节点距离其他节点的紧密程度；</li>
<li><strong>特征向量中心性</strong>：衡量节点和其邻居的重要性；</li>
<li><strong>PageRank</strong>：考虑随机游走的概率；</li>
<li><strong>Katz 中心性</strong>：同时考虑直接和间接连接的影响力。</li>
</ul>
<h3 id="十二、节点的子图中心性"><a href="#十二、节点的子图中心性" class="headerlink" title="十二、节点的子图中心性"></a>十二、节点的子图中心性</h3><p>节点的子图中心性（Subgraph Centrality）是一种用于衡量网络中节点重要性的方法，它反映了一个节点参与不同子图的频率。该中心性考虑了节点处于各种规模子图中的贡献，尤其是三角形、四边形等子图。它通过计算节点在这些子图中的存在程度来确定节点的重要性。</p>
<p>具体来说，子图中心性基于邻接矩阵的谱特性。通过邻接矩阵的特征值和特征向量，可以计算出节点的子图中心性。它不仅考虑节点在局部结构中的参与情况，还可以权衡节点在整个网络结构中的影响力。公式通常使用矩阵指数（matrix exponential）来表达：</p>
<p><img src="./images/efigure08.png" alt="图8"></p>
<p>其中：</p>
<ul>
<li>(C(v)) 表示节点 (v) 的子图中心性。</li>
<li>(A<sup>k</sup>) 是邻接矩阵 (A) 的 (k) 次幂，表示网络中长度为 (k) 的路径。</li>
<li>((A<sup>k</sup>)<sub>vv</sub>}) 是 (A<sup>k</sup>) 对角线上与节点 (v) 对应的元素，表示节点 (v) 参与的闭合路径（子图）。</li>
</ul>
<p>这种中心性能够很好地捕捉节点在网络中不同规模的结构中所处的位置，因此是一种能够全面反映节点重要性的度量方法。</p>
<h4 id="子图中心性的应用"><a href="#子图中心性的应用" class="headerlink" title="子图中心性的应用"></a>子图中心性的应用</h4><ul>
<li><strong>社交网络分析</strong>：用来识别在社交网络中影响力大的个人。</li>
<li><strong>生物网络分析</strong>：在基因调控网络或蛋白质相互作用网络中用于发现关键的生物分子。</li>
<li><strong>信息传播</strong>：可以帮助分析信息在网络中如何有效传播。</li>
</ul>
<h3 id="十三、结构度量指标"><a href="#十三、结构度量指标" class="headerlink" title="十三、结构度量指标"></a>十三、结构度量指标</h3><p><strong>结构度量指标</strong>（Structural Metrics）是用于描述网络结构特征的指标，帮助理解网络的整体形态、局部特征和连接模式。通过这些度量，可以量化网络的稠密性、集群性、分层性等不同性质，从而揭示网络的功能和行为模式。以下是常见的结构度量指标：</p>
<h4 id="1-平均度（Average-Degree）"><a href="#1-平均度（Average-Degree）" class="headerlink" title="1. 平均度（Average Degree）"></a>1. <strong>平均度（Average Degree）</strong></h4><ul>
<li><strong>定义</strong>：平均度是网络中所有节点度的平均值，反映了网络的整体连接性。</li>
<li><strong>公式</strong>：<br><img src="./images/efigure11.png" alt="图10"><br>其中，(E) 是网络中的边数，(N) 是节点数。</li>
<li><strong>解释</strong>：平均度描述了每个节点与其他节点连接的平均数量，能够衡量网络的稠密性。</li>
</ul>
<h4 id="2-度分布（Degree-Distribution）-1"><a href="#2-度分布（Degree-Distribution）-1" class="headerlink" title="2. 度分布（Degree Distribution）"></a>2. <strong>度分布（Degree Distribution）</strong></h4><ul>
<li><strong>定义</strong>：度分布 (P(k)) 是度为 (k) 的节点所占的比例，反映了网络中节点连接的异质性。</li>
<li><strong>解释</strong>：网络的度分布可以呈现不同的形态，如<strong>泊松分布</strong>（随机网络）、<strong>幂律分布</strong>（无标度网络），帮助理解网络的拓扑结构特征。</li>
<li><strong>应用</strong>：幂律分布常见于社交网络、互联网等现实世界网络，少数节点具有极高的度（枢纽节点），而大多数节点度较小。</li>
</ul>
<h4 id="3-聚类系数（Clustering-Coefficient）-1"><a href="#3-聚类系数（Clustering-Coefficient）-1" class="headerlink" title="3. 聚类系数（Clustering Coefficient）"></a>3. <strong>聚类系数（Clustering Coefficient）</strong></h4><ul>
<li><strong>定义</strong>：聚类系数衡量一个节点的邻居之间相互连接的程度，反映了网络的局部集群性。节点 (v) 的聚类系数 (C(v)) 由其邻居之间实际存在的边数与最大可能边数的比值决定。</li>
<li><strong>公式</strong>：<br><img src="./images/efigure19.png" alt=""><br>其中，(E<sub>v</sub>) 是节点 (v) 的邻居之间的边数，(k(v)) 是节点 (v) 的度。</li>
<li><strong>平均聚类系数</strong>：整个网络的平均聚类系数为所有节点聚类系数的平均值。</li>
<li><strong>解释</strong>：聚类系数高的网络通常表现出团状结构，表明节点倾向于与其邻居形成紧密的群体。</li>
</ul>
<h4 id="4-路径长度（Path-Length）"><a href="#4-路径长度（Path-Length）" class="headerlink" title="4. 路径长度（Path Length）"></a>4. <strong>路径长度（Path Length）</strong></h4><ul>
<li><strong>定义</strong>：路径长度是网络中两个节点之间的最短路径的边数。平均路径长度是所有节点对之间最短路径长度的平均值。</li>
<li><strong>公式</strong>：<br><img src="./images/efigure20.png" alt=""><br>其中，(d(i, j)) 是节点 (i) 和节点 (j) 之间的最短路径距离。</li>
<li><strong>解释</strong>：平均路径长度描述了网络中信息传播的效率，路径越短，网络内信息或资源传播的速度越快。<strong>小世界网络</strong>具有较短的平均路径长度和高聚类系数。</li>
</ul>
<h4 id="5-网络直径（Network-Diameter）"><a href="#5-网络直径（Network-Diameter）" class="headerlink" title="5. 网络直径（Network Diameter）"></a>5. <strong>网络直径（Network Diameter）</strong></h4><ul>
<li><strong>定义</strong>：网络直径是网络中任意两个节点之间的最短路径中的最大值。</li>
<li><strong>解释</strong>：网络直径代表了网络的“宽度”，即网络中最远节点之间的距离。直径越大，网络整体传播过程的时间越长。</li>
</ul>
<h4 id="6-连通性（Connectivity）"><a href="#6-连通性（Connectivity）" class="headerlink" title="6. 连通性（Connectivity）"></a>6. <strong>连通性（Connectivity）</strong></h4><ul>
<li><strong>定义</strong>：连通性衡量网络中节点之间的可达性，即节点对之间是否存在路径。网络的连通性可通过<strong>连通分量</strong>（connected components）来表示。<ul>
<li><strong>强连通分量</strong>（Strongly Connected Components）：在有向图中，所有节点之间均可互相到达的子集。</li>
<li><strong>弱连通分量</strong>（Weakly Connected Components）：在有向图中，忽略边的方向后，所有节点之间均可互相到达的子集。</li>
</ul>
</li>
<li><strong>解释</strong>：连通性指标反映网络的整体连通程度，有助于理解网络的全局结构。</li>
</ul>
<h4 id="7-密度（Density）"><a href="#7-密度（Density）" class="headerlink" title="7. 密度（Density）"></a>7. <strong>密度（Density）</strong></h4><ul>
<li><strong>定义</strong>：网络密度表示实际存在的边数与可能存在的最大边数的比值，衡量网络的稠密程度。</li>
<li><strong>公式</strong>：</li>
</ul>
<p><img src="./images/efigure21.png" alt=""></p>
<ul>
<li>其中，(E) 是网络中的边数，(N) 是节点数。</li>
<li><strong>解释</strong>：密度越高，说明网络中的节点间联系越紧密。密度通常用于评估小型网络或局部网络的结构特征。</li>
</ul>
<h4 id="8-同配性（Assortativity）"><a href="#8-同配性（Assortativity）" class="headerlink" title="8. 同配性（Assortativity）"></a>8. <strong>同配性（Assortativity）</strong></h4><ul>
<li><strong>定义</strong>：同配性衡量网络中具有相似属性的节点之间是否更倾向于相连。对于度的同配性，通常研究高度节点是否倾向于与其他高度节点相连。</li>
<li><strong>公式</strong>：<br><img src="./images/efigure22.png" alt=""><br>其中，(k<sub>i</sub>) 和 (k<sub>j</sub>) 是相连节点的度，(&lt; k &gt;) 是平均度。</li>
<li><strong>解释</strong>：正同配性（(r &gt; 0)）表明高度节点倾向于相互连接，负同配性（(r &lt; 0)）表明高低度节点之间更多相连。</li>
</ul>
<h4 id="9-核心度（k-core）"><a href="#9-核心度（k-core）" class="headerlink" title="9. 核心度（k-core）"></a>9. <strong>核心度（k-core）</strong></h4><ul>
<li><strong>定义</strong>：k-core 是网络中的一个子图，其中每个节点的度至少为 (k)。通过去除度小于 (k) 的节点，不断形成更小的 k-core 子图，直到剩余节点的度均大于等于 (k)。</li>
<li><strong>解释</strong>：k-core 用于识别网络中的核心群体，揭示网络中节点的层级结构或中心性。</li>
</ul>
<h4 id="10-模块度（Modularity）"><a href="#10-模块度（Modularity）" class="headerlink" title="10. 模块度（Modularity）"></a>10. <strong>模块度（Modularity）</strong></h4><ul>
<li><strong>定义</strong>：模块度是衡量网络中社区结构的指标，反映网络中的节点是否倾向于形成多个内部连接密集、外部连接稀疏的群体（社区）。模块度越高，说明社区结构越明显。</li>
<li><strong>公式</strong>：<br><img src="./images/efigure23.png" alt=""><br>其中，(A<sub>ij</sub>) 是邻接矩阵，(k<sub>i</sub>) 是节点 (i) 的度，(c<sub>i</sub>) 是节点 (i) 的社区标签。</li>
<li><strong>解释</strong>：模块度用于衡量网络是否具有明显的社区划分，并可以用于评估社区检测算法的效果。</li>
</ul>
<h4 id="11-子图中心性（Subgraph-Centrality）"><a href="#11-子图中心性（Subgraph-Centrality）" class="headerlink" title="11. 子图中心性（Subgraph Centrality）"></a>11. <strong>子图中心性（Subgraph Centrality）</strong></h4><ul>
<li><strong>定义</strong>：子图中心性衡量节点参与不同规模闭合路径（如环形路径、循环）的程度。子图中心性高的节点倾向于位于多个闭合路径中，反映其在局部网络中的重要性。</li>
</ul>
<h3 id="总结-15"><a href="#总结-15" class="headerlink" title="总结"></a><strong>总结</strong></h3><p>结构度量指标用于定量分析网络的各种拓扑特性，如节点连接模式、网络的紧密性、社区结构等。通过这些指标，可以更好地理解复杂网络的性质，并为应用场景中的网络优化和分析提供数据支持。根据具体的研究问题，可以选择相应的结构度量来揭示网络的整体或局部特性。</p>
<h3 id="十四、聚集指标"><a href="#十四、聚集指标" class="headerlink" title="十四、聚集指标"></a>十四、聚集指标</h3><p><strong>聚集指标</strong>（Aggregation Metrics）是用来衡量网络中节点间形成团体、集群或子群的程度。它们主要关注节点间的紧密连接程度、群体结构以及子群体在网络中的分布情况。常用的聚集指标包括<strong>聚类系数</strong>、<strong>模块度</strong>、<strong>k-core</strong>分析等。以下是几种常见的聚集指标及其详细介绍：</p>
<h4 id="1-聚类系数（Clustering-Coefficient）-1"><a href="#1-聚类系数（Clustering-Coefficient）-1" class="headerlink" title="1. 聚类系数（Clustering Coefficient）"></a>1. <strong>聚类系数（Clustering Coefficient）</strong></h4><p>聚类系数是衡量网络中节点的局部聚集性的指标，反映了某节点的邻居之间相互连接的紧密程度。</p>
<ul>
<li><p><strong>节点的聚类系数</strong>：表示节点的邻居之间有多大概率互相连接。节点 (v) 的聚类系数 (C(v)) 由其邻居之间的实际边数与最大可能边数的比值决定。</p>
<p><strong>公式</strong>：<br><img src="./images/efigure19.png" alt=""><br>其中，(E<sub>v</sub>) 是节点 (v) 的邻居之间的实际边数，(k(v)) 是节点 (v) 的度。</p>
</li>
<li><p><strong>全网络的平均聚类系数</strong>：表示整个网络的平均局部连接性，等于所有节点聚类系数的平均值。</p>
<p><strong>公式</strong>：<br><img src="./images/efigure24.png" alt=""><br>其中，(N) 是网络中的节点总数，(V) 是所有节点的集合。</p>
</li>
<li><p><strong>解释</strong>：聚类系数高的节点表示其邻居间的联系较紧密，通常形成团体或小群体。平均聚类系数高的网络表明具有较高的局部群体结构。</p>
</li>
</ul>
<h4 id="2-模块度（Modularity）"><a href="#2-模块度（Modularity）" class="headerlink" title="2. 模块度（Modularity）"></a>2. <strong>模块度（Modularity）</strong></h4><p>模块度是衡量网络中社区结构的指标，反映网络是否具有明显的群体或社区划分。高模块度意味着网络中存在一些节点之间连接紧密、但与其他社区连接稀疏的群体。</p>
<ul>
<li><p><strong>公式</strong>：<br><img src="./images/efigure23.png" alt=""><br>其中：</p>
<ul>
<li>(E) 是网络中的总边数；</li>
<li>(A<sub>ij</sub>) 是节点 (i) 和节点 (j) 之间的邻接矩阵；</li>
<li>(k<sub>i</sub>) 和 (k<sub>j</sub>) 分别是节点 (i) 和节点 (j) 的度；</li>
<li>(c<sub>i</sub>) 和 (c<sub>j</sub>) 表示节点的社区标签，((c<sub>i</sub>, c<sub>j</sub>)) 当 (c<sub>i</sub> = c<sub>j</sub>) 时为1，否则为0。</li>
</ul>
</li>
<li><p><strong>解释</strong>：模块度越高，说明网络中的社区划分越明显。社区内的节点彼此之间的联系紧密，而社区之间的联系较少。模块度是用于社区检测算法的常见评价指标。</p>
</li>
</ul>
<h4 id="3-k-core分析"><a href="#3-k-core分析" class="headerlink" title="3. k-core分析"></a>3. <strong>k-core分析</strong></h4><p>k-core 是网络中的一个子图，其中每个节点的度至少为 (k)。通过去除度小于 (k) 的节点，可以识别出网络中的“核心”结构。</p>
<ul>
<li><p><strong>定义</strong>：k-core 是由所有度不小于 (k) 的节点及其连接构成的最大子图。通过逐步剥离度小于 (k) 的节点，可以识别出不同层次的核心群体。</p>
</li>
<li><p><strong>解释</strong>：k-core 分析揭示了网络的层级结构，有助于识别网络中的核心节点和团体。这在社交网络、合作网络中尤其有用，用于找到最重要的群体或“精英”圈层。</p>
</li>
</ul>
<h4 id="4-团体系数（Clique-Coefficient）"><a href="#4-团体系数（Clique-Coefficient）" class="headerlink" title="4. 团体系数（Clique Coefficient）"></a>4. <strong>团体系数（Clique Coefficient）</strong></h4><p>团体系数是用来衡量网络中节点参与完全子图（团体，clique）的程度。在完全子图中，任意两个节点之间都相互连接。</p>
<ul>
<li><p><strong>定义</strong>：一个 (k)-团体是包含 (k) 个节点的完全子图，节点间两两相连。团体系数计算某个节点或整个网络中完全子图的数量或参与程度。</p>
</li>
<li><p><strong>应用</strong>：用于社交网络中识别密切合作的小组，或者在生物网络中找出功能模块。</p>
</li>
</ul>
<h4 id="5-嵌套度（Nestedness）"><a href="#5-嵌套度（Nestedness）" class="headerlink" title="5. 嵌套度（Nestedness）"></a>5. <strong>嵌套度（Nestedness）</strong></h4><p>嵌套度是指网络中不同群体的嵌套关系，特别是在双模式网络（如生态系统网络或互惠网络）中衡量节点子集间的包容关系。</p>
<ul>
<li><p><strong>定义</strong>：嵌套度高的网络表示某些子集的节点之间关系更加集中，较小的子集通常被包含在较大的子集中。</p>
</li>
<li><p><strong>应用</strong>：嵌套度在生态网络中广泛应用，用于衡量物种或互作组的层次结构及其稳定性。</p>
</li>
</ul>
<h4 id="6-凝聚性（Cohesiveness）"><a href="#6-凝聚性（Cohesiveness）" class="headerlink" title="6. 凝聚性（Cohesiveness）"></a>6. <strong>凝聚性（Cohesiveness）</strong></h4><p>凝聚性用于评估网络中群体之间的紧密程度。通常通过最大连通分量的大小、图的连通性或网络的最小割（cut）来衡量。</p>
<ul>
<li><p><strong>定义</strong>：凝聚性高的网络具有强连通性，节点之间更难分离。连通性差的网络则容易被分成孤立的小团体。</p>
</li>
<li><p><strong>应用</strong>：凝聚性指标可以用于评估社交网络的紧密性，或者在生物网络中衡量分子间的合作强度。</p>
</li>
</ul>
<h4 id="7-社团指数（Community-Index）"><a href="#7-社团指数（Community-Index）" class="headerlink" title="7. 社团指数（Community Index）"></a>7. <strong>社团指数（Community Index）</strong></h4><p>社团指数衡量网络中不同社团（社区、群体）的内外连接差异。社团指数较高的网络意味着群体内的节点连接密集，而群体间的连接较稀疏。</p>
<ul>
<li><strong>公式</strong>：不同的社团检测算法可以根据具体定义计算出社团指数，用于比较不同社团划分方案的质量。</li>
</ul>
<h4 id="总结-16"><a href="#总结-16" class="headerlink" title="总结"></a><strong>总结</strong></h4><p>聚集指标主要用于衡量网络中节点之间形成团体或社区的倾向性，帮助分析局部和全局的群体结构。它们在许多领域中有广泛应用，如社交网络分析、合作网络中的团队发现、生物网络中的功能模块识别等</p>
<h3 id="十五、超网络演化模型"><a href="#十五、超网络演化模型" class="headerlink" title="十五、超网络演化模型"></a>十五、<strong>超网络演化模型</strong></h3><p><strong>超网络演化模型</strong>（Hypernetwork Evolution Model）是复杂网络研究中一种重要的理论框架，旨在描述具有多元关系的系统如何随着时间演化。在超网络中，<strong>超边</strong>（Hyperedges）可以连接多个节点，而不仅仅是两两相连，适用于多方交互或复杂系统的建模，如社交网络中的群组对话、合作网络中的多方合作等。</p>
<p>超网络演化模型试图通过捕捉这些复杂多元交互的变化和规律，来解释和预测网络的演化行为。在超网络中，节点可以表示个体、实体，超边可以代表不同群体或交互场景，超边的动态变化是超网络演化的核心。</p>
<h4 id="1-超网络的基本概念"><a href="#1-超网络的基本概念" class="headerlink" title="1. 超网络的基本概念"></a>1. <strong>超网络的基本概念</strong></h4><p>在介绍演化模型之前，首先回顾超网络的一些基本概念：</p>
<ul>
<li><strong>节点（Nodes）</strong>：超网络中的基本单元，表示系统中的个体或实体。</li>
<li><strong>超边（Hyperedges）</strong>：不同于传统网络中连接两个节点的边，超边可以连接两个或多个节点，表示多方互动关系。</li>
<li><strong>度（Degree）</strong>：节点的度数可以表示为它参与的超边数量。在超网络中，节点的<strong>超度</strong>指的是它所参与的超边数量。</li>
<li><strong>超边的维度</strong>：每条超边可以连接多个节点，超边的维度表示该超边连接的节点数。</li>
</ul>
<p>超网络的复杂性主要体现在超边的多元性及其随时间的动态变化，因此在构建超网络演化模型时，需要考虑超边如何产生、增长、消失或演变。</p>
<h4 id="2-超网络演化模型的核心问题"><a href="#2-超网络演化模型的核心问题" class="headerlink" title="2. 超网络演化模型的核心问题"></a>2. <strong>超网络演化模型的核心问题</strong></h4><p>超网络的演化过程不仅涉及节点和超边数量的变化，还包括以下核心问题：</p>
<ul>
<li><strong>超边的生成机制</strong>：超边是如何随着时间生成的？是否有特定的规律或偏好？</li>
<li><strong>超边的演化模式</strong>：超边会如何增长或消亡？超边维度是否会随时间变化？</li>
<li><strong>节点的演化机制</strong>：节点如何加入或退出超网络？节点加入后如何选择参与哪些超边？</li>
<li><strong>社团结构演化</strong>：在超网络中，是否存在多节点的聚集结构，社团或群体如何形成和演化？</li>
</ul>
<h4 id="3-超网络演化模型的分类"><a href="#3-超网络演化模型的分类" class="headerlink" title="3. 超网络演化模型的分类"></a>3. <strong>超网络演化模型的分类</strong></h4><p>根据不同的模型假设和网络特征，超网络演化模型大致可以分为以下几类：</p>
<h5 id="（1）随机超网络演化模型"><a href="#（1）随机超网络演化模型" class="headerlink" title="（1）随机超网络演化模型"></a>（1）<strong>随机超网络演化模型</strong></h5><p>类似于经典的 Erdős–Rényi 随机图模型，随机超网络模型假设超边和节点的生成是随机的。</p>
<ul>
<li>在每个时间步，网络中可能随机添加新的节点和新的超边，超边的维度也是随机的。</li>
<li>这种模型较为简单，适合模拟无特定偏好的网络演化过程。</li>
</ul>
<h5 id="（2）优先连接超网络模型（Preferential-Attachment-in-Hypernetworks）"><a href="#（2）优先连接超网络模型（Preferential-Attachment-in-Hypernetworks）" class="headerlink" title="（2）优先连接超网络模型（Preferential Attachment in Hypernetworks）"></a>（2）<strong>优先连接超网络模型（Preferential Attachment in Hypernetworks）</strong></h5><p>这一类模型是超网络演化模型中较为常见的形式，灵感来自于 Barabási-Albert 模型中的“<strong>富者愈富</strong>”效应，适用于建模那些具有“强者越强”特征的系统：</p>
<ul>
<li>新加入的节点更有可能参与到已经参与节点多的超边中（即优先连接高超度的节点或超边）。</li>
<li>新超边的生成机制可以优先选择那些连接较多节点的节点形成新的超边，或扩展已有的超边。</li>
<li>这种优先连接机制导致超网络呈现<strong>无标度特性</strong>，即节点的度分布具有幂律分布。</li>
</ul>
<h5 id="（3）协同进化超网络模型（Co-evolution-Hypernetwork-Model）"><a href="#（3）协同进化超网络模型（Co-evolution-Hypernetwork-Model）" class="headerlink" title="（3）协同进化超网络模型（Co-evolution Hypernetwork Model）"></a>（3）<strong>协同进化超网络模型（Co-evolution Hypernetwork Model）</strong></h5><p>在这种模型中，节点和超边是协同演化的：</p>
<ul>
<li><strong>节点协同进化</strong>：节点间的交互依赖于它们的局部环境或状态。超边的产生和演化受到节点之间交互的影响。</li>
<li><strong>超边协同进化</strong>：超边内部的节点可以通过群体行为影响超边的存在、维度以及参与节点的变化。</li>
<li>这种模型常用于描述复杂的多方合作系统、生态系统等。</li>
</ul>
<h5 id="（4）动态分层超网络模型（Dynamic-Layered-Hypernetwork-Model）"><a href="#（4）动态分层超网络模型（Dynamic-Layered-Hypernetwork-Model）" class="headerlink" title="（4）动态分层超网络模型（Dynamic Layered Hypernetwork Model）"></a>（4）<strong>动态分层超网络模型（Dynamic Layered Hypernetwork Model）</strong></h5><p>分层超网络模型考虑了网络中节点与超边的层次结构：</p>
<ul>
<li>网络可以分为不同的层次（如组织、个体、关系等），每个层次可以定义自己的超边演化规则。</li>
<li>这种模型适合用于描述具有多层次结构的网络，如社交网络、生态系统网络等，其中不同层次之间的节点可能参与不同的超边。</li>
</ul>
<h5 id="（5）超边的融合与分裂模型（Merging-and-Splitting-of-Hyperedges）"><a href="#（5）超边的融合与分裂模型（Merging-and-Splitting-of-Hyperedges）" class="headerlink" title="（5）超边的融合与分裂模型（Merging and Splitting of Hyperedges）"></a>（5）<strong>超边的融合与分裂模型（Merging and Splitting of Hyperedges）</strong></h5><p>该模型关注的是超边的分裂与融合：</p>
<ul>
<li><strong>超边的融合</strong>：当多个超边中的节点有较强的相互联系时，这些超边可能会融合成一个新的、更大的超边。</li>
<li><strong>超边的分裂</strong>：一个超边可能由于内部节点的多样性而分裂为多个小超边。</li>
<li>这种演化方式在合作网络或群体决策过程中十分常见，例如一个项目团队可能会随着时间分成多个小组，或者多个团队合并成一个大团队。</li>
</ul>
<h5 id="（6）重叠社团的演化模型（Overlapping-Community-Evolution-in-Hypernetworks）"><a href="#（6）重叠社团的演化模型（Overlapping-Community-Evolution-in-Hypernetworks）" class="headerlink" title="（6）重叠社团的演化模型（Overlapping Community Evolution in Hypernetworks）"></a>（6）<strong>重叠社团的演化模型（Overlapping Community Evolution in Hypernetworks）</strong></h5><p>在许多实际网络中，节点和社团往往存在重叠，即节点可以同时属于多个超边或社团。重叠社团模型可以描述这种复杂的重叠现象：</p>
<ul>
<li>节点同时参与多个超边，且超边内部可能存在部分节点的交集。</li>
<li>超边的演化不仅考虑节点之间的连接强度，还要考虑不同超边之间的相互影响。</li>
</ul>
<h4 id="4-超网络演化的动力学机制"><a href="#4-超网络演化的动力学机制" class="headerlink" title="4. 超网络演化的动力学机制"></a>4. <strong>超网络演化的动力学机制</strong></h4><p>在超网络演化过程中，动力学机制是其发展的驱动力。典型的动力学机制包括：</p>
<ul>
<li><strong>局部规则</strong>：某个超边的变化可能仅由其局部的节点行为决定。比如，节点根据自己及邻居的状态决定是否加入或离开某个超边。</li>
<li><strong>全局驱动</strong>：网络演化过程可能受到外部全局事件的影响，比如社交网络中的热点事件会促使大量节点同时参与某个超边。</li>
<li><strong>随机波动</strong>：某些随机因素会影响超边的生成或消亡，如节点可能以一定的概率参与或退出某个超边。</li>
</ul>
<h4 id="5-超网络演化模型的应用"><a href="#5-超网络演化模型的应用" class="headerlink" title="5. 超网络演化模型的应用"></a>5. <strong>超网络演化模型的应用</strong></h4><p>超网络演化模型可以应用于多个领域，涵盖了许多复杂系统：</p>
<ul>
<li><strong>社交网络</strong>：在社交网络中，人们可能参与多个群聊或社区，超网络演化模型可以描述这些多方关系的演变。</li>
<li><strong>合作网络</strong>：如科研合作中，研究人员往往组成多个项目团队，超网络演化模型能够捕捉项目团队的组建、扩展和分裂过程。</li>
<li><strong>生物网络</strong>：在生物系统中，基因、蛋白质等往往参与多个生物过程，超网络可以描述这种多方相互作用的动态演化。</li>
</ul>
<h4 id="总结-17"><a href="#总结-17" class="headerlink" title="总结"></a>总结</h4><p><strong>超网络演化模型</strong>是复杂网络研究中的重要分支，能够描述和模拟多节点、多边交互的复杂系统。通过研究超边的生成、分裂、融合以及节点的动态行为，这些模型可以帮助我们理解复杂系统中的群体结构、协作模式和演化规律。</p>
<h3 id="十六、混合超网络模型"><a href="#十六、混合超网络模型" class="headerlink" title="十六、混合超网络模型"></a>十六、混合超网络模型</h3><p>“混合超网络模型”是复杂网络理论中的一种新型网络模型，主要用于描述多个不同类型的关系和交互同时存在的复杂系统。超网络的概念扩展了传统网络中的节点和边的定义，在超网络中，边可以连接多个节点，形成一个超边（hyperedge）。而“混合”超网络模型通常结合了不同类型的节点、边或层次结构，来描述复杂系统中多维、多类型的交互。</p>
<h4 id="关键特点"><a href="#关键特点" class="headerlink" title="关键特点"></a>关键特点</h4><ol>
<li><p><strong>超边（Hyperedges）</strong>：在传统网络中，边仅连接两个节点，而在超网络中，超边可以连接两个以上的节点。这种结构更灵活，适合描述多方参与的交互或关联关系，比如在社交网络中，群组讨论可以看作是多个成员的交互，而不是简单的两人对话。</p>
</li>
<li><p><strong>混合模型</strong>：混合超网络模型可以结合不同类型的超边或节点。例如，不同的子网络可以表示不同类型的关系（如社交关系、交易关系等），或者网络中的节点可以代表不同类型的实体（如人、机构、产品等），这些实体之间可能存在不同的交互模式。</p>
</li>
<li><p><strong>多层结构</strong>：许多混合超网络模型是多层网络（Multilayer Network）的扩展。每一层可以代表不同类型的交互，层与层之间可能有不同的耦合关系。这种模型特别适用于描述多维度的复杂系统，如生物网络、交通网络、金融网络等。</p>
</li>
<li><p><strong>动态性</strong>：混合超网络模型还可以捕捉到时间上的动态变化。网络的结构、超边的属性、节点的状态都可能随着时间变化，从而更准确地描述实际复杂系统的演变过程。</p>
</li>
</ol>
<h4 id="应用领域"><a href="#应用领域" class="headerlink" title="应用领域"></a>应用领域</h4><ol>
<li><p><strong>社会网络分析</strong>：通过混合超网络模型，可以更好地分析复杂的社交结构，考虑到个人参与的多种群体和互动关系，而不只是简单的双边关系。</p>
</li>
<li><p><strong>生物网络</strong>：在基因-蛋白质相互作用中，混合超网络模型可以描述基因与蛋白质之间的复杂多方相互作用。</p>
</li>
<li><p><strong>多重交通网络</strong>：可以用混合超网络模型来描述城市交通系统，考虑不同类型的交通工具（如公共汽车、地铁、自行车等）之间的相互关系和切换模式。</p>
</li>
<li><p><strong>经济与金融网络</strong>：在复杂的市场和供应链网络中，多个参与者和多种交易形式可以通过这种模型来表达和分析其复杂关系。</p>
</li>
</ol>
<h4 id="研究挑战"><a href="#研究挑战" class="headerlink" title="研究挑战"></a>研究挑战</h4><ol>
<li><strong>建模复杂性</strong>：由于混合超网络模型同时处理多种不同类型的关系，建模过程可能比传统的网络模型更加复杂。</li>
<li><strong>计算难度</strong>：超边和多层结构增加了计算复杂度，如何高效地分析和模拟这种网络是一个挑战。</li>
<li><strong>数据可用性</strong>：需要准确且多维度的数据源，才能建立可靠的混合超网络模型。</li>
</ol>
<p>总的来说，混合超网络模型提供了一种灵活的工具，用于刻画现实世界中多层次、多类型的复杂系统交互。</p>
<h3 id="十七、品牌效应与适应度共演的超网络模型"><a href="#十七、品牌效应与适应度共演的超网络模型" class="headerlink" title="十七、品牌效应与适应度共演的超网络模型"></a>十七、品牌效应与适应度共演的超网络模型</h3><p>“品牌效应与适应度共演的超网络模型”是复杂网络理论在经济学和市场学中的一种应用，旨在模拟和分析品牌效应如何与市场中个体（消费者或企业）的适应度相互影响和共同进化。这个模型的核心思想是品牌在市场中的影响力（品牌效应）与个体的适应能力（适应度）如何通过复杂的网络结构相互作用，并共同塑造市场的演变过程。</p>
<h4 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h4><ol>
<li><p><strong>品牌效应</strong>：</p>
<ul>
<li><strong>品牌影响力</strong>：品牌在消费者决策中的影响程度，知名品牌可能会因为长期的声誉积累、市场营销策略、消费者信任等原因对市场有更大的影响力。</li>
<li><strong>品牌偏好</strong>：消费者对于特定品牌的偏好，这种偏好可以在消费者的选择行为中得到反映。品牌效应往往通过网络传播，影响消费者的决策和行为。</li>
</ul>
</li>
<li><p><strong>适应度（Fitness）</strong>：</p>
<ul>
<li>在超网络模型中，适应度指的是个体或节点（如消费者或企业）在特定环境中的竞争力和生存能力。适应度可以受到市场环境、技术变化、品牌竞争力等因素的影响。</li>
<li>随着时间的推移，适应度不是固定的，而是会根据与品牌的相互作用和市场环境的变化动态调整。</li>
</ul>
</li>
<li><p><strong>超网络模型</strong>：</p>
<ul>
<li>这是指一种比传统网络模型更复杂的结构，超网络允许多方节点同时关联，并在多个层次上捕捉不同类型的互动。在品牌效应与适应度共演的背景下，可以通过多层网络结构来描述消费者与品牌之间的多维互动。</li>
<li>例如，品牌可能通过广告、社交网络或产品质量影响消费者，消费者也可以通过口碑、购买决策和反馈影响品牌的声誉和市场表现。</li>
</ul>
</li>
<li><p><strong>共演（Co-evolution）</strong>：</p>
<ul>
<li>在模型中，“共演”指的是品牌效应和消费者适应度如何随着时间相互影响和共同进化。品牌通过不断优化其产品、营销策略来增强其效应，而消费者也在不断调整其品牌偏好和购买决策，以适应市场中的变化。</li>
</ul>
</li>
</ol>
<p>模型机制</p>
<ol>
<li><p><strong>品牌与消费者的双向互动</strong>：</p>
<ul>
<li>品牌通过广告、市场推广、产品口碑等方式影响消费者的偏好和选择。</li>
<li>消费者通过购买行为、社交网络中的评论反馈，反过来影响品牌在市场中的表现和适应度。</li>
</ul>
</li>
<li><p><strong>品牌效应传播</strong>：</p>
<ul>
<li>超网络模型可以用于模拟品牌效应如何通过社交网络传播。一些高适应度的消费者可能会通过他们的购买行为影响其他消费者，导致品牌效应进一步增强。</li>
</ul>
</li>
<li><p><strong>适应度动态演化</strong>：</p>
<ul>
<li>消费者的适应度会受到多个因素的影响，包括品牌效应、个人偏好、市场价格等。品牌也在竞争中不断优化其策略以提升适应度，如调整价格、提高产品质量等。</li>
</ul>
</li>
<li><p><strong>多层超网络</strong>：</p>
<ul>
<li>该模型可能包括多个层次，如消费者-品牌互动层、消费者之间的社交网络层、品牌之间的竞争层。这些层次彼此之间存在耦合关系，共同影响整体系统的演化。</li>
</ul>
</li>
</ol>
<h4 id="应用领域-1"><a href="#应用领域-1" class="headerlink" title="应用领域"></a>应用领域</h4><ol>
<li><p><strong>市场营销</strong>：</p>
<ul>
<li>可以用该模型来分析品牌效应对消费者行为的影响，帮助企业制定更有效的品牌推广策略。</li>
<li>研究不同市场条件下品牌的适应性，以及如何通过品牌传播策略提升市场份额。</li>
</ul>
</li>
<li><p><strong>消费者行为研究</strong>：</p>
<ul>
<li>模拟消费者在不同品牌和市场环境中的适应行为，探索消费者的品牌选择如何受到市场条件、社交网络影响。</li>
</ul>
</li>
<li><p><strong>竞争分析</strong>：</p>
<ul>
<li>可以分析多个品牌之间的共演过程，研究如何在竞争激烈的市场中，品牌通过适应度和效应的相互作用生存和发展。</li>
</ul>
</li>
<li><p><strong>经济学与创新扩散</strong>：</p>
<ul>
<li>模型也可以应用于经济学，模拟创新产品（品牌）的扩散和消费者接受度的演化，分析市场中创新品牌的成长和传统品牌的竞争动态。</li>
</ul>
</li>
</ol>
<h4 id="研究挑战-1"><a href="#研究挑战-1" class="headerlink" title="研究挑战"></a>研究挑战</h4><ol>
<li><p><strong>复杂性和数据需求</strong>：由于该模型涉及多个层次的动态互动，所需的数据量可能较大，且难以收集和建模。</p>
</li>
<li><p><strong>共演过程的非线性</strong>：品牌效应与适应度之间的互动常常是非线性和动态的，因此对模型的分析和预测提出了挑战。</p>
</li>
<li><p><strong>参数选择与调控</strong>：模型中的参数（如品牌影响力、适应度更新规则等）对于模拟结果的影响很大，如何合理选择和优化这些参数也是一个研究难点。</p>
</li>
</ol>
<h4 id="总结-18"><a href="#总结-18" class="headerlink" title="总结"></a>总结</h4><p>品牌效应与适应度共演的超网络模型为研究市场和消费者行为提供了一种新的视角。通过这种模型，可以更全面地理解品牌和消费者之间的复杂互动关系，以及这种关系如何在市场中共同演化，进而为品牌策略和市场决策提供理论支持。</p>
<h3 id="十八、带有钝化和激活机制的超网络模型"><a href="#十八、带有钝化和激活机制的超网络模型" class="headerlink" title="十八、带有钝化和激活机制的超网络模型"></a>十八、带有钝化和激活机制的超网络模型</h3><p>“带有钝化和激活机制的超网络模型”是一种复杂网络模型，主要用于描述系统中节点和边的状态如何在不同机制的作用下进行动态演化。钝化和激活机制可以理解为网络中节点或边的两种相反状态或行为，它们可以代表抑制与促进的动态相互作用。这种模型常用于研究复杂系统中的动力学过程，例如社会网络中的信息传播、生物系统中的基因表达调控、以及金融市场中的风险扩散等。</p>
<h4 id="关键概念-1"><a href="#关键概念-1" class="headerlink" title="关键概念"></a>关键概念</h4><ol>
<li><p><strong>超网络模型</strong>：</p>
<ul>
<li>超网络是一种扩展的网络结构，超边可以连接多个节点，形成一个多节点关联的整体，而不是传统网络中两个节点之间的简单连接。这种结构特别适合描述具有多方互动的系统，如团队合作中的多方参与、社会群体中的群体行为、基因调控中的多基因关联等。</li>
</ul>
</li>
<li><p><strong>钝化机制（Passivation Mechanism）</strong>：</p>
<ul>
<li>钝化机制指的是网络中的某些节点或边在一定条件下被抑制或减弱其功能。例如，在社会网络中，某些用户可能由于疲劳、信息饱和或个人偏好而停止参与信息传播；在生物网络中，某些基因可能由于环境变化而失去表达活性。</li>
<li>钝化机制可以通过时间、外部环境、资源耗尽或内在规则等多种方式触发，导致系统中的一部分节点或边停止发挥作用。</li>
</ul>
</li>
<li><p><strong>激活机制（Activation Mechanism）</strong>：</p>
<ul>
<li>激活机制与钝化机制相反，指的是原本不活跃的节点或边在一定条件下被激发，重新参与到系统的动态中。例如，在社交网络中，某个长期不活跃的用户突然参与热点话题；在生物网络中，特定环境刺激可能会激活某些原本沉默的基因。</li>
<li>激活机制通常是外部刺激（如新信息的注入、环境变化）或系统内某些阈值被触发时产生的。</li>
</ul>
</li>
<li><p><strong>共演机制（Co-evolution Mechanism）</strong>：</p>
<ul>
<li>钝化与激活机制通常在一个动态的超网络中共同演化。即某些节点或边在一定时间范围内可能经历多次钝化与激活的过程，系统的整体动态也因此不断变化。共演机制是研究系统整体行为变化的关键。</li>
</ul>
</li>
</ol>
<h3 id="模型机制"><a href="#模型机制" class="headerlink" title="模型机制"></a>模型机制</h3><ol>
<li><p><strong>钝化和激活的规则</strong>：</p>
<ul>
<li>系统中钝化和激活可以由阈值、随机机制或外部干预触发。例如，某节点的钝化可能由其相邻节点的活跃度下降引发；激活可能由系统外部输入的某种“刺激”所引发。</li>
<li>钝化和激活过程之间可以存在竞争或合作。例如，激活的节点可能会促进相邻节点的进一步激活，或是抑制某些钝化节点恢复活跃。</li>
</ul>
</li>
<li><p><strong>超边的动态变化</strong>：</p>
<ul>
<li>在超网络模型中，超边（连接多个节点的结构）不仅可以受到单个节点的钝化和激活影响，还可以表现为群体行为的变化。例如，团队中的一个核心成员可能被钝化，导致整个团队的互动能力下降；反之，激活一个节点可能会增强群体的协作能力。</li>
</ul>
</li>
<li><p><strong>多层次网络的耦合</strong>：</p>
<ul>
<li>该模型可以扩展为多层网络，其中不同层次可能具有不同的钝化与激活机制。例如，在社交媒体网络中，信息传播层可能会出现钝化机制（用户不再分享信息），而在影响力层中可能会有激活机制（某个新话题提升了用户的参与度）。这些层次之间的相互作用会进一步复杂化网络动态。</li>
</ul>
</li>
<li><p><strong>时间演化过程</strong>：</p>
<ul>
<li>钝化与激活的动态演化往往是随时间变化的。系统可能从初始的高度活跃状态逐渐钝化，随着某些外部干预又重新激活。时间序列分析是研究该类系统演化的重要方法之一。</li>
</ul>
</li>
</ol>
<h4 id="应用领域-2"><a href="#应用领域-2" class="headerlink" title="应用领域"></a>应用领域</h4><ol>
<li><p><strong>社交网络中的信息扩散</strong>：</p>
<ul>
<li>钝化机制可以用于描述信息饱和或用户对某些内容的冷淡反应，激活机制则模拟突发性热点事件如何重新引发用户的兴趣。例如，用户可能因为某些社交媒体的过度使用而钝化，但热点新闻或娱乐事件可以激发他们重新参与互动。</li>
</ul>
</li>
<li><p><strong>生物网络中的基因调控</strong>：</p>
<ul>
<li>在基因调控网络中，钝化机制可以描述基因表达的沉默状态，激活机制则对应于基因在特定条件下的重新表达。该模型能够模拟基因表达如何随环境刺激动态变化，以及基因间如何通过超边相互调控。</li>
</ul>
</li>
<li><p><strong>金融市场中的风险扩散</strong>：</p>
<ul>
<li>钝化与激活机制可以用于模拟金融市场中的投资者行为。投资者在市场波动中可能由于风险厌恶而钝化，而市场出现新的机遇时可能会被重新激活，参与到投资行为中。这种动态演化能够帮助解释市场的非线性波动和突发性风险传播。</li>
</ul>
</li>
<li><p><strong>生态系统中的物种互动</strong>：</p>
<ul>
<li>生态系统中的物种可能因为资源不足、环境变化等原因钝化（如休眠或减少活动），但在适宜的条件下（如季节变化或生态恢复）重新激活参与生态互动。这种动态过程可以通过带有钝化和激活机制的超网络模型进行描述。</li>
</ul>
</li>
</ol>
<h4 id="研究挑战-2"><a href="#研究挑战-2" class="headerlink" title="研究挑战"></a>研究挑战</h4><ol>
<li><p><strong>模型复杂性</strong>：</p>
<ul>
<li>超网络模型本身已经包含了复杂的节点、超边和多层互动，钝化和激活机制的引入使得模型的动态演化更加复杂，尤其是在大规模系统中，如何有效地模拟和分析这些复杂的动态过程是一个挑战。</li>
</ul>
</li>
<li><p><strong>参数选择与调控</strong>：</p>
<ul>
<li>钝化和激活的触发条件、演化规则等参数对模型的影响非常显著，如何合理选择这些参数是研究中的一个关键问题。</li>
</ul>
</li>
<li><p><strong>数据需求与验证</strong>：</p>
<ul>
<li>这种模型通常需要大量高质量的数据进行验证，如社交网络的用户行为数据、生物网络中的基因表达数据等。如何获取和处理这些数据，并将模型与现实世界现象进行对比验证，是另一个挑战。</li>
</ul>
</li>
</ol>
<h4 id="总结-19"><a href="#总结-19" class="headerlink" title="总结"></a>总结</h4><p>带有钝化和激活机制的超网络模型为研究复杂系统中的动态演化过程提供了一个强有力的工具。通过这种模型，研究者可以模拟系统中的节点和边如何在不同机制下进行状态转换，进而揭示整个系统的动力学特性。这在社交网络、基因调控、生物生态系统、金融市场等多个领域有广泛的应用前景。</p>
<h3 id="十九、非广延统计方法"><a href="#十九、非广延统计方法" class="headerlink" title="十九、非广延统计方法"></a>十九、非广延统计方法</h3><p><strong>非广延统计方法</strong>（Non-extensive Statistical Mechanics）是一种扩展经典统计力学的理论框架，最著名的是基于 <strong>Tsallis 统计力学</strong>。它旨在处理经典广延统计力学（如玻尔兹曼-吉布斯统计力学）无法很好描述的复杂系统。传统的统计力学假设系统是“广延的”，即系统的总能量、熵等物理量都随着系统大小成比例增加。然而，许多实际系统不满足这一假设，尤其是复杂系统，如湍流、等离子体、天体物理系统、经济系统、社会网络等。这些系统中往往存在长程相互作用、非平衡态、多尺度相互作用等现象，需要用非广延统计方法来描述。</p>
<h4 id="关键概念-2"><a href="#关键概念-2" class="headerlink" title="关键概念"></a>关键概念</h4><ol>
<li><h5 id="广延性与非广延性："><a href="#广延性与非广延性：" class="headerlink" title="广延性与非广延性："></a><strong>广延性与非广延性</strong>：</h5><ul>
<li><strong>广延性</strong>：系统的性质（如能量、熵）可以线性叠加，例如如果将两个系统合并，总的熵等于两者的熵之和。玻尔兹曼-吉布斯统计力学正是基于广延性假设，适用于短程相互作用和处于平衡态的系统。</li>
<li><strong>非广延性</strong>：系统的性质不再是线性叠加的，可能表现为某种相互作用的耦合效应。许多复杂系统具有长程相互作用、强关联性、以及非平衡态，因此需要采用非广延统计的方法来描述。</li>
</ul>
</li>
<li><h5 id="Tsallis-熵与非广延统计："><a href="#Tsallis-熵与非广延统计：" class="headerlink" title="Tsallis 熵与非广延统计："></a><strong>Tsallis 熵与非广延统计</strong>：</h5><ul>
<li><strong>Tsallis 熵</strong>是非广延统计力学的核心概念之一，由巴西物理学家 Constantino Tsallis 于1988年提出。它通过引入一个新的参数 (q)，扩展了传统的玻尔兹曼-吉布斯熵公式。</li>
</ul>
<p>Tsallis 熵的定义为：<br><img src="./images/efigure25.png" alt=""><br>其中，(p_i) 是第 (i) 个微观状态的概率，(q) 是 Tsallis 熵的非广延参数，当 (q = 1) 时，Tsallis 熵恢复为传统的玻尔兹曼-吉布斯熵。</p>
</li>
<li><h5 id="非广延参数-q-："><a href="#非广延参数-q-：" class="headerlink" title="非广延参数 (q)："></a><strong>非广延参数 (q)</strong>：</h5><ul>
<li><strong>(q)</strong> 是非广延统计中关键的调控参数，它表征了系统中不同的相互作用特性：<ul>
<li>当 (q = 1)，系统符合广延统计力学，可以用玻尔兹曼-吉布斯统计来描述。</li>
<li>当 (q \neq 1)，系统表现出非广延性，适用于复杂系统中的长程相互作用、分形结构、自相似性等。</li>
</ul>
</li>
</ul>
</li>
<li><h5 id="非平衡态和长程相互作用："><a href="#非平衡态和长程相互作用：" class="headerlink" title="非平衡态和长程相互作用："></a><strong>非平衡态和长程相互作用</strong>：</h5><ul>
<li>非广延统计力学特别适用于非平衡态系统和具有长程相互作用的系统。在这些系统中，经典的玻尔兹曼-吉布斯理论通常无法很好地描述其动力学性质。</li>
<li>例如，在具有长程相互作用的系统中，一个粒子与远距离粒子的相互作用不能忽略，因此系统的行为不能简单地用局部相互作用的广延性来描述。</li>
</ul>
</li>
</ol>
<h4 id="应用领域-3"><a href="#应用领域-3" class="headerlink" title="应用领域"></a>应用领域</h4><ol>
<li><h5 id="物理学中的复杂系统："><a href="#物理学中的复杂系统：" class="headerlink" title="物理学中的复杂系统："></a><strong>物理学中的复杂系统</strong>：</h5><ul>
<li><strong>等离子体物理</strong>：等离子体中的带电粒子间存在长程库仑相互作用，经典统计力学往往不能充分描述其动力学行为。非广延统计方法为描述等离子体系统中的热力学性质提供了新的思路。</li>
<li><strong>湍流</strong>：在湍流中，不同尺度的涡旋相互作用复杂，传统统计力学无法很好地描述其多尺度行为，而 Tsallis 统计可以捕捉其中的长程相互作用和自相似性。</li>
<li><strong>引力系统</strong>：天体物理中的引力相互作用是长程的，像星团、引力波的行为常常需要用非广延统计来处理。</li>
</ul>
</li>
<li><h5 id="生物物理与生态系统："><a href="#生物物理与生态系统：" class="headerlink" title="生物物理与生态系统："></a><strong>生物物理与生态系统</strong>：</h5><ul>
<li>生物网络和生态系统中的相互作用网络可能具有复杂的拓扑结构和长程依赖，非广延统计可以帮助理解这些系统的多尺度行为和集体动力学特性。</li>
</ul>
</li>
<li><h5 id="经济与金融系统："><a href="#经济与金融系统：" class="headerlink" title="经济与金融系统："></a><strong>经济与金融系统</strong>：</h5><ul>
<li>经济系统中的市场波动、金融风险、财富分配等现象经常表现出不均匀性、分形特性和长程相互作用，这些特征使得传统的统计方法难以适用。非广延统计力学可以用于描述金融市场中的涨落、价格变化和复杂的风险传播机制。</li>
</ul>
</li>
<li><h5 id="信息理论与社交网络："><a href="#信息理论与社交网络：" class="headerlink" title="信息理论与社交网络："></a><strong>信息理论与社交网络</strong>：</h5><ul>
<li>非广延统计方法还可以应用于信息传播和社交网络中。社交网络的节点（个体）之间往往存在复杂的交互模式，某些热点事件可能会引发大范围的连锁反应（激活效应），这些现象可用 Tsallis 熵等非广延统计工具来分析。</li>
</ul>
</li>
<li><h5 id="其他应用："><a href="#其他应用：" class="headerlink" title="其他应用："></a><strong>其他应用</strong>：</h5><ul>
<li><strong>交通流网络</strong>：城市交通流量的分布和变化具有复杂的相互作用和非线性特性，非广延统计方法能够更好地捕捉其中的集体动力学行为。</li>
<li><strong>分形系统</strong>：许多自然系统和现象展现出分形特性，如地震、地质结构等，这些都可以通过非广延统计工具进行建模和分析。</li>
</ul>
</li>
</ol>
<h4 id="研究挑战-3"><a href="#研究挑战-3" class="headerlink" title="研究挑战"></a>研究挑战</h4><ol>
<li><p><strong>理论验证与推广</strong>：尽管非广延统计力学已经成功应用于许多复杂系统的建模中，但它并未完全替代经典的玻尔兹曼-吉布斯理论。如何验证和推广该理论是一个重要的研究课题。</p>
</li>
<li><p><strong>参数 (q) 的物理意义</strong>：在非广延统计方法中，参数 (q) 的选择对结果影响很大，如何确定 (q) 的最佳值并理解其物理意义，仍然是研究中的重要问题。</p>
</li>
<li><p><strong>应用的复杂性</strong>：由于非广延统计力学常用于长程相互作用和非平衡态系统，因此实际的计算和建模较为复杂，如何在大规模系统中有效应用也是一个挑战。</p>
</li>
</ol>
<h4 id="总结-20"><a href="#总结-20" class="headerlink" title="总结"></a>总结</h4><p><strong>非广延统计方法</strong>通过引入 Tsallis 熵等工具，扩展了传统的玻尔兹曼-吉布斯统计力学，尤其适用于处理复杂系统中的非平衡态、长程相互作用和多尺度行为。该方法已经在物理学、生物学、经济学等领域显示出广泛的应用前景，但仍需进一步的理论发展和验证。</p>
<h2 id="相关理论基础"><a href="#相关理论基础" class="headerlink" title="相关理论基础"></a>相关理论基础</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2024/09/23/python%E7%9A%84networkx%E5%BA%93/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/23/python%E7%9A%84networkx%E5%BA%93/" class="post-title-link" itemprop="url">python的networkx库</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-23 20:39:18" itemprop="dateCreated datePublished" datetime="2024-09-23T20:39:18+08:00">2024-09-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-11-20 09:10:49" itemprop="dateModified" datetime="2024-11-20T09:10:49+08:00">2024-11-20</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="复杂网络基本性质"><a href="#复杂网络基本性质" class="headerlink" title="复杂网络基本性质"></a>复杂网络基本性质</h1><h2 id="度、平均度以及度分布"><a href="#度、平均度以及度分布" class="headerlink" title="度、平均度以及度分布"></a>度、平均度以及度分布</h2><h3 id="1-度（Degree）"><a href="#1-度（Degree）" class="headerlink" title="1. 度（Degree）"></a>1. <strong>度（Degree）</strong></h3><p><strong>度</strong>是一个节点的连接数，表示该节点与其他节点之间的边的数量。</p>
<h4 id="公式："><a href="#公式：" class="headerlink" title="公式："></a>公式：</h4><p><img src="images/efigure001.png" alt="img"></p>
<p>对于有向图，每个节点有两个度：</p>
<ul>
<li><strong>入度（In-degree）</strong>：其他节点指向该节点的边的数量。</li>
<li><strong>出度（Out-degree）</strong>：该节点指向其他节点的边的数量。</li>
</ul>
<h4 id="解释："><a href="#解释：" class="headerlink" title="解释："></a>解释：</h4><ul>
<li>度表示每个节点的“活跃度”或“连接性”，反映了它在网络中的重要性。</li>
<li>节点度越高，说明它与其他节点的连接越多，可能起到关键的传输或枢纽作用。</li>
</ul>
<h3 id="2-平均度（Average-Degree）"><a href="#2-平均度（Average-Degree）" class="headerlink" title="2. 平均度（Average Degree）"></a>2. <strong>平均度（Average Degree）</strong></h3><p><strong>平均度</strong>（⟨k⟩）是网络中所有节点度的平均值，用于描述网络的整体连接性。</p>
<p><img src="images/efigure002.png" alt="img"></p>
<h4 id="解释：-1"><a href="#解释：-1" class="headerlink" title="解释："></a>解释：</h4><ul>
<li>平均度提供了网络中每个节点平均连接多少个其他节点的一个概况。</li>
<li>网络的连通性可以通过平均度来衡量。较大的平均度意味着网络较为紧密，节点之间的连接较多；较小的平均度则表明网络较稀疏。</li>
</ul>
<h3 id="3-度分布（Degree-Distribution）"><a href="#3-度分布（Degree-Distribution）" class="headerlink" title="3. 度分布（Degree Distribution）"></a>3. <strong>度分布（Degree Distribution）</strong></h3><p><strong>度分布</strong>描述了网络中节点度的分布情况，表示随机选择一个节点，其度数为 k 的概率 P(k)。</p>
<ul>
<li><img src="images/efigure003.png" alt=""></li>
</ul>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ul>
<li><strong>度</strong>是描述单个节点在网络中连接数量的指标。</li>
<li><strong>平均度</strong>是网络中节点连接数的平均值，反映网络整体的连通性。</li>
<li><strong>度分布</strong>提供了节点度在整个网络中的分布情况，是理解网络结构特性的重要指标。通过度分布，我们可以进一步分析网络是否具有稀疏、集中的特征，或者是否存在具有极高连接度的关键节点。</li>
</ul>
<h1 id="聚集系数"><a href="#聚集系数" class="headerlink" title="聚集系数"></a>聚集系数</h1><h2 id="聚集系数用来捕获给定节点的邻居节点之间的连接程度。"><a href="#聚集系数用来捕获给定节点的邻居节点之间的连接程度。" class="headerlink" title="聚集系数用来捕获给定节点的邻居节点之间的连接程度。"></a>聚集系数用来捕获给定节点的邻居节点之间的连接程度。</h2><p>对于一个度为ki的节点i，局部集聚系数定义为</p>
<p><img src="./images/efigure02.png" alt="img"></p>
<h2 id="全局集聚系数"><a href="#全局集聚系数" class="headerlink" title="全局集聚系数"></a>全局集聚系数</h2><p>全局聚集系数（Global Clustering Coefficient）也称为<strong>网络的三角形系数</strong>，是复杂网络中度量节点之间形成三角形闭合连接的比例。它的计算方式是基于<strong>已闭合三元组</strong>与<strong>所有可能的三元组</strong>的比例。</p>
<ul>
<li><strong>三元组</strong>：指由一个节点及其两个邻居构成的连接关系，分为<strong>开三元组</strong>（没有形成三角形）和<strong>闭三元组</strong>（形成三角形）。</li>
<li><strong>全局聚集系数公式</strong>：<img src="images/figure005.png" alt=""></li>
<li>三角形的数量 这里，三元组的数量包括所有可能的三元组，而三角形数量表示实际存在的三角形。</li>
</ul>
<h3 id="特点："><a href="#特点：" class="headerlink" title="特点："></a>特点：</h3><ul>
<li><strong>较高的全局聚集系数</strong>：说明网络具有较强的<strong>团体性</strong>，邻居节点之间更倾向于相互连接，常见于社交网络。</li>
<li><strong>较低的全局聚集系数</strong>：表示网络的节点连接较为松散，节点的邻居之间不太倾向于相互连接。</li>
</ul>
<h1 id="无向图"><a href="#无向图" class="headerlink" title="无向图"></a>无向图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G = nx.Graph()</span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"><span class="comment">#添加边</span></span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">4</span>)])</span><br><span class="line"><span class="comment">#可视化</span></span><br><span class="line">nx.draw(G, with_labels=<span class="literal">True</span>)</span><br><span class="line"><span class="comment">#保存图片地址</span></span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取图的邻接矩阵</span></span><br><span class="line">As = nx.adjacency_matrix(G)</span><br><span class="line"><span class="built_in">print</span>(As)</span><br><span class="line"></span><br><span class="line"><span class="comment">#转化为二维的矩阵</span></span><br><span class="line">A= As.todense()</span><br><span class="line"><span class="built_in">print</span>(A)</span><br></pre></td></tr></table></figure>
<p>如下图：<img src="./images/figure.png" style="zoom:33%;" /></p>
<p>输出为：<img src="./images/01input.png" alt="01input"  /></p>
<h1 id="根据邻接矩阵创建图"><a href="#根据邻接矩阵创建图" class="headerlink" title="根据邻接矩阵创建图"></a>根据邻接矩阵创建图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment">#已知邻接矩阵创建图</span></span><br><span class="line">A = np.array([[<span class="number">0</span>,<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>]])</span><br><span class="line">T = nx.from_numpy_array(A)</span><br><span class="line">nx.draw(T, with_labels=<span class="literal">True</span>)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure02.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如图<img src="images/figure02.png" style="zoom:33%;" /></p>
<h1 id="加权图"><a href="#加权图" class="headerlink" title="加权图"></a>加权图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G=nx.Graph()</span><br><span class="line">G.add_weighted_edges_from([(<span class="number">0</span>,<span class="number">1</span>,<span class="number">3.0</span>),(<span class="number">1</span>,<span class="number">2</span>,<span class="number">7.5</span>),(<span class="number">0</span>,<span class="number">2</span>,<span class="number">1.5</span>)])</span><br><span class="line">As = nx.adjacency_matrix(G)</span><br><span class="line"><span class="built_in">print</span>(As.todense())</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure03.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如图<img src="images/figure03.png" style="zoom:33%;" /></p>
<p>输入结果如图<img src="images/03input.png" alt=""></p>
<h1 id="有向图"><a href="#有向图" class="headerlink" title="有向图"></a>有向图</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G=nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加边</span></span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">3</span>,<span class="number">4</span>)])</span><br><span class="line">nx.draw(G)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure04.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如图：<img src="images/figure04.png" style="zoom:33%;" /></p>
<h1 id="获取网络图G的度"><a href="#获取网络图G的度" class="headerlink" title="获取网络图G的度"></a>获取网络图G的度</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line">G=nx.Graph()</span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加边</span></span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">4</span>)])</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取网络G的度</span></span><br><span class="line">d = nx.degree(G)</span><br><span class="line"><span class="built_in">print</span>(d)</span><br><span class="line"></span><br><span class="line"><span class="comment">#平均度</span></span><br><span class="line">d2 = <span class="built_in">dict</span>(nx.degree(G))</span><br><span class="line"><span class="built_in">print</span>(d2)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;平均度为：&quot;</span>,<span class="built_in">sum</span>(d2.values())/<span class="built_in">len</span>(G.nodes))</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取分布情况</span></span><br><span class="line">degree_counts = nx.degree_histogram(G)<span class="comment">#返回所有位于区间[0,dmax]的度的值</span></span><br><span class="line"><span class="built_in">print</span>(degree_counts)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>结果如图：<img src="./images/05input.png" alt="05input" style="zoom:67%;" /></p>
<h1 id="直方图绘制"><a href="#直方图绘制" class="headerlink" title="直方图绘制"></a>直方图绘制</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line">G=nx.Graph()</span><br><span class="line"><span class="comment">#添加节点</span></span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#添加边</span></span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">4</span>)])</span><br><span class="line"></span><br><span class="line">d = <span class="built_in">dict</span>(nx.degree(G))</span><br><span class="line"></span><br><span class="line">x = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">max</span>(d.values()) + <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">y = [i/<span class="built_in">len</span>(G.nodes()) <span class="keyword">for</span> i <span class="keyword">in</span> nx.degree_histogram(G)]</span><br><span class="line"></span><br><span class="line">plt.bar(x,y)</span><br><span class="line"></span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.ylabel(<span class="string">&quot;$p_k$&quot;</span>)</span><br><span class="line">plt.xlim([<span class="number">0</span>,<span class="number">4</span>])</span><br><span class="line">bar_path = <span class="string">&#x27;E:/MyBlog/source/images/figure05.png&#x27;</span></span><br><span class="line">plt.savefig(bar_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>结果如图：<img src="images/figure05.png" style="zoom:33%;" /></p>
<h1 id="路径与平均路径长度"><a href="#路径与平均路径长度" class="headerlink" title="路径与平均路径长度"></a>路径与平均路径长度</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G =nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">5</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">4</span>,<span class="number">5</span>)])</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure06.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure06.png" style="zoom:33%;" /></p>
<h2 id="最短路径"><a href="#最短路径" class="headerlink" title="最短路径"></a>最短路径</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获取节点1~4的最短路径</span></span><br><span class="line"><span class="built_in">list</span> = nx.shortest_path(G,source = <span class="number">1</span>, target = <span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">list</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果为：[1, 2, 3, 4]</p>
<h2 id="两个节点之间的所有最短路径"><a href="#两个节点之间的所有最短路径" class="headerlink" title="两个节点之间的所有最短路径"></a>两个节点之间的所有最短路径</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">list2 = <span class="built_in">list</span>(nx.all_shortest_paths(G, source = <span class="number">1</span>, target = <span class="number">4</span>))</span><br><span class="line"><span class="built_in">print</span>(list2)</span><br></pre></td></tr></table></figure>
<p>运行结果：[[1, 2, 3, 4], [1, 2, 5, 4]]</p>
<h2 id="求两个节点的最短路径的长度"><a href="#求两个节点的最短路径的长度" class="headerlink" title="求两个节点的最短路径的长度"></a>求两个节点的最短路径的长度</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#求这两个节点的最短路径长度（距离）</span></span><br><span class="line"><span class="built_in">len</span> = nx.shortest_path_length(G, source=<span class="number">1</span>, target=<span class="number">4</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>)</span><br></pre></td></tr></table></figure>
<p>运行结果：3</p>
<h2 id="求整个网络的平均距离"><a href="#求整个网络的平均距离" class="headerlink" title="求整个网络的平均距离"></a>求整个网络的平均距离</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#求整个网络的平均距离</span></span><br><span class="line">av_len = nx.average_shortest_path_length(G)</span><br><span class="line"><span class="built_in">print</span>(av_len)</span><br></pre></td></tr></table></figure>
<p>运行结果为：1.6</p>
<h1 id="连通性"><a href="#连通性" class="headerlink" title="连通性"></a>连通性</h1><h2 id="非连通图判断连通性"><a href="#非连通图判断连通性" class="headerlink" title="非连通图判断连通性"></a>非连通图判断连通性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G=nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>])</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">4</span>,<span class="number">7</span>),(<span class="number">5</span>,<span class="number">6</span>),(<span class="number">5</span>,<span class="number">7</span>),(<span class="number">6</span>,<span class="number">7</span>)])</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure07.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#联通图判断</span></span><br><span class="line"><span class="built_in">print</span>(nx.is_connected(G))  <span class="comment">#False</span></span><br></pre></td></tr></table></figure>
<p>结果如图：<img src="images/figure07.png" alt=""></p>
<h2 id="连通图判断联通性"><a href="#连通图判断联通性" class="headerlink" title="连通图判断联通性"></a>连通图判断联通性</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">Ga = nx.Graph()</span><br><span class="line">Ga.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>])</span><br><span class="line">Ga.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">4</span>,<span class="number">7</span>),(<span class="number">5</span>,<span class="number">6</span>),(<span class="number">5</span>,<span class="number">7</span>),(<span class="number">6</span>,<span class="number">7</span>)])</span><br><span class="line">nx.draw(Ga,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure08.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#联通图判断</span></span><br><span class="line"><span class="built_in">print</span>(nx.is_connected(Ga))  <span class="comment">#Ture</span></span><br></pre></td></tr></table></figure>
<p>如图<img src="../images/figure08.png" style="zoom:33%;" /></p>
<h1 id="集聚系数"><a href="#集聚系数" class="headerlink" title="集聚系数"></a>集聚系数</h1><h2 id="图一"><a href="#图一" class="headerlink" title="图一"></a>图一</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G =nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">4</span>),(<span class="number">1</span>,<span class="number">5</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">5</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">5</span>),(<span class="number">4</span>,<span class="number">5</span>)])</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure09.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#节点1的聚集系数</span></span><br><span class="line"><span class="built_in">print</span>(nx.clustering(G,<span class="number">1</span>)) <span class="comment">#1.0</span></span><br></pre></td></tr></table></figure>
<p>如图<img src="./../images/figure09.png" alt="figure09" style="zoom:33%;" /></p>
<h2 id="图二"><a href="#图二" class="headerlink" title="图二"></a>图二</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G = nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">4</span>,<span class="number">5</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">4</span>),(<span class="number">1</span>,<span class="number">5</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">5</span>),(<span class="number">3</span>,<span class="number">5</span>)])</span><br><span class="line"><span class="comment">#去除边</span></span><br><span class="line">G.remove_edges_from([(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">5</span>)])</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure0902.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(nx.clustering(G,<span class="number">1</span>)) <span class="comment">#0.5</span></span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure0902.png" style="zoom:33%;" /></p>
<h2 id="图三"><a href="#图三" class="headerlink" title="图三"></a>图三</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G = nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>])</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">4</span>,<span class="number">5</span>),(<span class="number">1</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">4</span>),(<span class="number">1</span>,<span class="number">5</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">5</span>),(<span class="number">3</span>,<span class="number">5</span>)])</span><br><span class="line"><span class="comment">#去除边</span></span><br><span class="line">G.remove_edges_from([(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">4</span>),(<span class="number">3</span>,<span class="number">5</span>)])</span><br><span class="line">G.remove_edges_from([(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">5</span>),(<span class="number">4</span>,<span class="number">5</span>)])</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure0903.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(nx.clustering(G,<span class="number">1</span>)) <span class="comment">#0.0</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure0903.png" style="zoom:33%;" /></p>
<h1 id="平均集聚系数与全局聚集系数"><a href="#平均集聚系数与全局聚集系数" class="headerlink" title="平均集聚系数与全局聚集系数"></a>平均集聚系数与全局聚集系数</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G=nx.Graph()</span><br><span class="line">G.add_nodes_from([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>])</span><br><span class="line">G.add_edges_from([(<span class="number">1</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">3</span>),(<span class="number">2</span>,<span class="number">4</span>),(<span class="number">2</span>,<span class="number">5</span>),(<span class="number">4</span>,<span class="number">5</span>),(<span class="number">4</span>,<span class="number">6</span>),(<span class="number">4</span>,<span class="number">7</span>),(<span class="number">5</span>,<span class="number">7</span>)])</span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure10.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="comment">#平均聚集系数</span></span><br><span class="line"><span class="built_in">print</span>(nx.average_clustering(G)) <span class="comment">#0.3095238095238095</span></span><br><span class="line"><span class="comment">#全局聚集系数</span></span><br><span class="line"><span class="built_in">print</span>(nx.transitivity(G))<span class="comment"># 0.375</span></span><br></pre></td></tr></table></figure>
<p>如图：<img src="images/figure10.png" style="zoom:33%;" /></p>
<h1 id="复杂网络的统计特征"><a href="#复杂网络的统计特征" class="headerlink" title="复杂网络的统计特征"></a>复杂网络的统计特征</h1><h2 id="泊松分布"><a href="#泊松分布" class="headerlink" title="泊松分布"></a>泊松分布</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个随机网络</span></span><br><span class="line">n = <span class="number">10000</span> <span class="comment"># 网络节点数</span></span><br><span class="line">p = <span class="number">0.001</span> <span class="comment"># 连边的概率0.001</span></span><br><span class="line"><span class="comment"># 生成ER网络</span></span><br><span class="line">ER = nx.erdos_renyi_graph(n, p)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取平均度</span></span><br><span class="line">d = <span class="built_in">dict</span>(nx.degree(ER))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;平均度为：&quot;</span>,<span class="built_in">sum</span>(d.values())/<span class="built_in">len</span>(ER.nodes))<span class="comment">#平均度为： 9.9996</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取所有可能得度值对应的概率</span></span><br><span class="line">x = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">max</span>(d.values())+<span class="number">1</span>))</span><br><span class="line">y = [i/n <span class="keyword">for</span> i <span class="keyword">in</span> nx.degree_histogram(ER)]</span><br><span class="line"></span><br><span class="line">plt.plot(x,y,<span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$p_k$&quot;</span>)</span><br><span class="line">ER_path = <span class="string">&#x27;E:/MyBlog/source/images/figure1101.png&#x27;</span></span><br><span class="line">plt.savefig(ER_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure1101.png" alt=""></p>
<h2 id="BA无标度网络"><a href="#BA无标度网络" class="headerlink" title="BA无标度网络"></a>BA无标度网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#创建一个随机网络</span></span><br><span class="line">n = <span class="number">100000</span> <span class="comment"># 网络节点数</span></span><br><span class="line">m = <span class="number">3</span> </span><br><span class="line"></span><br><span class="line">BA = nx.barabasi_albert_graph(n,m)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取平均度</span></span><br><span class="line">d = <span class="built_in">dict</span>(nx.degree(BA))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;平均度为&quot;</span>,<span class="built_in">sum</span>(d.values())/<span class="built_in">len</span>(BA.nodes))<span class="comment">#平均度为 5.99982</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#获取所有可能得度值对应的概率</span></span><br><span class="line">x = <span class="built_in">list</span>(<span class="built_in">range</span>(<span class="built_in">max</span>(d.values())+<span class="number">1</span>))</span><br><span class="line">y = [i/n <span class="keyword">for</span> i <span class="keyword">in</span> nx.degree_histogram(BA)]</span><br><span class="line"></span><br><span class="line"><span class="comment">#普通坐标轴下</span></span><br><span class="line"><span class="comment"># plt.plot(x, y, &#x27;o-&#x27;, color=&#x27;b&#x27;)</span></span><br><span class="line"><span class="comment"># plt.xlabel(&quot;$k$&quot;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&quot;$p_k$&quot;)</span></span><br><span class="line"><span class="comment"># BA_path = &#x27;E:/MyBlog/source/images/figure11021.png&#x27;</span></span><br><span class="line"><span class="comment"># plt.savefig(BA_path)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"><span class="comment">#在双对数轴下显示</span></span><br><span class="line"><span class="comment"># plt.plot(x,y,&#x27;ro-&#x27;)</span></span><br><span class="line"><span class="comment"># plt.xscale(&#x27;log&#x27;)</span></span><br><span class="line"><span class="comment"># plt.yscale(&#x27;log&#x27;)</span></span><br><span class="line"><span class="comment"># plt.xlabel(&quot;$k$&quot;)</span></span><br><span class="line"><span class="comment"># plt.ylabel(&quot;$p_k$&quot;)</span></span><br><span class="line"><span class="comment"># BA_path = &#x27;E:/MyBlog/source/images/figure11021.png&#x27;</span></span><br><span class="line"><span class="comment"># plt.savefig(BA_path)</span></span><br><span class="line"><span class="comment"># plt.show()</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#在双对数坐标轴下绘制，并且把点0值坐标排除</span></span><br><span class="line">new_x = []</span><br><span class="line">new_y = []</span><br><span class="line"><span class="comment"># 删除0值</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">    <span class="keyword">if</span> y[i] != <span class="number">0</span>:</span><br><span class="line">        new_x.append(x[i])</span><br><span class="line">        new_y.append(y[i])</span><br><span class="line">plt.plot(new_x,new_y,<span class="string">&#x27;ro-&#x27;</span>)</span><br><span class="line">plt.xscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.yscale(<span class="string">&#x27;log&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$p_k$&quot;</span>)</span><br><span class="line">BA_path = <span class="string">&#x27;E:/MyBlog/source/images/figure11022.png&#x27;</span></span><br><span class="line">plt.savefig(BA_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>普通轴下如图<img src="images/figure1102.png" alt=""></p>
<p>双对数轴下如图：<img src="images/figure11021.png" alt=""></p>
<p>去除0值坐标下图像如图<img src="images/figure11022.png" alt=""></p>
<h1 id="网络的直径、效率和平均最短距离"><a href="#网络的直径、效率和平均最短距离" class="headerlink" title="网络的直径、效率和平均最短距离"></a>网络的直径、效率和平均最短距离</h1><p>在复杂网络中，<strong>网络的直径</strong>、<strong>效率</strong>和<strong>平均最短距离</strong>是衡量网络结构和信息传递特性的重要指标。它们能帮助理解网络的全局特性以及节点之间的相互连接情况。</p>
<h3 id="1-网络的直径（Diameter-of-a-Network）"><a href="#1-网络的直径（Diameter-of-a-Network）" class="headerlink" title="1. 网络的直径（Diameter of a Network）"></a>1. <strong>网络的直径（Diameter of a Network）</strong></h3><ul>
<li><p><strong>定义</strong>：网络直径是网络中所有节点对之间最短路径长度的最大值，代表网络中最远的两个节点之间的距离。它是网络中最长的最短路径。</p>
</li>
<li><p><strong>意义</strong>：直径反映了网络的“扩展性”或“广度”，即信息在网络中传播需要经过的最大步数。直径越小，表示网络中任何两个节点之间的距离相对较短，信息传播更快。</p>
</li>
<li><p><strong>计算</strong>：通过计算所有节点对的最短路径，并取这些最短路径中的最大值来得到网络的直径。</p>
</li>
</ul>
<h3 id="2-网络效率（Network-Efficiency）"><a href="#2-网络效率（Network-Efficiency）" class="headerlink" title="2. 网络效率（Network Efficiency）"></a>2. <strong>网络效率（Network Efficiency）</strong></h3><ul>
<li><p><strong>定义</strong>：网络效率用来衡量网络中信息传播的效率，是所有节点对之间的最短路径长度的倒数的平均值。</p>
<p><img src="images/efigure006.png" alt=""></p>
</li>
<li><p><strong>意义</strong>：网络效率反映了整个网络的信息传递能力。效率越高，说明信息可以在网络中快速传播，节点之间的连接较为紧密。特别是在无标度网络或小世界网络中，网络效率通常较高。</p>
</li>
<li><p><strong>局部和全局效率</strong>：</p>
<ul>
<li><strong>局部效率</strong>：衡量每个节点周围子网络的效率，主要用于反映局部结构的稳健性。</li>
<li><strong>全局效率</strong>：衡量整个网络的信息传递效率。</li>
</ul>
</li>
</ul>
<h3 id="3-平均最短路径长度（Average-Shortest-Path-Length）"><a href="#3-平均最短路径长度（Average-Shortest-Path-Length）" class="headerlink" title="3. 平均最短路径长度（Average Shortest Path Length）"></a>3. <strong>平均最短路径长度（Average Shortest Path Length）</strong></h3><ul>
<li><p><strong>定义</strong>：平均最短路径长度是网络中所有节点对之间的最短路径长度的平均值，表示节点间的平均距离。</p>
<p><img src="images/efigure008.jpg" alt=""></p>
</li>
<li><p><strong>意义</strong>：平均最短路径长度反映了网络中任意两个节点之间的平均距离。它描述了网络的连通性和紧密性，平均最短路径越小，说明网络节点之间的距离较短，信息传播的速度更快。</p>
</li>
<li><p><strong>与网络类型的关系</strong>：</p>
<ul>
<li>在小世界网络中，平均最短路径长度通常较小，即便网络规模很大，节点之间的平均距离仍然较短。</li>
<li>随机网络和规则网络的平均最短路径长度则可能相对较大。</li>
</ul>
</li>
</ul>
<h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ul>
<li><strong>直径</strong>：最大最短路径，反映网络最远的两个节点的距离。</li>
<li><strong>效率</strong>：衡量网络中信息传播的效率，路径越短，效率越高。</li>
<li><strong>平均最短路径长度</strong>：所有节点对之间的平均最短路径，表示节点间平均距离。</li>
</ul>
<p>这些指标有助于分析网络的连通性和信息传播的效率，尤其在社会网络、交通网络和互联网等实际应用中非常关键。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">G = nx.barabasi_albert_graph(<span class="number">100</span>,<span class="number">3</span>)</span><br><span class="line"><span class="comment">#网络直径</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;网络直径为：&quot;</span>,nx.diameter(G)) <span class="comment">#网络直径为： 4</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#指定节点对i和j之间的效率，前提是这两个节点之间要有路径，即从i到j是可达的</span></span><br><span class="line"><span class="built_in">print</span>(nx.efficiency(G,<span class="number">1</span>,<span class="number">5</span>))<span class="comment">#1.0</span></span><br><span class="line"><span class="comment">#指定节点之间的最短路径</span></span><br><span class="line"><span class="built_in">print</span>(nx.shortest_path_length(G,<span class="number">1</span>,<span class="number">5</span>))<span class="comment">#1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#局部效率</span></span><br><span class="line"><span class="built_in">print</span>(nx.local_efficiency(G))<span class="comment">#0.14895517535955058</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#全局效率</span></span><br><span class="line"><span class="built_in">print</span>(nx.global_efficiency(G))<span class="comment">#0.42673400673403755</span></span><br><span class="line"><span class="comment">#集聚系数</span></span><br><span class="line"><span class="built_in">print</span>(nx.clustering(G))</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0: 0.054187192118226604, 1: 0.08947368421052632, 2: 0.1111111111111111, 3: 0.19444444444444445, 4: 0.12857142857142856, 5: 0.07602339181286549, 6: 0.10909090909090909, 7: 0.10476190476190476, 8: 0.08974358974358974, 9: 0.05555555555555555, 10: 0.08888888888888889, 11: 0.05238095238095238, 12: 0.09090909090909091, 13: 0.07692307692307693, 14: 0.08888888888888889, 15: 0, 16: 0.16666666666666666, 17: 0.045454545454545456, 18: 0.10714285714285714, 19: 0.3, 20: 0.3, 21: 0.2, 22: 0.3333333333333333, 23: 0.047619047619047616, 24: 0.3333333333333333, 25: 0.16666666666666666, 26: 0.16666666666666666, 27: 0.09523809523809523, 28: 0.6666666666666666, 29: 0, 30: 0.16666666666666666, 31: 0, 32: 0.1, 33: 0.07142857142857142, 34: 0.06666666666666667, 35: 0, 36: 0.1, 37: 0.06666666666666667, 38: 0.2, 39: 0.1, 40: 0, 41: 0, 42: 0, 43: 0, 44: 0, 45: 0, 46: 0, 47: 0, 48: 0.3333333333333333, 49: 0, 50: 0.3333333333333333, 51: 0, 52: 0, 53: 0, 54: 0, 55: 0.13333333333333333, 56: 0, 57: 0, 58: 0.6666666666666666, 59: 0, 60: 0.3333333333333333, 61: 0, 62: 0, 63: 0, 64: 0, 65: 0.3333333333333333, 66: 0, 67: 0.3333333333333333, 68: 0.3333333333333333, 69: 0.5, 70: 0.3333333333333333, 71: 0.3333333333333333, 72: 0.3333333333333333, 73: 0, 74: 0, 75: 0.3333333333333333, 76: 0, 77: 0, 78: 0, 79: 0, 80: 0.3333333333333333, 81: 0.3333333333333333, 82: 0, 83: 0.16666666666666666, 84: 0, 85: 0, 86: 0.3333333333333333, 87: 0.3333333333333333, 88: 0, 89: 0.1, 90: 0, 91: 0, 92: 0, 93: 0, 94: 0, 95: 0.3333333333333333, 96: 0.3333333333333333, 97: 0, 98: 0.3333333333333333, 99: 0&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#平均聚集系数</span></span><br><span class="line"><span class="built_in">print</span>(nx.average_clustering(G))<span class="comment">#0.12444503892961248</span></span><br><span class="line"><span class="comment">#全局聚集系数</span></span><br><span class="line"><span class="built_in">print</span>(nx.transitivity(G))<span class="comment">#0.0834658187599364</span></span><br><span class="line">nx.draw(G,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2001.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>如下图<img src="images/figure2001.png" alt=""></p>
<h1 id="度-度相关性"><a href="#度-度相关性" class="headerlink" title="度-度相关性"></a>度-度相关性</h1><p>度-度相关性（degree-degree correlation）是网络科学中的一个重要概念，描述的是网络中节点的度（即连接的边的数量）之间的相关性。它主要用于分析网络的结构特征，尤其是在无标度网络和小世界网络中。</p>
<h3 id="主要概念："><a href="#主要概念：" class="headerlink" title="主要概念："></a>主要概念：</h3><ol>
<li><p><strong>度（Degree）</strong>: 节点的度是指与该节点直接相连的边的数量。</p>
</li>
<li><p><strong>度-度相关性</strong>: 度-度相关性衡量的是节点的度值与其邻居节点度值之间的相关性。即，度较大的节点是否更可能连接到度较大的节点。</p>
</li>
</ol>
<h3 id="类型："><a href="#类型：" class="headerlink" title="类型："></a>类型：</h3><ul>
<li><p><strong>正相关（Assortative Mixing）</strong>: 高度节点倾向于连接到高度节点，低度节点倾向于连接到低度节点。例如，社交网络中，受欢迎的人可能更容易与其他受欢迎的人建立联系。</p>
</li>
<li><p><strong>负相关（Disassortative Mixing）</strong>: 高度节点倾向于连接到低度节点，低度节点倾向于连接到高度节点。这在许多生物网络和互联网中比较常见。</p>
</li>
<li><p><strong>无相关（Neutral Mixing）</strong>: 节点的度值与其邻居节点的度值之间没有明显的相关性。</p>
</li>
</ul>
<h3 id="衡量方法："><a href="#衡量方法：" class="headerlink" title="衡量方法："></a>衡量方法：</h3><ol>
<li><p><strong>Pearson相关系数</strong>: 可以计算节点度的平均值，利用这些值计算Pearson相关系数。</p>
</li>
<li><p><strong>度-度相关矩阵</strong>: 通过构建一个度-度相关矩阵，可以可视化度之间的相关性。</p>
</li>
<li><p><strong>配对分布函数</strong>: 分析特定度的节点连接到邻居的度分布，以检测度-度相关性。</p>
</li>
</ol>
<h3 id="应用："><a href="#应用：" class="headerlink" title="应用："></a>应用：</h3><ul>
<li><p><strong>社交网络分析</strong>: 理解人与人之间的关系，识别影响力节点。</p>
</li>
<li><p><strong>生物网络</strong>: 分析不同物种或基因之间的相互作用。</p>
</li>
<li><p><strong>网络优化</strong>: 在设计网络时考虑度-度相关性以提高网络的稳定性和效率。</p>
</li>
</ul>
<p>度-度相关性可以提供网络结构的深刻见解，帮助研究者理解和预测网络行为。</p>
<h2 id="最近邻平均度值"><a href="#最近邻平均度值" class="headerlink" title="最近邻平均度值"></a>最近邻平均度值</h2><p>最近邻平均度值（Average Nearest Neighbor Degree）是指某个节点的邻居的平均度数。计算步骤如下：</p>
<h4 id="计算步骤："><a href="#计算步骤：" class="headerlink" title="计算步骤："></a>计算步骤：</h4><ol>
<li><p><strong>构建图</strong>：首先，构建一个图（无向图或有向图），并定义每个节点的度数。</p>
</li>
<li><p><strong>计算每个节点的邻居的度数</strong>：</p>
<ul>
<li>对于图中的每个节点 i，找到它的所有邻居。</li>
<li>记录这些邻居的度数。</li>
</ul>
</li>
<li><p><strong>计算平均值</strong>：</p>
<ul>
<li>对于每个节点 iii，计算它的邻居的度数的平均值：</li>
<li><img src="images/efigure0020.png" alt=""></li>
</ul>
</li>
</ol>
<h5 id="python实现如下"><a href="#python实现如下" class="headerlink" title="python实现如下"></a>python实现如下</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> rcParams</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">`nx.from_pandas_edgelist` 是 NetworkX 库中的一个函数，用于从 Pandas DataFrame 创建图。你提到的四个参数的具体含义如下：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. **df2**: 这是包含边信息的 Pandas DataFrame。每一行通常代表图中的一条边。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">2. **&quot;source&quot;**: 这是指定 DataFrame 中表示边起点的列名。该列中的值将作为图中节点的起点。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">3. **&quot;target&quot;**: 这是指定 DataFrame 中表示边终点的列名。该列中的值将作为图中节点的终点。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">4. **create_using=nx.Graph()**: 这是一个可选参数，用于指定要创建的图的类型。在这个例子中，使用 `nx.Graph()` 表示创建一个无向图。如果需要创建有向图，可以使用 `nx.DiGraph()`。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">综合起来，这个函数会根据提供的 DataFrame 中的起点和终点列，构建一个图结构。</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载三个真实数据集</span></span><br><span class="line"><span class="comment"># 1. 科学合作网络</span></span><br><span class="line">df1 = pd.read_csv(<span class="string">&quot;citation.csv&quot;</span>)</span><br><span class="line">G1 = nx.from_pandas_edgelist(df1, <span class="string">&#x27;source&#x27;</span>, <span class="string">&#x27;target&#x27;</span>, create_using = nx.Graph())</span><br><span class="line"><span class="comment"># 2. 电网</span></span><br><span class="line">df2 = pd.read_csv(<span class="string">&quot;power.csv&quot;</span>)</span><br><span class="line">G2 = nx.from_pandas_edgelist(df2, <span class="string">&#x27;source&#x27;</span>, <span class="string">&#x27;target&#x27;</span>, create_using = nx.Graph())</span><br><span class="line"><span class="comment"># 3. 代谢网络</span></span><br><span class="line">df3 = pd.read_csv(<span class="string">&quot;celegans_metabolic.csv&quot;</span>)</span><br><span class="line">G3 = nx.from_pandas_edgelist(df3, <span class="string">&#x27;source&#x27;</span>, <span class="string">&#x27;target&#x27;</span>, create_using = nx.Graph())</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义求最近临平均度的函数</span></span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    set([G.degree(i) for i in G.nodes()]) 是用来获取图 </span></span><br><span class="line"><span class="string">𝐺</span></span><br><span class="line"><span class="string">G 中所有节点的度值，并将其转换为一个集合。让我们逐步分析这个表达式：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">G.nodes(): 这个方法返回图 </span></span><br><span class="line"><span class="string">𝐺</span></span><br><span class="line"><span class="string">G 中的所有节点。结果是一个节点的列表或集合。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">G.degree(i): 这个方法返回节点 </span></span><br><span class="line"><span class="string">𝑖</span></span><br><span class="line"><span class="string">i 的度，即与节点 </span></span><br><span class="line"><span class="string">𝑖</span></span><br><span class="line"><span class="string">i 直接相连的边的数量。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">列表推导式: [G.degree(i) for i in G.nodes()] 这一部分是一个列表推导式，它遍历所有节点 </span></span><br><span class="line"><span class="string">𝑖</span></span><br><span class="line"><span class="string">i，并对每个节点调用 G.degree(i)，生成一个包含所有节点度值的列表。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">set(...): 最后，使用 set(...) 将这个度值列表转换为集合。集合的特点是去重，这意味着最终结果将包含图中所有不同的度值。</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义求最近邻平均度的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">average_nearest_neighbor_degree</span>(<span class="params">G</span>):</span><br><span class="line">    k = <span class="built_in">set</span>([G.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes()])  <span class="comment"># 获取所有可能的度值</span></span><br><span class="line">    sorted_k = <span class="built_in">sorted</span>(k)</span><br><span class="line">    knni = nx.average_neighbor_degree(G)</span><br><span class="line"></span><br><span class="line">    k_nn_k = []</span><br><span class="line">    <span class="keyword">for</span> ki <span class="keyword">in</span> sorted_k:</span><br><span class="line">        <span class="keyword">if</span> ki == <span class="number">0</span>:</span><br><span class="line">            k_nn_k.append(<span class="number">0.0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            c = <span class="number">0</span></span><br><span class="line">            s = <span class="number">0</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">                <span class="keyword">if</span> G.degree(i) == ki:</span><br><span class="line">                    s += knni[i]</span><br><span class="line">                    c += <span class="number">1</span></span><br><span class="line">            k_nn_k.append(s / c)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> sorted_k, k_nn_k</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">函数average_nearest_neighbor_degree解析：</span></span><br><span class="line"><span class="string">这个函数 `average_nearest_neighbor_degree` 计算了给定图 ( G ) 中每个可能的节点度值的平均最近邻度（Average Nearest Neighbor Degree）。让我们逐步分析这个函数的实现：</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">### 函数结构</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">1. **获取所有度值**:</span></span><br><span class="line"><span class="string">   ```python</span></span><br><span class="line"><span class="string">   k = set([G.degree(i) for i in G.nodes()])</span></span><br></pre></td></tr></table></figure>
<ul>
<li>使用列表推导式获取图中所有节点的度值，并将其转换为集合以去重。最终结果是图 ( G ) 中所有不同的度值。</li>
</ul>
<ol>
<li><p><strong>排序度值</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sorted_k = <span class="built_in">sorted</span>(k)</span><br></pre></td></tr></table></figure>
<ul>
<li>将度值排序，方便后续计算。</li>
</ul>
</li>
<li><p><strong>初始化结果列表</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">k_nn_k = []</span><br></pre></td></tr></table></figure>
<ul>
<li>该列表用于存储每个度值的平均最近邻度。</li>
</ul>
</li>
<li><p><strong>计算每个度值的平均最近邻度</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> ki <span class="keyword">in</span> sorted_k:</span><br><span class="line">    c = <span class="number">0</span></span><br><span class="line">    k_nn_i = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">        <span class="keyword">if</span> G.degree(i) == ki:</span><br><span class="line">            k_nn_i += <span class="built_in">sum</span>([G.degree(j) <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">list</span>(nx.all_neighbors(G, i))]) / ki</span><br><span class="line">            c += <span class="number">1</span></span><br><span class="line">    k_nn_k.append(k_nn_i / c)</span><br></pre></td></tr></table></figure>
<ul>
<li>外层循环遍历每个度值 ( ki )。</li>
<li>对于每个度值，初始化计数器 ( c ) 和累计和 ( k_nn_i )。</li>
<li>内层循环遍历图中的所有节点 ( i )，并检查节点 ( i ) 的度是否等于 ( ki )。<ul>
<li>如果是，则计算节点 ( i ) 的所有邻居的度值之和，并除以该节点的度 ( ki )。</li>
<li>将这个值累加到 ( k_nn_i )，并增加计数 ( c )。</li>
</ul>
</li>
<li>最后，计算该度值的平均最近邻度并将结果添加到 ( k_nn_k ) 中。</li>
</ul>
</li>
<li><p><strong>返回结果</strong>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">return</span> sorted_k, k_nn_k</span><br></pre></td></tr></table></figure>
<ul>
<li>函数返回两个列表：排序后的度值列表 <code>sorted_k</code> 和对应的平均最近邻度列表 <code>k_nn_k</code>。</li>
</ul>
</li>
</ol>
<h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>这个函数的应用主要在于分析网络的结构特性，特别是度-度相关性。通过计算平均最近邻度，可以了解高连接度节点与低连接度节点之间的连接模式，以及网络的聚集性和分散性。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">x1, y1 = average_nearest_neighbor_degree(G1)</span><br><span class="line">x2, y2 = average_nearest_neighbor_degree(G2)</span><br><span class="line">x3, y3 = average_nearest_neighbor_degree(G3)</span><br><span class="line">plt.figure()</span><br><span class="line">rcParams[<span class="string">&#x27;font.family&#x27;</span>] = <span class="string">&#x27;SimHei&#x27;</span>  <span class="comment"># 或者 &#x27;Microsoft YaHei&#x27;</span></span><br><span class="line">rcParams[<span class="string">&#x27;axes.unicode_minus&#x27;</span>] = <span class="literal">False</span></span><br><span class="line">plt.plot(x1, y1, label =<span class="string">&quot;科学合作网络&quot;</span>, color=<span class="string">&#x27;red&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>)</span><br><span class="line">plt.plot(x2, y2, label=<span class="string">&#x27;电网&#x27;</span>, color=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>)</span><br><span class="line">plt.plot(x3, y3, label=<span class="string">&#x27;代谢网络&#x27;</span>, color=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;三个数据集度-度相关性&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;度值&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;对应的平均最近邻度&#x27;</span>)</span><br><span class="line">plt.ylim([<span class="number">1</span>,<span class="number">100</span>])</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2002.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>图像如下：<img src="images/figure2002.png" alt=""></p>
<h2 id="基于Pearson相关系数的度-度相关性"><a href="#基于Pearson相关系数的度-度相关性" class="headerlink" title="基于Pearson相关系数的度-度相关性"></a>基于Pearson相关系数的度-度相关性</h2><ol>
<li><p>度关联性系数（Degree Assortativity Coefficient）<br>定义：度关联性系数是用来衡量网络中节点的度数之间的关联性，特别是高出度节点与低出度节点之间的连接模式。<br>范围：结果在 -1 到 1 之间，值越接近 1 表示高度节点更倾向于连接到其他高度节点，值越接近 -1 表示高度节点更倾向于连接到低度节点，而接近 0 表示没有明显的关联性。<br>计算方式：通常通过比较节点的度数与其邻居节点的度数来计算。</p>
</li>
<li><p>Pearson 相关系数（Degree Pearson Correlation Coefficient）<br>定义：Pearson 相关系数用于度量两个变量之间的线性相关性。在这里，它用来量化节点度数与其邻居度数之间的线性关系。<br>范围：与度关联性系数相似，结果也在 -1 到 1 之间，值越接近 1 表示强正相关，值越接近 -1 表示强负相关，接近 0 表示无相关性。<br>计算方式：通过计算节点度数和其邻居度数的协方差与标准差的比值来得到。<br>总结<br>主要差异：虽然这两个系数都衡量节点之间的度数相关性，但 degree_assortativity_coefficient 更侧重于整体的度数关联性，而 degree_pearson_correlation_coefficient 更侧重于具体的线性相关性。<br>适用场景：选择使用哪个方法取决于你想要分析的具体问题和网络的特征。如果你想了解网络中节点的连接模式，使用度关联性系数可能更合适；如果你关注的是度数之间的线性关系，可以使用 Pearson 相关系数。</p>
</li>
<li><p>python代码实现如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">  r1 = nx.degree_assortativity_coefficient(G1)</span><br><span class="line">  r2 = nx.degree_assortativity_coefficient(G2)</span><br><span class="line">  r3 = nx.degree_assortativity_coefficient(G3)</span><br><span class="line">  <span class="built_in">print</span>(r1)<span class="comment">#0.3539349998192337</span></span><br><span class="line">  <span class="built_in">print</span>(r2)<span class="comment">#0.0034569877442048825</span></span><br><span class="line">  <span class="built_in">print</span>(r3)<span class="comment">#-0.219662309363656</span></span><br><span class="line">  r11 = nx.degree_pearson_correlation_coefficient(G1)</span><br><span class="line">  r22 = nx.degree_pearson_correlation_coefficient(G2)</span><br><span class="line">  r33 = nx.degree_pearson_correlation_coefficient(G3)</span><br><span class="line">  <span class="built_in">print</span>(r11)<span class="comment">#0.3539349998192342</span></span><br><span class="line">  <span class="built_in">print</span>(r22)<span class="comment">#0.0034569877442048313</span></span><br><span class="line">  <span class="built_in">print</span>(r33)<span class="comment">#-0.219662309363656</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 介数与核数</span></span><br><span class="line"></span><br><span class="line">介数和核数是网络分析中的两个重要概念，通常用于评估网络中节点的重要性。</span><br><span class="line"></span><br><span class="line"><span class="number">1.</span> **介数（Betweenness Centrality）**：</span><br><span class="line">   - 介数衡量一个节点在网络中作为其他节点之间的“中介”的程度。具体来说，它计算的是通过某个节点的最短路径的数量与所有最短路径总数的比例。</span><br><span class="line">   - 介数较高的节点在信息流通中起着关键作用，通常被视为重要的桥梁或连接者。</span><br><span class="line"><span class="number">2.</span> **核数（Core Number）**：</span><br><span class="line">   - 核数表示一个节点在网络中最核心的位置。它是指节点在网络的 k-core 中的最大 k 值。k-core 是一个子图，其中每个节点至少与 k 个其他节点相连。</span><br><span class="line">   - 核数较高的节点通常被视为网络的“核心”，与其他节点的连接较多，具有更高的整体影响力。</span><br><span class="line"></span><br><span class="line"><span class="comment">#### 介数python实现代码如下</span></span><br><span class="line"></span><br><span class="line">```python</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line">BA = nx.barabasi_albert_graph(<span class="number">20</span>,<span class="number">2</span>)</span><br><span class="line">bc = nx.betweenness_centrality(BA)</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取介数最大的节点标签</span></span><br><span class="line">max_is = <span class="built_in">max</span>(bc,key=bc.get)</span><br><span class="line"><span class="built_in">print</span>(max_is)<span class="comment">#0</span></span><br><span class="line">nx.draw(BA,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2006.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(bc)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0: 0.4897660818713449, 1: 0.14200779727095517, 2: 0.0996588693957115, 3: 0.21510721247563355, 4: 0.08913255360623781, 5: 0.0, 6: 0.04668615984405458, 7: 0.011695906432748537, 8: 0.0, 9: 0.04975633528265107, 10: 0.04566276803118908, 11: 0.0, 12: 0.006335282651072124, 13: 0.04132553606237817, 14: 0.0, 15: 0.01627680311890838, 16: 0.0, 17: 0.012670565302144249, 18: 0.002923976608187134, 19: 0.0&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
</ol>
<p>如图<img src="images/figure2006.png" alt=""></p>
<h4 id="边介数python实现代码如下"><a href="#边介数python实现代码如下" class="headerlink" title="边介数python实现代码如下"></a>边介数python实现代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">BA = nx.barabasi_albert_graph(<span class="number">20</span>,<span class="number">2</span>)</span><br><span class="line">ebc = nx.edge_betweenness_centrality(BA)</span><br><span class="line">nx.draw(BA,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2007.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(ebc)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;(0, 1): 0.09999999999999999, (0, 2): 0.14154135338345863, (0, 3): 0.03833333333333333, (0, 4): 0.055401002506265666, (0, 8): 0.05381578947368422, (0, 10): 0.03767543859649122, (0, 11): 0.08451754385964914, (0, 15): 0.08679824561403507, (2, 3): 0.04443609022556391, (2, 5): 0.10825187969924811, (2, 6): 0.06017543859649123, (2, 7): 0.06680451127819549, (2, 9): 0.0875438596491228, (2, 10): 0.08491854636591478, (2, 14): 0.06508771929824561, (2, 17): 0.0842857142857143, (2, 18): 0.0875438596491228, (2, 19): 0.07035087719298246, (3, 4): 0.05066416040100251, (3, 6): 0.03842105263157895, (4, 5): 0.05452380952380953, (4, 7): 0.04926065162907268, (4, 8): 0.058734335839598986, (4, 11): 0.04245614035087719, (4, 16): 0.08139097744360901, (5, 12): 0.0625, (6, 9): 0.012456140350877193, (6, 18): 0.012456140350877193, (8, 13): 0.0513220551378446, (8, 14): 0.052731829573934824, (8, 19): 0.04228070175438596, (10, 13): 0.054172932330827074, (11, 12): 0.04276315789473684, (13, 15): 0.025394736842105265, (13, 16): 0.03738095238095238, (14, 17): 0.015714285714285715&#125;</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure2007.png" alt=""></p>
<h3 id="核数python代码实现如下"><a href="#核数python代码实现如下" class="headerlink" title="核数python代码实现如下"></a>核数python代码实现如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line">BA = nx.barabasi_albert_graph(<span class="number">20</span>,<span class="number">2</span>)</span><br><span class="line">ks = nx.core_number(BA)</span><br><span class="line"><span class="built_in">print</span>(ks)<span class="comment">#&#123;0: 2, 1: 2, 2: 2, 3: 2, 4: 2, 5: 2, 6: 2, 7: 2, 8: 2, 9: 2, 10: 2, 11: 2, 12: 2, 13: 2, 14: 2, 15: 2, 16: 2, 17: 2, 18: 2, 19: 2&#125;</span></span><br><span class="line">nx.draw(BA,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2008.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure2008.png" alt=""></p>
<h4 id="换一个网络-俱乐部网络-python代码如下"><a href="#换一个网络-俱乐部网络-python代码如下" class="headerlink" title="换一个网络(俱乐部网络)python代码如下"></a>换一个网络(俱乐部网络)python代码如下</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">kcg = nx.karate_club_graph()</span><br><span class="line">ks = nx.core_number(kcg)</span><br><span class="line"></span><br><span class="line">nx.draw(kcg,with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2009.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(ks)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">&#123;0: 4, 1: 4, 2: 4, 3: 4, 4: 3, 5: 3, 6: 3, 7: 4, 8: 4, 9: 2, 10: 3, 11: 1, 12: 2, 13: 4, 14: 2, 15: 2, 16: 2, 17: 2, 18: 2, 19: 3, 20: 2, 21: 2, 22: 2, 23: 3, 24: 3, 25: 3, 26: 2, 27: 3, 28: 3, 29: 3, 30: 4, 31: 3, 32: 4, 33: 4&#125;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="comment">#获取核度最大的节点标签</span></span><br><span class="line">max_is = <span class="built_in">max</span>(ks,key=ks.get)</span><br><span class="line"><span class="built_in">print</span>(max_is)<span class="comment">#0</span></span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>如图<img src="" alt=""><img src="images/figure2009.png" alt="figure2009"></p>
<h2 id="网络密度"><a href="#网络密度" class="headerlink" title="网络密度"></a>网络密度</h2><p>网络密度是网络分析中的一个重要指标，用于衡量网络中实际连接的边与可能连接的边之间的比例。具体来说，网络密度的计算公式为：</p>
<ul>
<li><img src="images/figure00203.png" alt=""></li>
</ul>
<h3 id="解释：-2"><a href="#解释：-2" class="headerlink" title="解释："></a>解释：</h3><ul>
<li><strong>密度值范围</strong>：网络密度的值介于 0 和 1 之间。密度为 0 表示没有边连接任何节点（完全分散），而密度为 1 表示每对节点都有一条边连接（完全连通）。</li>
<li><strong>网络类型</strong>：对于稀疏网络，密度值通常较低，而对于密集网络，密度值较高。</li>
</ul>
<h3 id="应用：-1"><a href="#应用：-1" class="headerlink" title="应用："></a>应用：</h3><p>网络密度可以用来：</p>
<ul>
<li>评估网络的紧密程度。</li>
<li>比较不同网络之间的连通性。</li>
<li>分析网络的稳定性和信息传播效率。</li>
</ul>
<h3 id="上图网络的密度python代码实现如下"><a href="#上图网络的密度python代码实现如下" class="headerlink" title="上图网络的密度python代码实现如下"></a>上图网络的密度python代码实现如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#网络密度</span></span><br><span class="line"><span class="built_in">print</span>(nx.density(kcg))<span class="comment">#0.13903743315508021</span></span><br></pre></td></tr></table></figure>
<h2 id="几种常用的中心性指标"><a href="#几种常用的中心性指标" class="headerlink" title="几种常用的中心性指标"></a>几种常用的中心性指标</h2><p>在网络分析中，常用的中心性指标用于评估节点在网络中的重要性和影响力。以下是几种常见的中心性指标：</p>
<ol>
<li><p><strong>度中心性（Degree Centrality）</strong>：</p>
<ul>
<li>计算节点的直接连接数量（度），即与该节点相连的边的数量。</li>
<li>高度中心性的节点通常是网络中的重要连接者。</li>
</ul>
</li>
<li><p><strong>介数中心性（Betweenness Centrality）</strong>：</p>
<ul>
<li>衡量一个节点作为其他节点之间最短路径的桥梁的能力。</li>
<li>介数高的节点通常在信息流动中扮演重要角色。</li>
</ul>
</li>
<li><p><strong>接近中心性（Closeness Centrality）</strong>：</p>
<ul>
<li>衡量节点与其他节点的距离。计算节点到网络中所有其他节点的平均最短路径长度的倒数。</li>
<li>接近中心性高的节点能够快速访问网络中的其他节点。</li>
</ul>
</li>
<li><p><strong>特征向量中心性（Eigenvector Centrality）</strong>：</p>
<ul>
<li>不仅考虑一个节点的连接数量，还考虑其连接的节点的重要性。与高中心性节点相连的节点具有更高的特征向量中心性。</li>
<li>适合识别在社交网络等复杂网络中具有影响力的节点。</li>
</ul>
</li>
<li><p><strong>PageRank</strong>：</p>
<ul>
<li><p>一种基于链接结构的中心性指标，最初用于评估网页的重要性。考虑到指向某一节点的链接数量和质量。</p>
</li>
<li><p>在社交网络中，PageRank 可以用来识别影响力较大的用户。</p>
<h3 id="python代码实现如下"><a href="#python代码实现如下" class="headerlink" title="python代码实现如下"></a>python代码实现如下</h3></li>
</ul>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line"><span class="comment">#分别生成ER和BA无标度网络，节点设置为n=100</span></span><br><span class="line">GER = nx.erdos_renyi_graph(<span class="number">100</span>,<span class="number">0.08</span>)</span><br><span class="line">GBA = nx.barabasi_albert_graph(<span class="number">100</span>,<span class="number">4</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#度中心性</span></span><br><span class="line">dc1 = nx.degree_centrality(GER)</span><br><span class="line">dc2 = nx.degree_centrality(GBA)</span><br><span class="line"><span class="comment">#介数中心性</span></span><br><span class="line">bc1 = nx.betweenness_centrality(GER)</span><br><span class="line">bc2 = nx.betweenness_centrality(GBA)</span><br><span class="line"><span class="comment">#接近度中心性</span></span><br><span class="line">cc1 = nx.closeness_centrality(GER)</span><br><span class="line">cc2 = nx.closeness_centrality(GBA)</span><br><span class="line"><span class="comment">#特征向量中心性</span></span><br><span class="line">ec1 = nx.eigenvector_centrality(GER)</span><br><span class="line">ec2 = nx.eigenvector_centrality(GBA)</span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制比较图像</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>,<span class="number">10</span>))</span><br><span class="line">plt.subplot(<span class="number">221</span>)</span><br><span class="line">plt.scatter(dc1.keys(),dc1.values(),color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;ER&#x27;</span>)</span><br><span class="line">plt.scatter(dc2.keys(),dc2.values(),color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;BA&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;node_label&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;centrality&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;degree_centrality&quot;</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2010.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">222</span>)</span><br><span class="line">plt.plot(bc1.keys(),bc1.values(),color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;ER&#x27;</span>)</span><br><span class="line">plt.plot(bc2.keys(),bc2.values(),color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;BA&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;node_label&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;centrality&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;betweenness_centrality&quot;</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2011.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">223</span>)</span><br><span class="line">plt.plot(cc1.keys(),cc1.values(),color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;ER&#x27;</span>)</span><br><span class="line">plt.plot(cc2.keys(),cc2.values(),color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;BA&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;node_label&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;centrality&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;closeness_centrality&quot;</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2012.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">224</span>)</span><br><span class="line">plt.plot(ec1.keys(),ec1.values(),color=<span class="string">&#x27;red&#x27;</span>,label=<span class="string">&#x27;ER&#x27;</span>)</span><br><span class="line">plt.plot(ec2.keys(),ec2.values(),color=<span class="string">&#x27;blue&#x27;</span>,label=<span class="string">&#x27;BA&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;node_label&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;centrality&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;eigenvector_centrality&quot;</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2013.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>如图<img src="../images/figure2013.png" alt=""></p>
<h2 id="随即网络ER图"><a href="#随即网络ER图" class="headerlink" title="随即网络ER图"></a>随即网络ER图</h2><h3 id="第一种G（N-L）代码实现如下"><a href="#第一种G（N-L）代码实现如下" class="headerlink" title="第一种G（N,L）代码实现如下"></a>第一种G（N,L）代码实现如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GNL</span>(<span class="params">N,L</span>):</span><br><span class="line">    G = nx.Graph()</span><br><span class="line">    G.add_nodes_from(<span class="built_in">range</span>(N))</span><br><span class="line">    nlist = <span class="built_in">list</span>(G)</span><br><span class="line">    edge_count = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> edge_count &lt; L:</span><br><span class="line">        u = random.choice(nlist)</span><br><span class="line">        v = random.choice(nlist)</span><br><span class="line">        <span class="keyword">if</span> u == v <span class="keyword">or</span> G.has_edge(u,v):</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            G.add_edge(u,v)</span><br><span class="line">            edge_count += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line">G = GNL(<span class="number">10</span>,<span class="number">20</span>)</span><br><span class="line">nx.draw(G)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2000.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>图如下<img src="" alt=""><img src="images/figure2000.png" alt="figure2000"></p>
<h3 id="第二种G（N，p）python代码实现如下"><a href="#第二种G（N，p）python代码实现如下" class="headerlink" title="第二种G（N，p）python代码实现如下"></a>第二种G（N，p）python代码实现如下</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">import</span> itertools</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">GNP</span> (N,p):</span><br><span class="line">    edges = itertools.combinations(<span class="built_in">range</span>(N),<span class="number">2</span>)</span><br><span class="line">    G = nx.Graph()</span><br><span class="line">    G.add_nodes_from(<span class="built_in">range</span>(N))</span><br><span class="line">    <span class="keyword">for</span> e <span class="keyword">in</span> edges:</span><br><span class="line">        <span class="keyword">if</span> random.random() &lt; p:</span><br><span class="line">            G.add_edge(*e)</span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line">G = GNP(<span class="number">10</span>,<span class="number">0.6</span>)</span><br><span class="line">nx.draw(G)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2016.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure2016.png" alt=""></p>
<h1 id="小世界网络"><a href="#小世界网络" class="headerlink" title="小世界网络"></a>小世界网络</h1><p>小世界网络模型（Small-World Network Model）是一种网络结构模型，最初由D.J. Watts和S.H. Strogatz在1998年提出。这个模型描述了具有高聚集性和短路径特征的网络，通常用于研究社交网络、信息传播、生物网络等。</p>
<h3 id="主要特征："><a href="#主要特征：" class="headerlink" title="主要特征："></a>主要特征：</h3><ol>
<li><p><strong>高聚集性</strong>：小世界网络中的节点倾向于与其邻近节点建立连接，形成紧密的群体。这样的特性使得相邻节点之间的连接概率高。</p>
</li>
<li><p><strong>短路径长度</strong>：尽管小世界网络可能是一个大型网络，但任意两个节点之间的平均路径长度较短。即使节点之间没有直接连接，通过少量的中间节点也能实现快速连接。</p>
</li>
<li><p><strong>随机性</strong>：小世界网络在其结构中引入了一些随机连接，这样即使在局部聚集性较高的情况下，也能打破局部结构，使得网络具有更好的连通性。</p>
</li>
</ol>
<h3 id="典型应用："><a href="#典型应用：" class="headerlink" title="典型应用："></a>典型应用：</h3><ul>
<li><strong>社交网络</strong>：研究朋友之间的连接、信息传播的速度等。</li>
<li><strong>生物网络</strong>：如神经网络和生态系统中的物种间相互作用。</li>
<li><strong>互联网</strong>：分析网站链接结构、数据传输等。</li>
</ul>
<h3 id="示例："><a href="#示例：" class="headerlink" title="示例："></a>示例：</h3><p>一个经典的例子是“六度分隔”理论，表明在社交网络中，任意两个个体之间的联系通常可以通过最多六个中介达到。</p>
<p>小世界网络模型在网络科学中具有重要意义，帮助理解复杂系统中的连接和传播机制。</p>
<h2 id="十个真实网络的平均距离与最大距离"><a href="#十个真实网络的平均距离与最大距离" class="headerlink" title="十个真实网络的平均距离与最大距离"></a>十个真实网络的平均距离与最大距离</h2><div class="table-container">
<table>
<thead>
<tr>
<th>网络类型</th>
<th>网络名称</th>
<th>节点数</th>
<th>边数</th>
<th>平均距离</th>
<th>最大距离</th>
</tr>
</thead>
<tbody>
<tr>
<td>社交网络</td>
<td>Facebook</td>
<td>4,000</td>
<td>88,000</td>
<td>3.5</td>
<td>7</td>
</tr>
<tr>
<td>互联网</td>
<td>AS (Autonomous System)</td>
<td>40,000</td>
<td>80,000</td>
<td>3.6</td>
<td>14</td>
</tr>
<tr>
<td>生物网络</td>
<td>蛋白质互作网络</td>
<td>10,000</td>
<td>50,000</td>
<td>4.2</td>
<td>10</td>
</tr>
<tr>
<td>交通网络</td>
<td>路网</td>
<td>5,000</td>
<td>15,000</td>
<td>5.1</td>
<td>20</td>
</tr>
<tr>
<td>科学合作网络</td>
<td>科学家合作</td>
<td>2,000</td>
<td>10,000</td>
<td>4.0</td>
<td>8</td>
</tr>
<tr>
<td>世界贸易网络</td>
<td>国家间贸易</td>
<td>200</td>
<td>1,000</td>
<td>3.1</td>
<td>8</td>
</tr>
<tr>
<td>生态网络</td>
<td>生态系统</td>
<td>1,500</td>
<td>7,000</td>
<td>4.5</td>
<td>12</td>
</tr>
<tr>
<td>语言网络</td>
<td>单词共现网络</td>
<td>1,000</td>
<td>3,000</td>
<td>2.8</td>
<td>6</td>
</tr>
<tr>
<td>神经网络</td>
<td>脑神经元连接</td>
<td>20,000</td>
<td>100,000</td>
<td>6.0</td>
<td>15</td>
</tr>
<tr>
<td>邮件网络</td>
<td>电子邮件交换</td>
<td>10,000</td>
<td>50,000</td>
<td>3.9</td>
<td>11</td>
</tr>
</tbody>
</table>
</div>
<h2 id="K-近邻规则网络"><a href="#K-近邻规则网络" class="headerlink" title="K-近邻规则网络"></a>K-近邻规则网络</h2><h3 id="K-近邻规则网络与小世界网络区别与联系"><a href="#K-近邻规则网络与小世界网络区别与联系" class="headerlink" title="K-近邻规则网络与小世界网络区别与联系"></a>K-近邻规则网络与小世界网络区别与联系</h3><div class="table-container">
<table>
<thead>
<tr>
<th><strong>类别</strong></th>
<th><strong>K-近邻规则网络</strong></th>
<th><strong>小世界网络</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>构造方式</strong></td>
<td>每个节点与最近的K个邻居节点相连，依赖特征空间中的距离。</td>
<td>从规则格网随机重连，形成短路径和远距离连接。</td>
</tr>
<tr>
<td><strong>平均距离和聚集性</strong></td>
<td>通常具有较高的聚集性，平均路径长度可能较长，尤其在K较小时。</td>
<td>短的平均路径长度和高聚集性，节点间连接较近。</td>
</tr>
<tr>
<td><strong>应用场景</strong></td>
<td>模式识别、推荐系统等，侧重特征相似性构建网络。</td>
<td>社交网络、生态系统、信息传播等，表现短距离特性。</td>
</tr>
</tbody>
</table>
</div>
<div class="table-container">
<table>
<thead>
<tr>
<th><strong>联系</strong></th>
<th><strong>K-近邻规则网络与小世界网络的联系</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>网络特性</strong></td>
<td>两者均具有较高的聚集性，但小世界网络实现更短的平均路径长度。 K-近邻网络在K值较大时可能表现出小世界特性。</td>
</tr>
<tr>
<td><strong>网络动态</strong></td>
<td>K-近邻规则网络可在引入随机重连机制后演变成小世界网络。</td>
</tr>
<tr>
<td><strong>相似性</strong></td>
<td>两者均为描述真实世界网络的简化模型，反映节点间的连接和特征相似性。</td>
</tr>
</tbody>
</table>
</div>
<h3 id="K-近邻规则网络的生成与可视化"><a href="#K-近邻规则网络的生成与可视化" class="headerlink" title="K-近邻规则网络的生成与可视化"></a>K-近邻规则网络的生成与可视化</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">regular_graph</span>(<span class="params">n,k</span>):</span><br><span class="line">    G = nx.Graph()</span><br><span class="line">    nodes = <span class="built_in">list</span>(<span class="built_in">range</span>(n))</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,k//<span class="number">2</span>+<span class="number">1</span>):</span><br><span class="line">        targets = nodes[j:] + nodes[<span class="number">0</span>:j]</span><br><span class="line">        G.add_edges_from(<span class="built_in">zip</span>(nodes,targets))</span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line">color_list = [<span class="string">&quot;red&quot;</span>,<span class="string">&quot;gray&quot;</span>]</span><br><span class="line"></span><br><span class="line">G = regular_graph(<span class="number">20</span>,<span class="number">4</span>)</span><br><span class="line">pos = nx.circular_layout(G)</span><br><span class="line">nx.draw(G,pos=pos,node_color=color_list[<span class="number">0</span>],edge_color=color_list[<span class="number">1</span>],with_labels=<span class="literal">True</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2020.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p>如图<img src="images/figure2020.png" alt=""></p>
<h2 id="规则网络、WS-小世界网络和随机网络的区别和联系"><a href="#规则网络、WS-小世界网络和随机网络的区别和联系" class="headerlink" title="规则网络、WS 小世界网络和随机网络的区别和联系"></a>规则网络、WS 小世界网络和随机网络的区别和联系</h2><div class="table-container">
<table>
<thead>
<tr>
<th>特征</th>
<th>规则网络</th>
<th>WS 小世界网络</th>
<th>随机网络</th>
</tr>
</thead>
<tbody>
<tr>
<td>结构</td>
<td>每个节点连接固定数量的邻居</td>
<td>通过规则网络重连部分边</td>
<td>边随机连接，没有固定结构</td>
</tr>
<tr>
<td>聚类系数</td>
<td>较高</td>
<td>较高</td>
<td>较低</td>
</tr>
<tr>
<td>平均路径长度</td>
<td>较长</td>
<td>较短</td>
<td>较短</td>
</tr>
<tr>
<td>连接方式</td>
<td>固定邻接</td>
<td>部分随机重连</td>
<td>完全随机</td>
</tr>
<tr>
<td>示例</td>
<td>网格状的社交网络</td>
<td>人际网络</td>
<td>互联网初期的网络</td>
</tr>
<tr>
<td>适用场景</td>
<td>有明确结构的系统</td>
<td>社交网络、传播模型</td>
<td>随机联系的系统</td>
</tr>
</tbody>
</table>
</div>
<h3 id="联系："><a href="#联系：" class="headerlink" title="联系："></a>联系：</h3><ul>
<li>三者都是网络模型，旨在描述节点和边之间的关系。</li>
<li>WS 小世界网络可以看作是规则网络和随机网络的结合，兼具高聚类和短路径的特点。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">color_list = [<span class="string">&quot;red&quot;</span>, <span class="string">&quot;gray&quot;</span>]</span><br><span class="line">n = <span class="number">20</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 绘制规则网络</span></span><br><span class="line">p = <span class="number">0</span></span><br><span class="line">G1 = nx.watts_strogatz_graph(n, k, p)</span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">pos1 = nx.circular_layout(G1)</span><br><span class="line">nx.draw(G1, pos1, node_size=<span class="number">100</span>, node_color=color_list[<span class="number">0</span>], edge_color=color_list[<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&quot;regular&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制WS小世界</span></span><br><span class="line">p=<span class="number">0.2</span></span><br><span class="line">G2 = nx.watts_strogatz_graph(n, k, p)</span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">pos2 = nx.circular_layout(G2)</span><br><span class="line">nx.draw(G2, pos2, node_size=<span class="number">100</span>, node_color=color_list[<span class="number">0</span>], edge_color=color_list[<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&quot;small-world&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制随机网络</span></span><br><span class="line">p=<span class="number">1.0</span></span><br><span class="line">G3 = nx.watts_strogatz_graph(n, k, p)</span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">pos3 = nx.circular_layout(G3)</span><br><span class="line">nx.draw(G3, pos3, node_size=<span class="number">100</span>, node_color=color_list[<span class="number">0</span>], edge_color=color_list[<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&quot;random&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2021.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2021.png" alt=""></p>
<h2 id="NW（Newman-Watts）小世界网络和-WS（Watts-Strogatz）小世界网络的区别与联系的对比表格："><a href="#NW（Newman-Watts）小世界网络和-WS（Watts-Strogatz）小世界网络的区别与联系的对比表格：" class="headerlink" title="NW（Newman-Watts）小世界网络和 WS（Watts-Strogatz）小世界网络的区别与联系的对比表格："></a>NW（Newman-Watts）小世界网络和 WS（Watts-Strogatz）小世界网络的区别与联系的对比表格：</h2><div class="table-container">
<table>
<thead>
<tr>
<th>比较项</th>
<th>NW小世界网络 (Newman-Watts)</th>
<th>WS小世界网络 (Watts-Strogatz)</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>提出者</strong></td>
<td>Mark Newman 和 Duncan Watts</td>
<td>Duncan Watts 和 Steven Strogatz</td>
</tr>
<tr>
<td><strong>构建方式</strong></td>
<td>从规则网络出发，在随机选择的节点之间添加新边</td>
<td>从规则网络出发，以一定概率重新连接每条边</td>
</tr>
<tr>
<td><strong>网络连接类型</strong></td>
<td>仅添加新边，保持原有连接不变</td>
<td>重新连接部分边，部分原始边会被替换</td>
</tr>
<tr>
<td><strong>参数控制</strong></td>
<td>添加新边的概率 p</td>
<td>重新连接的概率 p</td>
</tr>
<tr>
<td><strong>平均路径长度</strong></td>
<td>随着增加新边逐渐减小</td>
<td>随着重新连接概率的增加逐渐减小</td>
</tr>
<tr>
<td><strong>聚类系数</strong></td>
<td>通过增加新边通常能维持较高的聚类系数</td>
<td>随着 p 增加，聚类系数先保持较高值，后逐渐降低</td>
</tr>
<tr>
<td><strong>节点和边的变动性</strong></td>
<td>节点和原有边不变，仅添加新边</td>
<td>原有边可能重新连接</td>
</tr>
<tr>
<td><strong>适用性</strong></td>
<td>适合需要保持原有结构的网络</td>
<td>适合能接受一定程度边重新连接的网络</td>
</tr>
<tr>
<td><strong>应用场景</strong></td>
<td>网络扩展、社交网络等</td>
<td>神经网络、社会关系网络等</td>
</tr>
<tr>
<td><strong>代表特性</strong></td>
<td>保持规则网络特性并增加小世界特性</td>
<td>平衡规则网络与随机网络特性，实现小世界特性</td>
</tr>
</tbody>
</table>
</div>
<p>这些网络模型的共同点是都具有<strong>小世界特性</strong>，即<strong>较高的聚类系数</strong>和<strong>较短的平均路径长度</strong>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">color_list = [<span class="string">&quot;red&quot;</span>, <span class="string">&quot;gray&quot;</span>]</span><br><span class="line">n = <span class="number">20</span></span><br><span class="line">k = <span class="number">4</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>, <span class="number">4</span>))</span><br><span class="line"><span class="comment"># 绘制规则网络</span></span><br><span class="line">p = <span class="number">0</span></span><br><span class="line">G1 = nx.watts_strogatz_graph(n, k, p)</span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">pos1 = nx.circular_layout(G1)</span><br><span class="line">nx.draw(G1, pos1, node_size=<span class="number">100</span>, node_color=color_list[<span class="number">0</span>], edge_color=color_list[<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&quot;regular&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制NW小世界</span></span><br><span class="line">p=<span class="number">0.2</span></span><br><span class="line">G2 = nx.newman_watts_strogatz_graph(n, k, p)</span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">pos2 = nx.circular_layout(G2)</span><br><span class="line">nx.draw(G2, pos2, node_size=<span class="number">100</span>, node_color=color_list[<span class="number">0</span>], edge_color=color_list[<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&quot;small-world&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#绘制完全网络：加边概率为1</span></span><br><span class="line">G3 = nx.complete_graph(n)</span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">pos3 = nx.circular_layout(G3)</span><br><span class="line">nx.draw(G3, pos3, node_size=<span class="number">100</span>, node_color=color_list[<span class="number">0</span>], edge_color=color_list[<span class="number">1</span>])</span><br><span class="line">plt.title(<span class="string">&quot;complete&quot;</span>, fontsize=<span class="number">20</span>)</span><br><span class="line">Ga_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2022.png&#x27;</span></span><br><span class="line">plt.savefig(Ga_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2022.png" alt=""></p>
<h1 id="WS小世界网络度分布的情况"><a href="#WS小世界网络度分布的情况" class="headerlink" title="WS小世界网络度分布的情况"></a>WS小世界网络度分布的情况</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 定义求度分布的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_pdf</span>(<span class="params">G, k</span>):</span><br><span class="line">    N = <span class="built_in">len</span>(G.nodes())</span><br><span class="line"></span><br><span class="line">    Pk = []</span><br><span class="line">    <span class="keyword">for</span> ki <span class="keyword">in</span> k:</span><br><span class="line">        c = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">            <span class="keyword">if</span> G.degree(i) == ki:</span><br><span class="line">                c += <span class="number">1</span></span><br><span class="line">        Pk.append(c / N)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Pk</span><br><span class="line"><span class="comment"># 以N＝1000，K＝6的WS模型的数值模拟结果为例</span></span><br><span class="line">N = <span class="number">1000</span></span><br><span class="line">K = <span class="number">6</span></span><br><span class="line">samples = <span class="number">100</span>  <span class="comment"># 统计平均次数</span></span><br><span class="line">p_rew = [<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.4</span>,<span class="number">0.6</span>,<span class="number">1.0</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">symbols = [<span class="string">&quot;ro-&quot;</span>, <span class="string">&quot;bs-&quot;</span>, <span class="string">&quot;g*-&quot;</span>, <span class="string">&quot;yv-&quot;</span>, <span class="string">&quot;k^-&quot;</span>]</span><br><span class="line"><span class="comment"># 为了便于统计平均，指定区间[1,16]</span></span><br><span class="line">kmin, kmax = <span class="number">1</span>, <span class="number">16</span></span><br><span class="line">x = <span class="built_in">list</span>(<span class="built_in">range</span>(kmin, kmax + <span class="number">1</span>))</span><br><span class="line">c = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> p_rew:</span><br><span class="line">    s = np.zeros(kmax - kmin + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">        G = nx.watts_strogatz_graph(N, K, p)</span><br><span class="line">        y = get_pdf(G, x)</span><br><span class="line">        s += np.array(y)</span><br><span class="line"></span><br><span class="line">    s = <span class="built_in">list</span>(s)</span><br><span class="line">    </span><br><span class="line">    new_x = []</span><br><span class="line">    new_y = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">        <span class="keyword">if</span> s[i] != <span class="number">0</span>:</span><br><span class="line">            new_x.append(x[i])</span><br><span class="line">            new_y.append(s[i])</span><br><span class="line"></span><br><span class="line">    plt.plot(new_x, np.array(new_y) / samples, symbols[c], label=<span class="string">&#x27;$p_&#123;rew&#125; = $&#x27;</span> + <span class="built_in">str</span>(p))</span><br><span class="line">    c += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="number">0</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$p_k$&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.xlim([kmin, kmax])</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2022.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2023.png" alt=""></p>
<h1 id="NW小世界网络度分布的情况"><a href="#NW小世界网络度分布的情况" class="headerlink" title="NW小世界网络度分布的情况"></a>NW小世界网络度分布的情况</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="comment"># 定义求度分布的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_pdf</span>(<span class="params">G, k</span>):</span><br><span class="line">    N = <span class="built_in">len</span>(G.nodes())</span><br><span class="line"></span><br><span class="line">    Pk = []</span><br><span class="line">    <span class="keyword">for</span> ki <span class="keyword">in</span> k:</span><br><span class="line">        c = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">            <span class="keyword">if</span> G.degree(i) == ki:</span><br><span class="line">                c += <span class="number">1</span></span><br><span class="line">        Pk.append(c / N)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Pk</span><br><span class="line"><span class="comment"># 以N＝1000，K＝6的NW模型的数值模拟结果为例</span></span><br><span class="line">N = <span class="number">1000</span></span><br><span class="line">K = <span class="number">6</span></span><br><span class="line">samples = <span class="number">100</span>  <span class="comment"># 统计平均次数</span></span><br><span class="line">p_rew = [<span class="number">0.1</span>,<span class="number">0.2</span>,<span class="number">0.4</span>,<span class="number">0.6</span>,<span class="number">1.0</span>]</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">6</span>))</span><br><span class="line">symbols = [<span class="string">&quot;ro-&quot;</span>, <span class="string">&quot;bs-&quot;</span>, <span class="string">&quot;g*-&quot;</span>, <span class="string">&quot;yv-&quot;</span>, <span class="string">&quot;k^-&quot;</span>]</span><br><span class="line"><span class="comment"># 为了便于统计平均，指定区间[1,16]</span></span><br><span class="line">kmin, kmax = <span class="number">1</span>, <span class="number">16</span></span><br><span class="line">x = <span class="built_in">list</span>(<span class="built_in">range</span>(kmin, kmax + <span class="number">1</span>))</span><br><span class="line">c = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> p_rew:</span><br><span class="line">    s = np.zeros(kmax - kmin + <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">        G = nx.newman_watts_strogatz_graph(N, K, p)</span><br><span class="line">        y = get_pdf(G, x)</span><br><span class="line">        s += np.array(y)</span><br><span class="line"></span><br><span class="line">    s = <span class="built_in">list</span>(s)</span><br><span class="line">    </span><br><span class="line">    new_x = []</span><br><span class="line">    new_y = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x)):</span><br><span class="line">        <span class="keyword">if</span> s[i] != <span class="number">0</span>:</span><br><span class="line">            new_x.append(x[i])</span><br><span class="line">            new_y.append(s[i])</span><br><span class="line"></span><br><span class="line">    plt.plot(new_x, np.array(new_y) / samples, symbols[c], label=<span class="string">&#x27;$p_&#123;rew&#125; = $&#x27;</span> + <span class="built_in">str</span>(p))</span><br><span class="line">    c += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.legend(loc=<span class="number">0</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$p_k$&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.xlim([kmin, kmax])</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2024.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2024.png" alt=""></p>
<h1 id="WS小世界网络的“小世界”与“高集聚”特性"><a href="#WS小世界网络的“小世界”与“高集聚”特性" class="headerlink" title="WS小世界网络的“小世界”与“高集聚”特性"></a>WS小世界网络的“小世界”与“高集聚”特性</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">N,K = <span class="number">1000</span>,<span class="number">10</span></span><br><span class="line">samples = <span class="number">10</span></span><br><span class="line">p_rew = np.logspace(<span class="number">0</span>,<span class="number">4</span>,<span class="number">10</span>)/<span class="number">10000</span></span><br><span class="line"><span class="built_in">print</span>(p_rew)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 平均距离与平均集聚系数</span></span><br><span class="line">C = []</span><br><span class="line">CT = []  <span class="comment"># 理论近似值：&#123;[3(K-2)]/[4(K-1)]&#125;*(1-p)^3</span></span><br><span class="line">L = []</span><br><span class="line">sigma = []</span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> p_rew:</span><br><span class="line">    s1 = <span class="number">0</span></span><br><span class="line">    s2 = <span class="number">0</span></span><br><span class="line">    s3 = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(samples):</span><br><span class="line">        <span class="comment"># 为了防止在计算平均距离时报错：最好改用生成连通WS小世界网络函数connected_watts_strogatz_graph()</span></span><br><span class="line">        G = nx.connected_watts_strogatz_graph(N, K, p, tries=<span class="number">100</span>)</span><br><span class="line">        G_random = nx.gnm_random_graph(N, N * K / <span class="number">2</span>)</span><br><span class="line">        <span class="keyword">while</span> <span class="keyword">not</span> nx.is_connected(G_random):</span><br><span class="line">            G_random = nx.gnm_random_graph(N, N * K / <span class="number">2</span>)</span><br><span class="line">        c = nx.average_clustering(G)</span><br><span class="line">        cr = nx.average_clustering(G_random)</span><br><span class="line">        l = nx.average_shortest_path_length(G)</span><br><span class="line">        lr = nx.average_shortest_path_length(G_random)</span><br><span class="line">        s1 += c</span><br><span class="line">        s2 += l</span><br><span class="line">        s3 += (c / cr) / (l / lr)</span><br><span class="line"></span><br><span class="line">    ct = (<span class="number">3</span> * (K - <span class="number">2</span>) / (<span class="number">4</span> * (K - <span class="number">1</span>))) * ((<span class="number">1</span> - p) ** <span class="number">3</span>)</span><br><span class="line">    CT.append(ct)</span><br><span class="line">    C.append(s1 / samples)</span><br><span class="line">    L.append(s2 / samples)</span><br><span class="line">    sigma.append(s3 / samples)</span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">4</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line">plt.plot(p_rew, C, <span class="string">&#x27;ro&#x27;</span>, label=<span class="string">&#x27;$C(p)$&#x27;</span>)</span><br><span class="line">plt.plot(p_rew, CT, <span class="string">&#x27;r-&#x27;</span>, label=<span class="string">&#x27;$CT(p)$&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$p$&quot;</span>)</span><br><span class="line">plt.xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line">plt.plot(p_rew, L, <span class="string">&#x27;bs&#x27;</span>, label=<span class="string">&#x27;$L(p)$&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>, fontsize=<span class="number">14</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$p$&quot;</span>)</span><br><span class="line">plt.xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line"></span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2025.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><img src="images/figure2029.png" alt=""></p>
<h1 id="真实网络的集聚系数与度之间的依赖关系（以科学合作网络为例）"><a href="#真实网络的集聚系数与度之间的依赖关系（以科学合作网络为例）" class="headerlink" title="真实网络的集聚系数与度之间的依赖关系（以科学合作网络为例）"></a>真实网络的集聚系数与度之间的依赖关系（以科学合作网络为例）</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">C_vs_k</span>(<span class="params">G</span>):</span><br><span class="line">    kilist = [G.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes()]</span><br><span class="line">    all_C = &#123;i:nx.clustering(G, i) <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes()&#125;</span><br><span class="line">    all_k = <span class="built_in">list</span>(<span class="built_in">set</span>(kilist))</span><br><span class="line"></span><br><span class="line">    C_k = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">sorted</span>(all_k):</span><br><span class="line">        s = <span class="number">0</span></span><br><span class="line">        j = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">            <span class="keyword">if</span> G.degree(i) == k:</span><br><span class="line">                j = j + <span class="number">1</span></span><br><span class="line">                s = s + all_C[i]</span><br><span class="line">        avc_k = s / j</span><br><span class="line">        C_k[k] = avc_k</span><br><span class="line">    <span class="keyword">return</span> C_k</span><br><span class="line"></span><br><span class="line">df = pd.read_csv(<span class="string">&quot;citation.csv&quot;</span>)</span><br><span class="line">G = nx.from_pandas_edgelist(df,<span class="string">&quot;source&quot;</span>,<span class="string">&quot;target&quot;</span>,create_using=nx.Graph())</span><br><span class="line"><span class="built_in">len</span>(G.nodes())</span><br><span class="line">C_k = C_vs_k(G)</span><br><span class="line">avC = nx.average_clustering(G)</span><br><span class="line"><span class="built_in">print</span>(avC)<span class="comment">#0.4593321340705977</span></span><br><span class="line">x = np.linspace(<span class="number">1</span>,<span class="number">10000</span>,<span class="number">10000</span>)</span><br><span class="line">y = [avC]*<span class="number">10000</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">4</span>))</span><br><span class="line">plt.plot(C_k.keys(),C_k.values(),<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.plot(x,y,<span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;k&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;C(k)&quot;</span>)</span><br><span class="line">plt.xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.xlim(<span class="number">1</span>,<span class="number">10000</span>)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2027.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2027.png" alt=""></p>
<h1 id="道路网络和航空网络的度分布情况以及航空网络的粗略拟合"><a href="#道路网络和航空网络的度分布情况以及航空网络的粗略拟合" class="headerlink" title="道路网络和航空网络的度分布情况以及航空网络的粗略拟合"></a>道路网络和航空网络的度分布情况以及航空网络的粗略拟合</h1><p>代码如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">from</span> scipy <span class="keyword">import</span> optimize</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载数据</span></span><br><span class="line">df1 = pd.read_csv(<span class="string">&quot;euroroad.csv&quot;</span>)</span><br><span class="line">G1 = nx.from_pandas_edgelist(df1,<span class="string">&quot;source&quot;</span>,<span class="string">&quot;target&quot;</span>,create_using=nx.Graph())</span><br><span class="line"></span><br><span class="line">df2 = pd.read_csv(<span class="string">&quot;openflights.csv&quot;</span>)</span><br><span class="line">G2 = nx.from_pandas_edgelist(df2,<span class="string">&quot;source&quot;</span>,<span class="string">&quot;target&quot;</span>,create_using=nx.Graph())</span><br><span class="line"></span><br><span class="line"><span class="comment">#输出节点个数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">len</span>(G1.nodes()),<span class="built_in">len</span>(G2.nodes()))<span class="comment">#1174 3425</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义求度分布的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_pdf</span>(<span class="params">G</span>):</span><br><span class="line">    all_k = [G.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes()]</span><br><span class="line">    k = <span class="built_in">list</span>(<span class="built_in">set</span>(all_k))</span><br><span class="line">    N = <span class="built_in">len</span>(G.nodes())</span><br><span class="line">    Pk = []</span><br><span class="line">    <span class="keyword">for</span> ki <span class="keyword">in</span> <span class="built_in">sorted</span>(k):</span><br><span class="line">        c = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">            <span class="keyword">if</span> G.degree(i) == ki:</span><br><span class="line">                c += <span class="number">1</span></span><br><span class="line">        Pk.append(c/N)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sorted</span>(k),Pk</span><br><span class="line"></span><br><span class="line">deg1 = [G1.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G1.nodes()]</span><br><span class="line">deg2 = [G2.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G2.nodes()]</span><br><span class="line">k1,Pk1 = get_pdf(G1)</span><br><span class="line">k2,Pk2 = get_pdf(G2)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">18</span>,<span class="number">6</span>))</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">131</span>)</span><br><span class="line">plt.plot(k1,Pk1,<span class="string">&quot;ro-&quot;</span>,label=<span class="string">&quot;euroroad&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$P(k)$&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.subplot(<span class="number">132</span>)</span><br><span class="line">plt.plot(k2,Pk2,<span class="string">&quot;ro&quot;</span>,label=<span class="string">&quot;openflights&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$P(k)$&quot;</span>)</span><br><span class="line">plt.ylim([<span class="number">1e-4</span>,<span class="number">1</span>])</span><br><span class="line">plt.xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#拟合航空网络</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit_list</span>(<span class="params">x,a,b</span>):</span><br><span class="line">    <span class="keyword">return</span> a * x + b</span><br><span class="line"></span><br><span class="line">x = np.log10(np.array(k2))</span><br><span class="line">y = np.log10(np.array(Pk2))</span><br><span class="line">kmin2, kmax2 = <span class="built_in">min</span>(deg2), <span class="built_in">max</span>(deg2)</span><br><span class="line">a,b = optimize.curve_fit(fit_list,x,y)[<span class="number">0</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;斜率：&quot;</span>,a)<span class="comment">#斜率： -1.366312420298909</span></span><br><span class="line"></span><br><span class="line">x1 = np.arange(kmin2, kmax2, <span class="number">0.01</span>)</span><br><span class="line">y1 = (<span class="number">10</span>**b) * (x1**a)</span><br><span class="line">plt.subplot(<span class="number">133</span>)</span><br><span class="line">plt.plot(k2, Pk2, <span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.plot(x1, y1, <span class="string">&#x27;b-&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$p_k$&quot;</span>)</span><br><span class="line">plt.ylim([<span class="number">1e-4</span>,<span class="number">1</span>])</span><br><span class="line">plt.xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line"></span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2033.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2033.png" alt=""></p>
<h1 id="航空网络精度拟合"><a href="#航空网络精度拟合" class="headerlink" title="航空网络精度拟合"></a>航空网络精度拟合</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> powerlaw</span><br><span class="line"></span><br><span class="line">df2 = pd.read_csv(<span class="string">&quot;openflights.csv&quot;</span>)</span><br><span class="line">G2 = nx.from_pandas_edgelist(df2,<span class="string">&quot;source&quot;</span>,<span class="string">&quot;target&quot;</span>,create_using=nx.Graph())</span><br><span class="line"></span><br><span class="line">date = [G2.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G2.nodes()]</span><br><span class="line"><span class="built_in">print</span>(date)</span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">[18, 21, 7, 16, 14, 53, 190, 7, 1, 3, 9, 10, 39, 113, 67, 9, 10, 4, 28, 9, 1, 1, 1, 2, 23, 6, 1, 57, 5, 2, 1, 4, 3, 3, 21, 2, 15, 30, 16, 32, 20, 16, 9, 74, 19, 26, 18, 1, 2, 19, 137, 49, 73, 101, 83, 55, 4, 85, 1, 2, 124, 4, 4, 2, 2, 2, 3, 1, 3, 30, 4, 2, 6, 1, 2, 7, 105, 8, 2, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 78, 2, 1, 5, 1, 2, 41, 3, 8, 2, 2, 2, 5, 1, 2, 1, 4, 3, 3, 2, 45, 30, 2, 12, 3, 92, 18, 11, 10, 3, 50, 4, 9, 4, 12, 6, 2, 206, 61, 2, 1, 4, 3, 15, 3, 1, 44, 7, 163, 7, 12, 8, 5, 21, 165, 2, 2, 4, 1, 10, 3, 8, 96, 4, 3, 3, 3, 2, 3, 3, 2, 4, 20, 11, 11, 2, 2, 13, 188, 111, 8, 67, 122, 125, 20, 38, 72, 134, 32, 57, 103, 112, 20, 38, 15, 20, 29, 54, 24, 2, 5, 18, 147, 12, 192, 87, 33, 110, 24, 21, 51, 11, 21, 217, 2, 2, 1, 1, 1, 2, 1, 97, 4, 23, 8, 33, 69, 10, 6, 3, 102, 6, 1, 1, 5, 26, 11, 7, 248, 12, 12, 93, 80, 64, 153, 93, 5, 78, 20, 98, 47, 38, 16, 127, 25, 3, 8, 6, 19, 4, 6, 3, 9, 3, 6, 6, 23, 13, 4, 11, 30, 9, 34, 7, 7, 2, 15, 86, 150, 89, 108, 10, 55, 29, 58, 95, 55, 54, 41, 52, 70, 18, 59, 12, 30, 38, 33, 28, 15, 38, 44, 207, 154, 2, 85, 41, 86, 19, 47, 66, 19, 19, 14, 13, 47, 62, 33, 72, 1, 19, 6, 37, 35, 133, 9, 6, 5, 10, 48, 4, 2, 55, 35, 54, 8, 3, 18, 13, 30, 7, 4, 2, 10, 41, 4, 18, 4, 16, 14, 10, 2, 76, 7, 5, 7, 133, 149, 82, 79, 5, 1, 2, 2, 4, 74, 3, 19, 19, 7, 5, 4, 34, 1, 37, 11, 55, 1, 1, 32, 2, 4, 2, 1, 2, 188, 41, 162, 138, 48, 38, 5, 11, 26, 18, 60, 5, 95, 10, 7, 4, 6, 2, 1, 1, 7, 81, 32, 10, 9, 41, 35, 22, 22, 32, 21, 33, 13, 2, 6, 8, 1, 9, 5, 1, 21, 5, 38, 5, 5, 6, 9, 8, 5, 5, 4, 98, 4, 15, 38, 4, 65, 66, 26, 17, 23, 117, 81, 67, 10, 104, 51, 52, 49, 81, 23, 35, 43, 41, 77, 38, 240, 39, 11, 50, 42, 144, 89, 64, 162, 5, 62, 59, 11, 11, 30, 4, 5, 28, 172, 103, 148, 113, 90, 39, 94, 65, 14, 49, 51, 8, 5, 13, 55, 37, 153, 22, 61, 73, 139, 23, 78, 16, 28, 21, 29, 27, 159, 5, 32, 19, 29, 31, 18, 244, 89, 52, 33, 3, 24, 4, 2, 2, 2, 2, 5, 2, 1, 2, 4, 2, 2, 2, 2, 3, 3, 29, 2, 2, 3, 3, 2, 3, 3, 2, 2, 2, 2, 3, 3, 2, 3, 3, 4, 3, 2, 2, 3, 1, 2, 3, 2, 2, 15, 1, 2, 8, 2, 2, 2, 1, 1, 3, 2, 8, 2, 2, 3, 9, 9, 4, 29, 9, 30, 14, 1, 8, 3, 1, 8, 2, 36, 2, 2, 64, 38, 1, 42, 46, 1, 43, 104, 1, 1, 1, 1, 6, 6, 1, 5, 3, 144, 2, 7, 20, 6, 5, 4, 41, 44, 12, 2, 10, 24, 29, 4, 3, 3, 4, 3, 3, 11, 2, 10, 2, 3, 4, 7, 4, 3, 2, 2, 2, 3, 3, 4, 6, 1, 23, 20, 2, 15, 11, 10, 23, 2, 1, 83, 1, 18, 41, 85, 12, 32, 9, 40, 13, 7, 9, 2, 22, 12, 9, 8, 17, 8, 7, 3, 4, 5, 6, 4, 5, 3, 5, 4, 8, 6, 3, 2, 69, 25, 122, 1, 3, 1, 2, 1, 1, 35, 4, 31, 2, 2, 4, 8, 1, 2, 3, 4, 2, 5, 33, 68, 4, 33, 13, 37, 19, 7, 2, 1, 1, 3, 74, 1, 3, 14, 3, 34, 2, 2, 7, 9, 2, 1, 1, 4, 6, 1, 2, 2, 3, 4, 2, 2, 2, 2, 3, 2, 3, 3, 2, 2, 2, 2, 2, 5, 3, 2, 4, 3, 4, 16, 3, 6, 4, 6, 3, 3, 2, 2, 3, 2, 3, 4, 2, 2, 3, 4, 2, 3, 2, 4, 3, 1, 2, 3, 2, 4, 1, 2, 2, 2, 47, 9, 6, 3, 141, 19, 18, 7, 21, 13, 31, 45, 19, 22, 44, 236, 12, 80, 2, 15, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 4, 2, 1, 1, 3, 4, 1, 1, 2, 2, 2, 6, 20, 22, 10, 1, 2, 3, 2, 3, 26, 1, 2, 2, 17, 4, 5, 4, 1, 4, 69, 2, 2, 3, 4, 3, 1, 3, 1, 2, 8, 2, 1, 1, 10, 45, 21, 4, 29, 8, 3, 4, 4, 6, 5, 3, 12, 7, 2, 1, 5, 1, 3, 7, 7, 6, 4, 11, 8, 3, 6, 2, 4, 1, 1, 1, 1, 2, 12, 58, 25, 7, 21, 5, 3, 3, 4, 1, 2, 2, 1, 8, 9, 12, 3, 5, 37, 13, 6, 12, 4, 8, 11, 9, 47, 4, 10, 14, 20, 6, 13, 4, 131, 9, 16, 17, 14, 135, 39, 5, 1, 70, 12, 32, 6, 103, 3, 3, 4, 19, 1, 1, 1, 4, 49, 1, 12, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 5, 19, 16, 1, 1, 1, 2, 5, 2, 2, 1, 1, 2, 3, 2, 2, 5, 3, 8, 1, 2, 3, 3, 5, 4, 7, 4, 6, 5, 5, 2, 2, 3, 21, 1, 2, 2, 2, 8, 1, 2, 8, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 2, 1, 2, 3, 1, 5, 1, 1, 1, 4, 1, 1, 1, 1, 25, 59, 62, 68, 6, 14, 72, 6, 1, 1, 1, 3, 90, 6, 18, 48, 58, 41, 1, 3, 1, 10, 41, 2, 118, 2, 2, 1, 81, 2, 153, 147, 3, 4, 2, 1, 3, 2, 1, 3, 4, 4, 5, 8, 8, 4, 2, 2, 39, 7, 20, 1, 3, 3, 1, 1, 1, 2, 4, 3, 4, 9, 1, 86, 56, 1, 123, 2, 41, 18, 13, 61, 1, 2, 4, 5, 8, 7, 3, 1, 17, 1, 2, 1, 2, 3, 123, 26, 5, 5, 6, 26, 1, 11, 32, 13, 4, 5, 26, 9, 32, 1, 5, 8, 2, 11, 4, 9, 5, 4, 1, 20, 1, 1, 5, 9, 9, 1, 23, 91, 29, 1, 26, 61, 3, 3, 91, 50, 32, 1, 6, 5, 2, 8, 127, 34, 42, 8, 6, 8, 26, 37, 5, 19, 3, 6, 18, 20, 10, 8, 47, 6, 30, 10, 16, 20, 58, 19, 18, 57, 94, 1, 2, 4, 10, 12, 72, 10, 11, 21, 6, 20, 56, 2, 33, 2, 16, 170, 17, 2, 4, 1, 19, 4, 2, 9, 4, 169, 5, 35, 9, 17, 1, 29, 43, 3, 14, 30, 2, 5, 23, 40, 3, 20, 19, 1, 5, 19, 12, 39, 13, 2, 23, 105, 92, 29, 6, 4, 12, 5, 2, 35, 11, 2, 4, 37, 3, 1, 11, 33, 3, 13, 10, 11, 9, 2, 1, 1, 6, 3, 3, 20, 52, 49, 12, 1, 1, 8, 2, 3, 3, 7, 5, 2, 10, 7, 3, 11, 21, 22, 15, 6, 10, 17, 5, 7, 14, 1, 3, 32, 9, 5, 30, 1, 6, 4, 1, 18, 16, 1, 2, 5, 3, 9, 1, 8, 10, 5, 63, 8, 4, 35, 1, 1, 3, 22, 36, 16, 3, 11, 5, 11, 7, 1, 6, 24, 6, 4, 51, 12, 56, 49, 30, 37, 12, 2, 18, 16, 18, 6, 8, 2, 3, 1, 4, 3, 2, 4, 5, 6, 3, 2, 5, 5, 57, 55, 96, 11, 8, 26, 28, 25, 30, 15, 30, 17, 9, 7, 11, 47, 8, 6, 15, 77, 4, 38, 57, 5, 2, 2, 75, 5, 4, 17, 38, 8, 46, 7, 9, 9, 20, 9, 13, 5, 6, 31, 4, 4, 6, 5, 2, 2, 5, 11, 2, 4, 1, 2, 3, 7, 3, 2, 3, 3, 1, 3, 3, 1, 13, 6, 6, 13, 5, 2, 4, 1, 1, 1, 2, 1, 2, 2, 1, 8, 7, 51, 1, 2, 3, 19, 8, 8, 1, 4, 19, 6, 1, 6, 18, 1, 1, 1, 3, 2, 3, 1, 7, 8, 1, 4, 1, 26, 1, 1, 2, 3, 3, 2, 2, 8, 9, 5, 3, 7, 1, 5, 2, 10, 12, 6, 2, 7, 7, 5, 1, 1, 1, 5, 4, 3, 2, 1, 2, 1, 1, 3, 1, 1, 2, 4, 2, 3, 4, 2, 3, 1, 1, 1, 23, 4, 4, 5, 4, 32, 13, 1, 25, 2, 1, 8, 14, 11, 1, 7, 1, 1, 24, 1, 5, 1, 75, 9, 1, 23, 45, 4, 12, 4, 6, 7, 39, 13, 19, 17, 16, 22, 27, 9, 9, 9, 21, 5, 22, 9, 1, 10, 7, 9, 1, 19, 2, 2, 10, 7, 5, 13, 1, 4, 3, 6, 7, 24, 6, 4, 4, 3, 12, 3, 1, 1, 4, 6, 2, 3, 2, 1, 6, 5, 1, 1, 2, 4, 1, 1, 1, 5, 2, 2, 3, 2, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 29, 2, 9, 12, 7, 14, 20, 4, 5, 14, 3, 5, 48, 5, 6, 13, 3, 10, 3, 7, 8, 4, 9, 26, 4, 26, 3, 17, 2, 1, 4, 2, 5, 3, 1, 1, 1, 1, 3, 1, 1, 2, 2, 3, 1, 1, 1, 3, 3, 1, 2, 2, 1, 1, 1, 2, 1, 4, 1, 2, 2, 1, 10, 1, 4, 2, 1, 2, 2, 9, 4, 5, 1, 7, 2, 1, 5, 7, 5, 2, 2, 2, 1, 2, 7, 8, 1, 22, 3, 3, 2, 15, 9, 3, 2, 17, 2, 2, 2, 2, 6, 3, 8, 3, 1, 1, 2, 2, 1, 1, 4, 1, 1, 2, 1, 1, 1, 15, 13, 6, 1, 2, 1, 1, 34, 2, 1, 41, 1, 3, 1, 1, 1, 28, 10, 2, 13, 1, 10, 31, 4, 8, 2, 8, 37, 23, 9, 1, 7, 1, 8, 18, 4, 12, 11, 6, 9, 1, 1, 12, 57, 4, 11, 34, 1, 11, 8, 5, 1, 1, 2, 1, 4, 2, 2, 3, 40, 38, 14, 15, 9, 4, 27, 5, 12, 5, 3, 8, 11, 7, 8, 5, 13, 4, 5, 10, 5, 13, 25, 1, 1, 15, 8, 6, 12, 7, 3, 11, 11, 5, 57, 11, 2, 5, 15, 2, 1, 1, 2, 1, 8, 2, 1, 1, 48, 3, 4, 10, 2, 3, 5, 23, 2, 3, 3, 7, 4, 4, 5, 4, 20, 2, 3, 2, 7, 7, 3, 8, 6, 2, 3, 6, 9, 8, 18, 3, 3, 2, 2, 2, 3, 2, 3, 4, 2, 7, 3, 2, 3, 2, 1, 1, 1, 4, 7, 7, 2, 2, 2, 5, 4, 7, 8, 11, 9, 18, 2, 10, 11, 5, 2, 14, 3, 9, 2, 4, 9, 9, 4, 6, 7, 1, 6, 7, 4, 3, 3, 13, 6, 5, 4, 4, 4, 8, 15, 4, 9, 3, 2, 2, 35, 4, 8, 3, 9, 4, 4, 9, 7, 4, 1, 2, 4, 3, 3, 3, 4, 3, 3, 5, 3, 2, 1, 7, 1, 7, 6, 3, 1, 23, 10, 15, 1, 5, 2, 7, 3, 7, 1, 2, 9, 5, 1, 13, 6, 7, 10, 2, 1, 1, 1, 2, 1, 1, 13, 1, 4, 7, 1, 1, 8, 13, 2, 2, 2, 4, 1, 20, 1, 3, 1, 4, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 5, 1, 2, 2, 1, 18, 1, 1, 1, 2, 3, 2, 4, 1, 1, 1, 3, 3, 1, 4, 2, 2, 2, 2, 4, 3, 4, 1, 2, 1, 1, 2, 2, 2, 2, 2, 6, 1, 2, 1, 3, 3, 3, 2, 3, 2, 17, 10, 5, 2, 6, 2, 3, 3, 2, 6, 7, 4, 3, 1, 1, 6, 3, 35, 8, 2, 5, 1, 11, 15, 1, 10, 6, 2, 17, 7, 1, 3, 1, 1, 1, 7, 4, 6, 30, 26, 9, 17, 6, 22, 14, 13, 2, 4, 3, 7, 3, 20, 43, 17, 25, 9, 21, 6, 12, 10, 9, 7, 8, 1, 2, 1, 5, 2, 1, 4, 1, 1, 3, 6, 6, 5, 1, 1, 1, 8, 4, 4, 1, 2, 2, 3, 1, 1, 1, 3, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 2, 2, 2, 2, 3, 3, 2, 2, 3, 2, 15, 3, 2, 4, 5, 1, 1, 6, 1, 3, 2, 1, 3, 2, 3, 28, 2, 2, 2, 3, 14, 2, 3, 4, 2, 1, 2, 2, 6, 2, 1, 2, 4, 1, 9, 2, 1, 45, 50, 5, 2, 1, 12, 21, 21, 1, 2, 2, 1, 1, 3, 4, 3, 3, 1, 7, 4, 1, 18, 11, 4, 9, 1, 6, 4, 1, 83, 63, 47, 85, 38, 21, 17, 8, 50, 31, 3, 50, 4, 19, 11, 26, 2, 4, 3, 3, 5, 16, 10, 9, 1, 11, 5, 4, 3, 3, 5, 3, 8, 3, 2, 6, 2, 4, 3, 2, 5, 12, 17, 1, 1, 3, 5, 9, 8, 9, 4, 6, 1, 18, 31, 32, 1, 3, 5, 2, 1, 3, 2, 5, 1, 2, 2, 4, 1, 3, 6, 3, 5, 5, 3, 10, 8, 1, 2, 9, 2, 2, 11, 5, 3, 2, 2, 4, 2, 4, 4, 2, 1, 3, 1, 5, 3, 6, 2, 2, 2, 2, 2, 6, 3, 8, 5, 1, 5, 1, 1, 1, 1, 9, 2, 1, 8, 9, 5, 2, 3, 2, 5, 2, 2, 7, 2, 2, 2, 2, 3, 2, 8, 5, 3, 2, 2, 1, 2, 2, 1, 1, 2, 2, 3, 2, 2, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 3, 4, 2, 1, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 9, 1, 1, 1, 4, 4, 4, 3, 3, 2, 3, 1, 3, 3, 3, 1, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 7, 16, 2, 2, 2, 3, 7, 2, 1, 12, 1, 1, 2, 2, 4, 8, 1, 4, 10, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 5, 5, 3, 3, 2, 5, 3, 1, 3, 2, 2, 1, 1, 1, 19, 2, 8, 1, 1, 1, 3, 2, 4, 5, 15, 3, 4, 1, 10, 1, 8, 1, 2, 2, 9, 2, 5, 4, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 7, 3, 1, 2, 1, 3, 2, 3, 5, 6, 2, 3, 4, 3, 6, 2, 2, 2, 5, 1, 2, 1, 1, 2, 4, 1, 3, 3, 4, 5, 5, 5, 2, 3, 2, 4, 3, 2, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 7, 2, 4, 3, 3, 3, 3, 4, 9, 18, 2, 2, 2, 3, 1, 3, 2, 2, 2, 2, 1, 2, 2, 3, 2, 2, 1, 2, 1, 1, 1, 1, 5, 3, 2, 1, 2, 2, 2, 1, 2, 2, 40, 1, 1, 7, 6, 4, 3, 2, 7, 3, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 13, 29, 15, 16, 3, 1, 5, 2, 3, 4, 3, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 2, 2, 2, 2, 2, 3, 1, 3, 1, 3, 1, 2, 1, 3, 6, 4, 5, 4, 3, 2, 2, 3, 2, 3, 1, 8, 2, 6, 2, 1, 3, 1, 2, 1, 1, 2, 2, 1, 2, 3, 1, 4, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 4, 3, 2, 1, 5, 2, 2, 10, 4, 2, 5, 3, 2, 3, 1, 3, 2, 2, 3, 3, 3, 3, 1, 9, 2, 2, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 3, 3, 2, 1, 9, 3, 5, 1, 3, 1, 1, 5, 1, 1, 3, 2, 4, 1, 1, 3, 3, 4, 5, 2, 3, 3, 2, 1, 1, 2, 2, 3, 3, 2, 1, 2, 1, 2, 1, 1, 3, 3, 1, 1, 2, 3, 1, 1, 1, 1, 4, 3, 5, 3, 4, 9, 1, 1, 1, 2, 1, 2, 2, 3, 2, 1, 1, 1, 4, 5, 2, 3, 3, 2, 2, 2, 3, 3, 2, 3, 2, 4, 5, 8, 4, 3, 3, 3, 2, 1, 3, 3, 3, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 4, 1, 3, 3, 2, 2, 3, 2, 2, 1, 3, 6, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 3, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 3, 3, 2, 2, 2, 2, 4, 9, 2, 3, 3, 2, 2, 2, 1, 2, 3, 2, 2, 1, 4, 2, 2, 4, 5, 4, 1, 3, 2, 2, 2, 1, 1, 1, 2, 1, 8, 6, 1, 3, 2, 3, 2, 6, 1, 2, 1, 2, 1, 4, 1, 1, 1, 2, 2, 2, 3, 1, 5, 1, 1, 1, 1, 2, 1, 2, 1, 2, 4, 4, 1, 2, 1, 2, 2, 5, 3, 2, 8, 2, 1, 2, 2, 1, 3, 2, 1, 2, 1, 3, 2, 2, 2, 11, 1, 1, 5, 3, 4, 4, 6, 3, 2, 2, 4, 2, 3, 1, 1, 1, 1, 1, 1, 6, 1, 3, 1, 3, 2, 1, 1, 1, 1, 3, 2, 2, 2, 1, 2, 4, 1, 2, 1, 6, 2, 2, 2, 1, 1, 3, 2, 2, 3, 3, 4, 2, 1, 2, 2, 2, 2, 2, 1, 1, 3, 2, 2, 1, 2, 2, 12, 8, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 3, 3, 1, 6, 4, 2, 9, 2, 1, 1, 3, 1, 2, 1, 2, 1, 2, 1, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 3, 3, 2, 1, 1, 1, 1, 1, 1, 3, 3, 1, 3, 2, 1, 1, 2, 2, 2, 2, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 2, 1, 3, 1, 2, 3, 2, 2, 1, 2, 1, 1, 1, 2, 3, 3, 4, 4, 3, 3, 2, 2, 7, 4, 3, 4, 5, 6, 3, 2, 2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 3, 3, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 2, 1, 3, 1, 1, 9, 3, 3, 8, 4, 6, 3, 6, 4, 1, 4, 5, 5, 6, 3, 5, 5, 3, 5, 1, 2, 4, 3, 2, 3, 3, 3, 1, 2, 4, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 2, 3, 4, 4, 2, 3, 2, 4, 5, 2, 2, 3, 3, 2, 1, 3, 3, 3, 2, 6, 3, 5, 1, 7, 1, 1, 1, 2, 1, 1, 1, 2, 5, 1, 1, 2, 1, 2, 2, 3, 4, 6, 3, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 3, 2, 1]</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line">fit = powerlaw.Fit(date)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(fit)<span class="comment">#&lt;powerlaw.Fit object at 0x000002144E547BB0&gt;</span></span><br><span class="line"></span><br><span class="line">kmin = fit.power_law.xmin</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;kmin&quot;</span>,kmin)<span class="comment">#kmin 2.0</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;gamma&quot;</span>,fit.power_law.alpha)<span class="comment">#gamma 1.9028919860606162</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;D:&quot;</span>,fit.power_law.D)<span class="comment">#D: 0.05721869113396072</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">6</span>))</span><br><span class="line">plt.subplot(<span class="number">121</span>)</span><br><span class="line"><span class="comment">#绘制数据的概率密度函数 (PDF)</span></span><br><span class="line">fig = fit.plot_pdf(marker = <span class="string">&#x27;o&#x27;</span>,color=<span class="string">&#x27;b&#x27;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line"><span class="comment">#绘制幂律分布的 PDF 拟合曲线</span></span><br><span class="line">fit.power_law.plot_pdf(color=<span class="string">&#x27;b&#x27;</span>, linestyle=<span class="string">&#x27;--&#x27;</span>, ax=fig)</span><br><span class="line">plt.subplot(<span class="number">122</span>)</span><br><span class="line"><span class="comment">#绘制数据的补充累积分布函数 (CCDF)</span></span><br><span class="line">fig = fit.plot_ccdf(marker = <span class="string">&#x27;o&#x27;</span>,color=<span class="string">&#x27;r&#x27;</span>, linewidth=<span class="number">2</span>)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2034.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2036.png" alt=""></p>
<h2 id="生产符合幂律分布的度序列"><a href="#生产符合幂律分布的度序列" class="headerlink" title="生产符合幂律分布的度序列"></a>生产符合幂律分布的度序列</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> powerlaw</span><br><span class="line"><span class="keyword">from</span> networkx.utils <span class="keyword">import</span> powerlaw_sequence</span><br><span class="line"></span><br><span class="line"><span class="comment">#度分布指数为2,5</span></span><br><span class="line">degree_seq = powerlaw_sequence(<span class="number">10000</span>,exponent=<span class="number">2.5</span>)</span><br><span class="line"></span><br><span class="line">int_deg = [<span class="built_in">int</span> (di) <span class="keyword">for</span> di <span class="keyword">in</span> degree_seq]</span><br><span class="line"><span class="built_in">print</span>(int_deg)</span><br><span class="line"></span><br><span class="line">fit = powerlaw.Fit(degree_seq)</span><br><span class="line"><span class="built_in">print</span>(fit)</span><br><span class="line">kmin = fit.power_law.xmin</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;kmin&quot;</span>,kmin)<span class="comment">#kmin 1.4350193502239013</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;gamma&quot;</span>,fit.power_law.alpha)<span class="comment">#gamma 2.504886520959022</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;D&quot;</span>,fit.power_law.D)<span class="comment">#D 0.0060534251036666875</span></span><br><span class="line"></span><br><span class="line">plt.figure(figsize=[<span class="number">6</span>,<span class="number">4.8</span>])</span><br><span class="line">fig = fit.plot_pdf(marker=<span class="string">&#x27;o&#x27;</span>,color = <span class="string">&#x27;b&#x27;</span>,linewidth=<span class="number">1</span>)</span><br><span class="line">fit.power_law.plot_pdf(color=<span class="string">&#x27;b&#x27;</span>,linestyle=<span class="string">&#x27;--&#x27;</span>, ax=fig)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2040.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2040.png" alt=""></p>
<h2 id="配置模型生成给定度序列的网络"><a href="#配置模型生成给定度序列的网络" class="headerlink" title="配置模型生成给定度序列的网络"></a>配置模型生成给定度序列的网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">from</span> networkx.utils <span class="keyword">import</span> powerlaw_sequence</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n, gamma = <span class="number">50000</span>, <span class="number">2.1</span></span><br><span class="line">degree_seq = powerlaw_sequence(n,gamma)</span><br><span class="line">int_deg = [<span class="built_in">int</span>(di) <span class="keyword">for</span> di <span class="keyword">in</span> degree_seq]</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> <span class="built_in">sum</span>(int_deg)%<span class="number">2</span> != <span class="number">0</span>:</span><br><span class="line">    degree_seq = powerlaw_sequence(n,gamma)</span><br><span class="line">    int_deg = [<span class="built_in">int</span>(di) <span class="keyword">for</span> di <span class="keyword">in</span> degree_seq]</span><br><span class="line"></span><br><span class="line">G = nx.configuration_model(int_deg)</span><br><span class="line"><span class="comment">#该模型会生成自环和多重连接。而这些在真实网络中通常是不会出现的</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#定义求度分布的函数，获取各个不同度值对应的概率（适用于网络节点数量比较少的情况）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_pdf</span>(<span class="params">G</span>):</span><br><span class="line">    all_k = [G.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes()]</span><br><span class="line">    k = <span class="built_in">list</span>(<span class="built_in">set</span>(all_k))</span><br><span class="line">    N = <span class="built_in">len</span>(G.nodes())</span><br><span class="line">    Pk = []</span><br><span class="line">    <span class="keyword">for</span> ki <span class="keyword">in</span> <span class="built_in">sorted</span>(k):</span><br><span class="line">        c = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">            <span class="keyword">if</span> G.degree(i) == ki:</span><br><span class="line">                c += <span class="number">1</span></span><br><span class="line">        Pk.append(c/N)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sorted</span>(k),Pk</span><br><span class="line"></span><br><span class="line">k,Pk = get_pdf(G)</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">4.8</span>))</span><br><span class="line">plt.plot(k,Pk,<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$P(k)$&quot;</span>)</span><br><span class="line">plt.xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line"></span><br><span class="line">G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure2041.png&#x27;</span></span><br><span class="line">plt.savefig(G_patch)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2041.png" alt=""></p>
<h2 id="隐参数模型生成无标度网络"><a href="#隐参数模型生成无标度网络" class="headerlink" title="隐参数模型生成无标度网络"></a>隐参数模型生成无标度网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> bisect <span class="keyword">import</span> bisect</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">generate_SF_network</span>(<span class="params">N, gamma, L</span>):</span><br><span class="line">    alpha = <span class="number">1</span> / (gamma - <span class="number">1</span>)</span><br><span class="line">    n = np.linspace(<span class="number">1</span>, N, N)</span><br><span class="line">    eta = n ** (-alpha)</span><br><span class="line">    nom_eta = eta / np.<span class="built_in">sum</span>(eta)</span><br><span class="line">    random.shuffle(nom_eta)</span><br><span class="line">    cum_eta = np.array([np.<span class="built_in">sum</span>(nom_eta[:i]) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>, N)])</span><br><span class="line">    edges = []</span><br><span class="line"></span><br><span class="line">    c = <span class="number">0</span></span><br><span class="line">    <span class="keyword">while</span> c &lt; L:</span><br><span class="line">        i = bisect(cum_eta, np.random.rand(<span class="number">2</span>)[<span class="number">0</span>])</span><br><span class="line">        j = bisect(cum_eta, np.random.rand(<span class="number">2</span>)[<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Ensure i and j are within valid range</span></span><br><span class="line">        <span class="keyword">if</span> i &gt;= N <span class="keyword">or</span> j &gt;= N:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> i == j:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        e1 = (i, j)</span><br><span class="line">        e2 = (j, i)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> e1 <span class="keyword">not</span> <span class="keyword">in</span> edges <span class="keyword">and</span> e2 <span class="keyword">not</span> <span class="keyword">in</span> edges:</span><br><span class="line">            edges.append(e1)</span><br><span class="line">            c += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    G = nx.Graph()</span><br><span class="line">    G.add_edges_from(edges)</span><br><span class="line">    <span class="keyword">return</span> G</span><br><span class="line"></span><br><span class="line">N = <span class="number">5000</span></span><br><span class="line">gamma = <span class="number">2.1</span></span><br><span class="line">avk = <span class="number">6.0</span></span><br><span class="line">L = <span class="built_in">int</span> (avk * N / <span class="number">2</span>)</span><br><span class="line">G = generate_SF_network(N,gamma,L)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义求度分布的函数，获取各个不同度值对应的概率（适用于网络节点数量比较少的情况）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_pdf</span>(<span class="params">G</span>):</span><br><span class="line">    all_k = [G.degree(i) <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes()]</span><br><span class="line">    k = <span class="built_in">list</span>(<span class="built_in">set</span>(all_k))</span><br><span class="line">    N = <span class="built_in">len</span>(G.nodes())</span><br><span class="line">    Pk = []</span><br><span class="line">    <span class="keyword">for</span> ki <span class="keyword">in</span> <span class="built_in">sorted</span>(k):</span><br><span class="line">        c = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> G.nodes():</span><br><span class="line">            <span class="keyword">if</span> G.degree(i) == ki:</span><br><span class="line">                c += <span class="number">1</span></span><br><span class="line">        Pk.append(c/N)</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sorted</span>(k),Pk</span><br><span class="line"></span><br><span class="line">k,Pk = get_pdf(G)</span><br><span class="line">plt.figure(figsize=(<span class="number">6</span>,<span class="number">4.8</span>))</span><br><span class="line">plt.plot(k,Pk,<span class="string">&#x27;ro&#x27;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;$k$&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;$P(k)$&quot;</span>)</span><br><span class="line">plt.xscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line">plt.yscale(<span class="string">&quot;log&quot;</span>)</span><br><span class="line"></span><br><span class="line">G_patch = <span class="string">&#x27;E:/MyBlog/source/images/figure2042.png&#x27;</span></span><br><span class="line">plt.savefig(G_patch)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2042.png" alt=""></p>
<h2 id="EoN库：ER网络和BA网络上的流行病仿真"><a href="#EoN库：ER网络和BA网络上的流行病仿真" class="headerlink" title="EoN库：ER网络和BA网络上的流行病仿真"></a>EoN库：ER网络和BA网络上的流行病仿真</h2><h2 id="下列为SIS仿真"><a href="#下列为SIS仿真" class="headerlink" title="下列为SIS仿真"></a>下列为SIS仿真</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> EoN</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line">N = <span class="number">10</span>**<span class="number">4</span></span><br><span class="line">M = <span class="number">4</span>*N</span><br><span class="line">ER = nx.gnm_random_graph(N, M)</span><br><span class="line"></span><br><span class="line">tau = <span class="number">0.5</span></span><br><span class="line">gamma = <span class="number">0.05</span></span><br><span class="line">t,S,I = EoN.fast_SIS(ER,tau=tau,gamma=gamma,tmax=<span class="number">10</span>)</span><br><span class="line">plt.plot(t,S,color = <span class="string">&#x27;r&#x27;</span>,label = <span class="string">&#x27;S&#x27;</span>)</span><br><span class="line">plt.plot(t,I,color = <span class="string">&#x27;b&#x27;</span>,label = <span class="string">&#x27;I&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$I$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;indivduals&#x27;</span>)</span><br><span class="line">G_path = <span class="string">&#x27;E:/MyBlog/source/images/figure2049.png&#x27;</span></span><br><span class="line">plt.savefig(G_path)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2049.png" alt=""></p>
<p>SIR仿真</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> EoN</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> networkx <span class="keyword">as</span> nx</span><br><span class="line"></span><br><span class="line">N = <span class="number">10</span>**<span class="number">4</span></span><br><span class="line">M = <span class="number">4</span>*N</span><br><span class="line">ER = nx.gnm_random_graph(N, M)</span><br><span class="line"></span><br><span class="line">tau = <span class="number">0.5</span></span><br><span class="line">gamma = <span class="number">1.0</span></span><br><span class="line">rho = <span class="number">0.05</span></span><br><span class="line">t,S,I,R = EoN.fast_SIR(ER,tau=tau,gamma=gamma,rho=rho,tmax=<span class="number">20</span>)</span><br><span class="line">plt.plot(t,S,color = <span class="string">&#x27;r&#x27;</span>,label = <span class="string">&#x27;S&#x27;</span>)</span><br><span class="line">plt.plot(t,I,color = <span class="string">&#x27;b&#x27;</span>,label = <span class="string">&#x27;I&#x27;</span>)</span><br><span class="line">plt.plot(t,R,color = <span class="string">&#x27;g&#x27;</span>,label = <span class="string">&#x27;R&#x27;</span>)</span><br><span class="line">plt.legend(loc=<span class="number">0</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;$I$&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;indivduals&#x27;</span>)</span><br><span class="line"><span class="comment"># G_path = &#x27;E:/MyBlog/source/images/figure2050.png&#x27;</span></span><br><span class="line"><span class="comment"># plt.savefig(G_path)</span></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="images/figure2050.png" alt=""></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2024/09/06/python%E8%BF%9B%E9%98%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/06/python%E8%BF%9B%E9%98%B6/" class="post-title-link" itemprop="url">python进阶</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-09-06 21:08:49" itemprop="dateCreated datePublished" datetime="2024-09-06T21:08:49+08:00">2024-09-06</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-23 20:39:10" itemprop="dateModified" datetime="2024-09-23T20:39:10+08:00">2024-09-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="python进阶"><a href="#python进阶" class="headerlink" title="python进阶"></a>python进阶</h1><h2 id="异常"><a href="#异常" class="headerlink" title="异常"></a>异常</h2><p>定义：是一个事件，这个事件在程序执行过程中发生，影响了程序的正常执行。</p>
<h3 id="异常处理"><a href="#异常处理" class="headerlink" title="异常处理"></a>异常处理</h3><p>语法格式一：</p>
<p>try:</p>
<p>​    可能引发异常现象的代码</p>
<p>except:</p>
<p>​    出现异常现象的处理代码</p>
<p>语法格式二：</p>
<p>try:</p>
<p>​    可能引发异常现象的代码</p>
<p>except:</p>
<p>​    出现异常现象的处理代码</p>
<p>else:</p>
<p>​    try 代码块结束后运行的代码</p>
<h3 id="异常传递"><a href="#异常传递" class="headerlink" title="异常传递"></a>异常传递</h3><p>当函数/方法执行出现异常，会将异常传递给函数/方法的调用一方</p>
<p>如果传递到主程序，仍没有异常处理，程序才会被终止</p>
<h2 id="递归函数"><a href="#递归函数" class="headerlink" title="递归函数"></a>递归函数</h2><p>特性：</p>
<ol>
<li>必须有一个明确的结束条件</li>
<li>每次进入更深一层递归时，问题规模相比上一次递归都应有所减少</li>
<li>相邻两次重复之前有紧密联系，前一次要为后一次做准备</li>
<li>递归效率不高，递归层次过多导致栈溢出</li>
<li>优点：定义简单，逻辑清晰</li>
</ol>
<p>递推：给递归实现拆解，递归每次都是基于上一次进行下一次的执行</p>
<p>回溯：遇到终止条件之前，从最后往回返，一级一级的把值返回来</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#应用：</span></span><br><span class="line"><span class="comment">#累加</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">if</span> n &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> fun(n-<span class="number">1</span>)+n</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="built_in">print</span>(fun(<span class="number">7</span>))   	</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#斐波那契数列 1,1,2,3,5,8,13,21</span></span><br><span class="line">list1 = []</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">n</span>):</span><br><span class="line">    <span class="keyword">if</span> n &lt;= <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> n</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> fun(n-<span class="number">1</span>) + fun(n-<span class="number">2</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>):</span><br><span class="line">    list1.append(fun(i))</span><br><span class="line"><span class="built_in">print</span>(list1)<span class="comment">#[1, 1, 2, 3, 5, 8, 13, 21, 34, 55]</span></span><br></pre></td></tr></table></figure>
<h2 id="函数引用"><a href="#函数引用" class="headerlink" title="函数引用"></a>函数引用</h2><p>定义：如果函数收到的是一个可变对象（比如字典或列表）的引用，就能够修改对象的原始——相当于通过”传引用”来传递对象；如果函数接收到的是一个不可变对象（如数字字符元组）的引用，就不能直接修改原始对象——相当于”‘传值”来传对象</p>
<p>函数引用：如函数名的引用，函数传递时的引用传递</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def test1():</span><br><span class="line">    print(&quot;---in test1 func---&quot;)</span><br><span class="line">test1()</span><br><span class="line">res = test1</span><br><span class="line">print(id(res))</span><br><span class="line">print(id(test1()))</span><br></pre></td></tr></table></figure>
<h2 id="闭包"><a href="#闭包" class="headerlink" title="闭包"></a>闭包</h2><p>定义：闭包是函数内部定义的函数</p>
<ol>
<li>闭包是嵌套在函数中的函数</li>
<li>闭包必须是内层函数对外层函数变量的引用</li>
</ol>
<p>构成条件</p>
<ol>
<li>函数中嵌套一个函数</li>
<li>内层嵌套函数，对外部作用域有一个非全局变量的引用</li>
<li>外层函数的返回值是内层函数的函数名</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#闭包模版</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">outF</span>():</span><br><span class="line">    <span class="built_in">sum</span> = n <span class="comment">#定义一个非全局变量</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inF</span>(<span class="params">n</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">sum</span>+<span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> inF <span class="comment">#外层函数返回值是内层函数的函数名</span></span><br></pre></td></tr></table></figure>
<p>闭包的作用：</p>
<p>​    保存局部信息不被销毁，保证数据的安全性</p>
<p>闭包的应用：</p>
<ol>
<li>可以保存一些非全局变量，不易被销毁、改变的数据</li>
<li>装饰器</li>
<li>实现数据锁定</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#例子</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">outer</span>(<span class="params">m</span>):</span><br><span class="line">    n = <span class="number">10</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;inner函数&quot;</span>,n+m)</span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line">t = outer(<span class="number">2</span>)</span><br><span class="line">t()<span class="comment">#inner函数 12</span></span><br></pre></td></tr></table></figure>
<h2 id="装饰器"><a href="#装饰器" class="headerlink" title="装饰器"></a>装饰器</h2><p>装饰器本质就是一个闭包函数，装饰器的返回值也是一个函数对象</p>
<p>他可以让其他函数在不需要做任何代码变动的前提下增加额外的功能</p>
<p>装饰器功能</p>
<ol>
<li>函数执行时间统计</li>
<li>可以用在框架的路由传参上</li>
<li>插入日志</li>
<li>事务处理</li>
<li>权限校验</li>
<li>缓存</li>
</ol>
<p>装饰器使用方法：</p>
<ol>
<li>先定义一个装饰函数（帽子）</li>
<li>在定义一个你的业务函数</li>
<li>最后把这个帽子戴在这个人的头上</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#日志打印</span></span><br><span class="line"><span class="comment">#语法一</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logger</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我准备计算开始：&#123;&#125;函数了&quot;</span>.<span class="built_in">format</span>(func.__name__))</span><br><span class="line">        <span class="comment">#真正执行的业务</span></span><br><span class="line">        func(*args)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我计算完了&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"></span><br><span class="line"><span class="comment">#第一种方法</span></span><br><span class="line"><span class="comment">#真正的业务函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; + &#123;&#125; = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a, b, a + b))</span><br><span class="line"></span><br><span class="line"><span class="comment">#使用装饰器来装饰函数</span></span><br><span class="line"><span class="comment">#把函数add作为参数传入到装饰函数</span></span><br><span class="line">te = logger(add) <span class="comment">#调用logger函数</span></span><br><span class="line">te(<span class="number">12</span>,<span class="number">55</span>) <span class="comment">#实现了wrapper的调用</span></span><br><span class="line">/*我准备计算开始：add函数了</span><br><span class="line"><span class="number">12</span> + <span class="number">55</span> = <span class="number">67</span></span><br><span class="line">我计算完了*/</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#日志打印</span></span><br><span class="line"><span class="comment">#语法二</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">logger</span>(<span class="params">func</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">wrapper</span>(<span class="params">*args</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我准备计算开始：&#123;&#125;函数了&quot;</span>.<span class="built_in">format</span>(func.__name__))</span><br><span class="line">        <span class="comment">#真正执行的业务</span></span><br><span class="line">        func(*args)</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;我计算完了&quot;</span>)</span><br><span class="line">    <span class="keyword">return</span> wrapper</span><br><span class="line"><span class="comment">#第二种语法@</span></span><br><span class="line"><span class="comment">#真正的业务函数</span></span><br><span class="line"><span class="meta">@logger</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">add</span>(<span class="params">a, b</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;&#123;&#125; + &#123;&#125; = &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(a, b, a + b))</span><br><span class="line">add(<span class="number">1</span>, <span class="number">200</span>)</span><br></pre></td></tr></table></figure>
<h2 id="无参数的装饰器"><a href="#无参数的装饰器" class="headerlink" title="无参数的装饰器"></a>无参数的装饰器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">te</span>(<span class="params">fun</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>():</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;这是inner&quot;</span>)</span><br><span class="line">        fun()</span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"><span class="comment">#方法一</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">t1</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;哈哈哈&quot;</span>)</span><br><span class="line"></span><br><span class="line">t = te(t1)</span><br><span class="line">t()</span><br></pre></td></tr></table></figure>
<h2 id="有参数的装饰器"><a href="#有参数的装饰器" class="headerlink" title="有参数的装饰器"></a>有参数的装饰器</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">exam</span>(<span class="params">fun</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">inner</span>(<span class="params">a,b</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;inner函数中的值：%s,%s&quot;</span>%(a,b))</span><br><span class="line">        fun(a,b)<span class="comment">#真正的业务函数</span></span><br><span class="line">    <span class="keyword">return</span> inner</span><br><span class="line"><span class="meta">@exam</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">te</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;结果是：&quot;</span>,(a+b))</span><br><span class="line">te(<span class="number">1</span>,<span class="number">2</span>)</span><br><span class="line">/*</span><br><span class="line">inner函数中的值：<span class="number">1</span>,<span class="number">2</span></span><br><span class="line">结果是： <span class="number">3</span></span><br><span class="line">*/</span><br></pre></td></tr></table></figure>
<h2 id="多层嵌套"><a href="#多层嵌套" class="headerlink" title="多层嵌套"></a>多层嵌套</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">exam</span>(<span class="params">fn</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">fun</span>(<span class="params">x,y</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;hello&quot;</span>,x,y)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">inner</span>(<span class="params">a,b</span>):</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;inner函数中的值：%s，%s&quot;</span>%(a,b))</span><br><span class="line">            fn(a,b)</span><br><span class="line">        <span class="keyword">return</span> inner</span><br><span class="line">    <span class="keyword">return</span> fun</span><br><span class="line"><span class="meta">@exam</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">te</span>(<span class="params">a,b</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;结果是：&quot;</span>, (a + b))</span><br><span class="line">te(<span class="number">1</span>,<span class="number">2</span>)(<span class="number">3</span>,<span class="number">4</span>)</span><br><span class="line">/*</span><br><span class="line">hello <span class="number">1</span> <span class="number">2</span></span><br><span class="line">inner函数中的值：<span class="number">3</span>，<span class="number">4</span></span><br><span class="line">结果是： <span class="number">7</span></span><br><span class="line">*/</span><br></pre></td></tr></table></figure>
<h2 id="属性与方法"><a href="#属性与方法" class="headerlink" title="属性与方法"></a>属性与方法</h2><p>属性：对象的特征描述，实际为定义的变量，该变量为属性</p>
<p>方法：对象具有的行为（本质是函数），类中定义的函数即方法</p>
<h3 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h3><p>对象的创建格式</p>
<p>​    对象名 = 类名（）</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2024/09/05/C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/09/05/C/" class="post-title-link" itemprop="url">C++</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-09-05 17:01:12 / 修改时间：17:08:51" itemprop="dateCreated datePublished" datetime="2024-09-05T17:01:12+08:00">2024-09-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/C/" itemprop="url" rel="index"><span itemprop="name">C++</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://liujunblog.github.io/2024/04/24/python%E5%9F%BA%E7%A1%80/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="LiuJun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/24/python%E5%9F%BA%E7%A1%80/" class="post-title-link" itemprop="url">python</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2024-04-24 10:04:02" itemprop="dateCreated datePublished" datetime="2024-04-24T10:04:02+08:00">2024-04-24</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2024-09-23 20:39:15" itemprop="dateModified" datetime="2024-09-23T20:39:15+08:00">2024-09-23</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/python/" itemprop="url" rel="index"><span itemprop="name">python</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="python基础"><a href="#python基础" class="headerlink" title="python基础"></a>python基础</h1><h2 id="数值类型"><a href="#数值类型" class="headerlink" title="数值类型"></a>数值类型</h2><p>整型（int）浮点类型（float） 布尔（bool）复数（complex，z = a + bj , j为虚部）</p>
<h2 id="字符串str"><a href="#字符串str" class="headerlink" title="字符串str"></a>字符串str</h2><p>特点：需要加上引号，单双引号都可以，包含了多行时可以使用三引号；三引号用来多行注释（无变量名）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">&#x27;Tom&#x27;</span></span><br><span class="line">name = <span class="string">&quot;Tom&quot;</span></span><br><span class="line">name = <span class="string">&quot;&quot;&quot;&quot;Tom&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>
<h2 id="格式话输出"><a href="#格式话输出" class="headerlink" title="格式话输出"></a>格式话输出</h2><ol>
<li><p>占位符（生成一定格式的字符串）</p>
</li>
<li><p>%s字符串（常用）占位符只会占据位置不会被输出</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">&quot;Tom&quot;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;我的名字：%s&quot;</span> %name)</span><br></pre></td></tr></table></figure>
</li>
<li><p>%d 整型（常用）%4d 数字设置位数，不足前面补空白，%04d前面不足补零</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">&quot;Tom&quot;</span></span><br><span class="line">age = <span class="number">18</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;我的名字：%s,年龄：%2d&quot;</span> %(name,age))</span><br></pre></td></tr></table></figure>
</li>
<li><p>%f 浮点类型（常用）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">a = <span class="number">1.2</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;%f&quot;</span> %a) <span class="comment">#默认六位小数，遵循四舍五入原则</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;%.4f&quot;</span> %a) <span class="comment">#设置小数位数，遵循四舍五入，不足后面补零</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>%%占位符</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;我是%%的1%%&quot;</span>%())</span><br></pre></td></tr></table></figure>
</li>
<li><p>f 格式化（格式f”{表达式}）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">name = <span class="string">&quot;Tom&quot;</span></span><br><span class="line">age = <span class="number">18</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;我的名字是<span class="subst">&#123;name&#125;</span>,我今年<span class="subst">&#123;age&#125;</span>岁了&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="while循环"><a href="#while循环" class="headerlink" title="while循环"></a>while循环</h2><p>九九乘法表</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">i = <span class="number">1</span></span><br><span class="line"><span class="keyword">while</span> i &lt; <span class="number">10</span> :</span><br><span class="line">    j = <span class="number">1</span></span><br><span class="line">    <span class="keyword">while</span> j &lt;= i:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;i&#125;</span>*<span class="subst">&#123;j&#125;</span>=<span class="subst">&#123;i*j&#125;</span>&quot;</span>,end=<span class="string">&quot;\t&quot;</span>)</span><br><span class="line">        j += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span>()</span><br><span class="line">    i = i+<span class="number">1</span></span><br></pre></td></tr></table></figure>
<h2 id="for循环"><a href="#for循环" class="headerlink" title="for循环"></a>for循环</h2><p>用法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>()</span><br><span class="line"><span class="comment">#range()三个参数start,stop,step</span></span><br><span class="line"><span class="comment">#包前不包后</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="number">11</span>)<span class="comment">#1-10</span></span><br></pre></td></tr></table></figure>
<h2 id="break、continue与return"><a href="#break、continue与return" class="headerlink" title="break、continue与return"></a>break、continue与return</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">区别</th>
<th style="text-align:center">break</th>
<th style="text-align:center">continue</th>
<th style="text-align:center">return</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">描述</td>
<td style="text-align:center">break命令用于在循环中遇到某些条件时立即退出循环。当执行到break语句时，程序将立即跳出当前循环，继续执行下一条语句</td>
<td style="text-align:center">continue命令用于在循环中遇到某些条件时跳过本次循环的剩余语句，并继续执行下一次循环</td>
<td style="text-align:center">return命令用于从函数中返回一个值并结束函数执行。当执行到return语句时，函数会立即结束，并将结果返回给调用者</td>
</tr>
<tr>
<td style="text-align:center">使用场景</td>
<td style="text-align:center">当需要在循环中遇到某些特定条件时退出循环<br>当需要终止无限循环时</td>
<td style="text-align:center">当需要忽略当前循环中剩余的语句时<br>当需要实现类似“跳过本次循环”的操作的时候</td>
<td style="text-align:center">当需要在函数中返回一个值时<br>当需要结束函数的执行时</td>
</tr>
<tr>
<td style="text-align:center">注意事项</td>
<td style="text-align:center">break语句会直接退出最内层循环，如果嵌套了多层循环，则不会直接退出外层循环<br>break语句只能退出循环，不能跳出函数，需要通过return语句才能退出函数</td>
<td style="text-align:center">continue语句只能用于循环结构中，不能用于if语句或switch语句等其他结构中执行<br>continue语句后，会直接进入下一次循环，不会执行本次循环中剩余的语句</td>
<td style="text-align:center">return语句只能用于函数内部，循环或其他结构中谨慎使用<br>执行return语句后，会直接结束当前函数的执行，不会执行后续的语句<br>如果函数中没有return语句，则默认返回None</td>
</tr>
</tbody>
</table>
</div>
<h2 id="字符串编码"><a href="#字符串编码" class="headerlink" title="字符串编码"></a>字符串编码</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">详情</th>
<th style="text-align:center">Unicode</th>
<th style="text-align:center">UTF-8</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">好处</td>
<td style="text-align:center">字符与数字之间转换速度更快一些</td>
<td style="text-align:center">节省空间</td>
</tr>
<tr>
<td style="text-align:center">坏处</td>
<td style="text-align:center">占用空间大</td>
<td style="text-align:center">字符与数字之间转换速度较慢</td>
</tr>
</tbody>
</table>
</div>
<h2 id="字符串编码转化"><a href="#字符串编码转化" class="headerlink" title="字符串编码转化"></a>字符串编码转化</h2><p>encode  编码；  decode 解码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#encode()方法用于将字符串从Unicode编码转换为指定的编码形式</span></span><br><span class="line">text = <span class="string">&quot;Hello, 你好&quot;</span></span><br><span class="line">encoded_text = text.encode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(encoded_text)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#decode()方法用于将字符串从指定的编码形式解码为Unicode编码</span></span><br><span class="line">byte_data = <span class="string">b&#x27;Hello, \xe4\xbd\xa0\xe5\xa5\xbd&#x27;</span>  <span class="comment"># UTF-8编码的字节串</span></span><br><span class="line">decoded_text = byte_data.decode(<span class="string">&#x27;utf-8&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(decoded_text)</span><br></pre></td></tr></table></figure>
<h2 id="字符串运算符"><a href="#字符串运算符" class="headerlink" title="字符串运算符"></a>字符串运算符</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">操作符</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">+</td>
<td style="text-align:center">字符串连接</td>
<td style="text-align:center">hello+Python输出结果：helloPython</td>
</tr>
<tr>
<td style="text-align:center">*</td>
<td style="text-align:center">重复输出字符串</td>
<td style="text-align:center">hello*2输出结果：hellohello</td>
</tr>
<tr>
<td style="text-align:center">[]</td>
<td style="text-align:center">通过索引来获取字符串中的字符</td>
<td style="text-align:center">hello[1]输出结果为e</td>
</tr>
<tr>
<td style="text-align:center">[:]</td>
<td style="text-align:center">截取字符串中的部分</td>
<td style="text-align:center">hello[1:4]输出结果：ell</td>
</tr>
<tr>
<td style="text-align:center">in</td>
<td style="text-align:center">成员运算-如果字符串中包含给定的字符串返回True</td>
<td style="text-align:center">e in hello 输出结果：True</td>
</tr>
<tr>
<td style="text-align:center">not in</td>
<td style="text-align:center">成员运算-如果字符串不包含给定的字符串返回True</td>
<td style="text-align:center">t not in hello 输出结果：True</td>
</tr>
</tbody>
</table>
</div>
<h2 id="字符串常见操作"><a href="#字符串常见操作" class="headerlink" title="字符串常见操作"></a>字符串常见操作</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">函数</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">len</td>
<td style="text-align:center">len函数可以获取字符串的长度。</td>
<td style="text-align:center"><code>mystr = &#39;今天天气好晴朗，处处好风光呀好风光&#39; print(len(mystr))  # 17 获取字符串的长度</code></td>
</tr>
<tr>
<td style="text-align:center">find</td>
<td style="text-align:center">查找指定内容在字符串中是否存在，如果存在就返回该内容在字符串中第一次出现的开始位置索引值，如果不存在，则返回-1</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’<br/>print(mystr.find(‘好风光’))  # 10 ‘好风光’第一次出现时，’好’所在的位置<br/>print(mystr.find(‘你好’))  # -1  ‘你好’不存在，返回 -1<br/>print(mystr.find(‘风’, 12))  # 15 从下标12开始查找’风’,找到风所在的位置是15<br/>print(mystr.find(‘风光’,1,10)) # -1 从下标1开始到12查找”风光”,未找到，返回 -1</td>
</tr>
<tr>
<td style="text-align:center">rfind</td>
<td style="text-align:center">类似于 find()函数，不过是从右边开始查找。</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’ print(mystr.rfind(‘好’)) <em># 14</em></td>
</tr>
<tr>
<td style="text-align:center">index</td>
<td style="text-align:center">跟find()方法一样，只不过，find方法未找到时，返回-1,而index未找到时，会报一个异常。</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">rindex</td>
<td style="text-align:center">类似于 index()，不过是从右边开始。</td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">startswith</td>
<td style="text-align:center">判断字符串是否以指定内容开始。</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’ print(mystr.startswith(‘今’))  <em># True</em> print(mystr.startswith(‘今日’)) <em># False</em></td>
</tr>
<tr>
<td style="text-align:center">endswith</td>
<td style="text-align:center">判断字符串是否以指定内容结束。</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’ print(mystr.endswith(‘好风光’)) <em>#True</em> print(mystr.endswith(‘好日子’)) <em>#False</em></td>
</tr>
<tr>
<td style="text-align:center">isalpha</td>
<td style="text-align:center">判断字符串是否是纯字母。</td>
<td style="text-align:center">mystr = ‘hello’ print(mystr.isalpha())  # True mystr = ‘hello world’ print(mystr.isalpha()) # False 因为中间有空格</td>
</tr>
<tr>
<td style="text-align:center">isdigit</td>
<td style="text-align:center">判断一个字符串是否是纯数字，只要出现非0~9的数字，结果就是False.</td>
<td style="text-align:center">mystr = ‘1234’ print(mystr.isdigit()) <em># True</em> mystr = ‘123.4’ print(mystr.isdigit()) <em># False</em> mystr = ‘-1234’ print(mystr.isdigit()) <em># False</em></td>
</tr>
<tr>
<td style="text-align:center">isalnum</td>
<td style="text-align:center">判断是否由数字和字母组成。只要出现了非数字和字母，就返回False.</td>
<td style="text-align:center">mystr = ‘abcd’<br/>print(mystr.isalnum())  # True<br/>mystr = ‘1234’<br/>print(mystr.isalnum()) # True<br/>mystr = ‘abcd1234’<br/>print(mystr.isalnum()) # True<br/>mystr = ‘abcd1234_’<br/>print(mystr.isalnum()) # False</td>
</tr>
<tr>
<td style="text-align:center">isspace</td>
<td style="text-align:center">如果 mystr 中只包含空格，则返回 True，否则返回 False.</td>
<td style="text-align:center">mystr = ‘’<br/>print(mystr.isspace()) # False mystr是一个空字符串<br/>mystr = ‘  ‘<br/>print(mystr.isspace()) # True 只有空格<br/>mystr = ‘ d’<br/>print(mystr.isspace()) # False 除了空格外还有其他内容</td>
</tr>
<tr>
<td style="text-align:center">count</td>
<td style="text-align:center">返回 str在start和end之间 在 mystr里面出现的次数。</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’ <br>print(mystr.count(‘好’))  # 3. ‘好’字出现三次</td>
</tr>
<tr>
<td style="text-align:center">replace</td>
<td style="text-align:center">替换字符串中指定的内容，如果指定次数count，则替换不会超过count次。</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’<br/>newstr = mystr.replace(‘好’, ‘坏’)<br/>print(mystr)  # 今天天气好晴朗，处处好风光呀好风光  原字符串未改变！<br/>print(newstr)  # 今天天气坏晴朗，处处坏风光呀坏风光 得到的新字符串里，’好’被修改成了’坏’<br/> <br/>newstr = mystr.replace(‘好’,’坏’,2)  # 指定了替换的次数<br/>print(newstr) # 今天天气坏晴朗，处处坏风光呀好风光 只有两处的’好’被替换成了’坏’</td>
</tr>
<tr>
<td style="text-align:center">split</td>
<td style="text-align:center">以指定字符串为分隔符切片，如果 maxsplit有指定值，则仅分隔 maxsplit+1 个子字符串。返回的结果是一个列表。</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’<br/>result = mystr.split() # 没有指定分隔符，默认使用空格，换行等空白字符进行分隔<br/>print(result) #[‘今天天气好晴朗，处处好风光呀好风光’] 没有空白字符，所以，字符串未被分隔<br/> <br/>result = mystr.split(‘好’)  # 以 ‘好’ 为分隔符<br/>print(result) # [‘今天天气’, ‘晴朗，处处’,’风光呀,’风光’]<br/> <br/>result = mystr.split(“好”,2) # 以 ‘好’ 为分隔符，最多切割成3份<br/>print(result) # [‘今天天气’, ‘晴朗，处处’, ‘风光呀好风光’]</td>
</tr>
<tr>
<td style="text-align:center">rsplit</td>
<td style="text-align:center">用法和split基本一致，只不过是从右往左分隔。</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’ print(mystr.rsplit(‘好’,1))  #[‘今天天气好晴朗，处处好风光呀’, ‘风光’]</td>
</tr>
<tr>
<td style="text-align:center">splitlines</td>
<td style="text-align:center">按照行分隔，返回一个包含各行作为元素的列表。</td>
<td style="text-align:center">mystr = ‘hello \nworld’ print(mystr.splitlines())</td>
</tr>
<tr>
<td style="text-align:center">partition</td>
<td style="text-align:center">把mystr以str分割成三部分,str前，str和str后，三部分组成一个元组</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’ print(mystr.partition(‘好’))  # (‘今天天气’, ‘好’, ‘晴朗，处处好风光呀好风光’)</td>
</tr>
<tr>
<td style="text-align:center">rpartition</td>
<td style="text-align:center">类似于 partition()函数,不过是从右边开始.</td>
<td style="text-align:center">mystr = ‘今天天气好晴朗，处处好风光呀好风光’ print(mystr.rpartition(‘好’))   # (‘今天天气好晴朗，处处好风光呀’, ‘好’, ‘风光’)</td>
</tr>
<tr>
<td style="text-align:center">capitalize</td>
<td style="text-align:center">第一个单词的首字母大写。</td>
<td style="text-align:center">mystr = ‘hello world’ print(mystr.capitalize()) # Hello world</td>
</tr>
<tr>
<td style="text-align:center">title</td>
<td style="text-align:center">每个单词的首字母大写。</td>
<td style="text-align:center">mystr = ‘hello world’ print(mystr.title()) # Hello World</td>
</tr>
<tr>
<td style="text-align:center">lower</td>
<td style="text-align:center">所有都变成小写。</td>
<td style="text-align:center">mystr = ‘hElLo WorLD’ print(mystr.lower()) <em># hello world</em></td>
</tr>
<tr>
<td style="text-align:center">upper</td>
<td style="text-align:center">所有都变成大写</td>
<td style="text-align:center">mystr = ‘hello world’ print(mystr.upper())  <em>#HELLO WORLD</em></td>
</tr>
<tr>
<td style="text-align:center">ljust</td>
<td style="text-align:center">返回指定长度的字符串，并在右侧使用空白字符补全(左对齐)。</td>
<td style="text-align:center">str = ‘hello’ print(str.ljust(10))  # hello     在右边补了五个空格</td>
</tr>
<tr>
<td style="text-align:center">rjust</td>
<td style="text-align:center">返回指定长度的字符串，并在左侧使用空白字符补全(右对齐)。</td>
<td style="text-align:center">str = ‘hello’ print(str.rjust(10))  <em>#      hello在左边补了五个空格</em></td>
</tr>
<tr>
<td style="text-align:center">center</td>
<td style="text-align:center">返回指定长度的字符串，并在两端使用空白字符补全(居中对齐)</td>
<td style="text-align:center">str = ‘hello’ print(str.center(10))  <em>#  hello   两端加空格，让内容居中</em></td>
</tr>
<tr>
<td style="text-align:center">lstrip</td>
<td style="text-align:center">删除 mystr 左边的空白字符。</td>
<td style="text-align:center">mystr = ‘    he   llo      ‘<br/>print(str.lstrip())  #he   llo      只去掉了左边的空格，中间和右边的空格被保留</td>
</tr>
<tr>
<td style="text-align:center">rstrip</td>
<td style="text-align:center">删除 mystr 右边的空白字符。</td>
<td style="text-align:center">mystr = ‘    he   llo      ‘<br/>print(str.rstrip())  #    he   llo右边的空格被删除</td>
</tr>
<tr>
<td style="text-align:center">strip</td>
<td style="text-align:center">删除两断的空白字符。</td>
<td style="text-align:center">str = ‘    he   llo      ‘<br/>print(str.strip())  #he   llo</td>
</tr>
<tr>
<td style="text-align:center">join</td>
<td style="text-align:center">把参数进行遍历，取出参数里的每一项，然后再在后面加上mystr</td>
<td style="text-align:center">mystr = ‘a’<br/>print(mystr.join(‘hxmdq’))  #haxamadaq  把hxmd一个个取出，并在后面添加字符a. 最后的 q 保留，没有加 a<br/>print(mystr.join([‘hi’,’hello’,’good’]))  #hiahelloagood</td>
</tr>
</tbody>
</table>
</div>
<h2 id="元组"><a href="#元组" class="headerlink" title="元组"></a>元组</h2><p>基本格式：元组名 = （元素1，元素2，元素3）</p>
<p>所有元素包含在小括号内，元素与元素之间，分隔，不同元素也可以是不同的数据类型</p>
<p>只有一个元素末尾必须加逗号</p>
<div class="table-container">
<table>
<thead>
<tr>
<th></th>
<th>元组</th>
<th>列表</th>
</tr>
</thead>
<tbody>
<tr>
<td>区别</td>
<td>元素在小括号中<br>只有一个元素末尾需要加逗号<br>元组只能查询，不能增删改</td>
<td>元素在中括号中<br>只有一个元素不需要加逗号<br>列表可以增删改查</td>
</tr>
<tr>
<td>联系</td>
<td>都有下标</td>
</tr>
</tbody>
</table>
</div>
<h2 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h2><p>基本格式：字典名 = {键1：值1，键2，值2}</p>
<p>字典中键名具备唯一性，但值可以重复</p>
<p>字典中键名重复时，值会被后面的值替换</p>
<h2 id="字典常见操作"><a href="#字典常见操作" class="headerlink" title="字典常见操作"></a>字典常见操作</h2><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">操作</th>
<th style="text-align:center">描述</th>
<th style="text-align:center">实例</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">[‘’]</td>
<td style="text-align:center">查找元素需要根据键名，键名相当于下标<br>键名不存在会报错</td>
<td style="text-align:center">dic = {‘name’:’Tom’,’age’:18}<br>print(dic[‘age’])#18</td>
</tr>
<tr>
<td style="text-align:center">变量名.get(键名)</td>
<td style="text-align:center">查找元素<br>键名不存在时不会报错，返回None<br>变量名.get(,)第二个参数可以设置，查找不到返回第二个参数</td>
<td style="text-align:center">dic = {‘name’:’Tom’,’age’:18}<br/>print(dic.get(‘age’)#18<br>print(dic.get(‘sex’),”不存在”)#不存在</td>
</tr>
<tr>
<td style="text-align:center">变量名[‘键名’] = 值</td>
<td style="text-align:center">修改字典元素</td>
<td style="text-align:center">dic = {‘name’:’Tom’,’age’:18}<br>dic[‘age’] = 20</td>
</tr>
<tr>
<td style="text-align:center">变量名[‘键名’] = 值</td>
<td style="text-align:center">添加字典元素</td>
<td style="text-align:center">dic = {‘name’:’Tom’,’age’:18}<br/>dic[‘sex’] = ‘女’</td>
</tr>
<tr>
<td style="text-align:center">del</td>
<td style="text-align:center">删除整个字典<br>删除指定的键值对</td>
<td style="text-align:center">dic = {‘name’:’Tom’,’age’:18}<br>del dic<br></td>
</tr>
<tr>
<td style="text-align:center">keys()</td>
<td style="text-align:center">查询键值</td>
<td style="text-align:center">d3 = {‘name’:’张三’,’age’:18,’sex’:’男’} print(d3.keys())  # dict_keys([‘name’, ‘age’, ‘sex’])</td>
</tr>
<tr>
<td style="text-align:center">values()</td>
<td style="text-align:center">查询值</td>
<td style="text-align:center">d4 = {‘name’:’张三’,’age’:18,’sex’:’男’} print(d4.values())  # dict_values([‘张三’, 18, ‘男’])</td>
</tr>
<tr>
<td style="text-align:center">items()</td>
<td style="text-align:center">遍历</td>
<td style="text-align:center">d5 = {‘name’:’张三’,’age’:18,’sex’:’男’} print(d5.items()) <em># dict_items([(‘name’, ‘张三’), (‘age’, 18), (‘sex’, ‘男’)])</em></td>
</tr>
</tbody>
</table>
</div>
<h2 id="集合"><a href="#集合" class="headerlink" title="集合"></a>集合</h2><p>集合基本格式：{数据1，数据2，数据3，….}</p>
<p>集合和字典的区别</p>
<ol>
<li>字典是键值对形式，集合只有数据</li>
<li>s={}默认是空字典，s=set()默认是空集合</li>
<li>集合的type是“set”,字典的类型是“dict”</li>
</ol>
<p>集合特点：</p>
<p>​    无序不重复的数据类型，不支持小标操作</p>
<h2 id="集合常见操作"><a href="#集合常见操作" class="headerlink" title="集合常见操作"></a>集合常见操作</h2><div class="table-container">
<table>
<thead>
<tr>
<th>操作</th>
<th>描述</th>
<th>实例</th>
</tr>
</thead>
<tbody>
<tr>
<td>add</td>
<td>添加集合</td>
<td>s1 = {10,20}<br>s1.add(100)<br>print(s1) #{100,10,20}</td>
</tr>
<tr>
<td>update</td>
<td>追加的数据必须是可迭代对象（列表、集合、字典、元组）</td>
<td>s1 = {10,20}<br/>s1.update(100)<br/>print(s1) #’int’ object is not iterable(int不是可迭代对象)<br>s1.update([100])#列表是迭代对象<br>print(s1)#{100, 10, 20}</td>
</tr>
<tr>
<td>remove</td>
<td>删除集合指定的数据，如果数据不存在则报错</td>
<td>s1 = {10,20,30}<br>s1.remove(10)<br>print(s1) #集合中没有数据会报错</td>
</tr>
<tr>
<td>discard</td>
<td>删除集合指定的数据，如果数据不存在不会报错</td>
<td>s1 = {10,20,30}<br/>s1.discard(10)<br/>print(s1) #集合中没有数据不会报错</td>
</tr>
<tr>
<td>pop</td>
<td>随机删除集合里面的某个数据，并返回这个数据</td>
<td>s1 = {10,20,30，40,50}<br/>s2  = s1.pop()<br/>print(s2) #20 返回被删除元素</td>
</tr>
<tr>
<td>&amp;</td>
<td>交集</td>
<td>a = {1,2,3,4}<br>b = {2,3,5,6}<br>se = a &amp; b<br>print(se)# {2,3}</td>
</tr>
<tr>
<td>\</td>
<td></td>
<td>或</td>
<td>a = {1,2,3,4}<br/>b = {2,3,5,6}<br/>se = a \</td>
<td>b<br/>print(se)# {1,2,3,4,5,6}</td>
</tr>
</tbody>
</table>
</div>
<h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>Number 数字 int float bool complex</p>
<p>String 字符串</p>
<p>List 列表  表示[]</p>
<p>Tuple 元组 表示（）</p>
<p>Set 集合{a,b,c}</p>
<p>Dictionary 字典{‘a’:’1’}</p>
<h2 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h2><div class="table-container">
<table>
<thead>
<tr>
<th>函数</th>
<th>操作</th>
<th>实例</th>
</tr>
</thead>
<tbody>
<tr>
<td>str()</td>
<td>转化为字符串</td>
<td>a = 5 <br>print(type(a)) #<class 'int'><br>b = str(a) <br>print(b, type(b))#5 <class 'str'></td>
</tr>
<tr>
<td>tuple()</td>
<td>转换为元组类型</td>
<td>list = [1,2] <br>print(type(list)) #<class 'list'><br>print(type(tuple(list)))#<class 'tuple'></td>
</tr>
<tr>
<td>list()</td>
<td>转化为列表</td>
<td>t = (1,2) <br>print(type(t)) #<class 'tuple'><br>print(type(list(t)))#<class 'list'></td>
</tr>
<tr>
<td>dict()</td>
<td>转化为字典</td>
<td>a = [‘a’, ‘b’, ‘c’]<br> b = [‘d’, ‘e’]<br> d = zip(a, b)<br> print(d)#返回的是对象地址<zip object at 0x000002A6E88B4788><br> print(dict(d))#{‘a’: ‘d’, ‘b’: ‘e’}</td>
</tr>
</tbody>
</table>
</div>
<h2 id="不可变对象"><a href="#不可变对象" class="headerlink" title="不可变对象"></a>不可变对象</h2><p>定义：存储空间保存的数据不允许被修改，这种数据就是不可变类型(原变量内容不可变，地址会变化，原变量改变后，需要重新分配内存空间)</p>
<p>常见的不可变类型有：数值类型int, bool, float, complex</p>
<p>​                    字符串 str</p>
<p>​                    元组 tuple</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#内容不可变，地址可以变化</span></span><br><span class="line">i  = <span class="number">73</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">type</span>(i))</span><br><span class="line"><span class="built_in">print</span>(i)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(i)) <span class="comment"># 地址：1825204704</span></span><br><span class="line"></span><br><span class="line">i+=<span class="number">2</span></span><br><span class="line"><span class="built_in">print</span>(i)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(i))<span class="comment">#地址：1825204768</span></span><br><span class="line"><span class="comment">#元组</span></span><br><span class="line">t = (<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>)</span><br><span class="line"><span class="built_in">print</span>(t)<span class="comment"># (1, 2, 3, 4, 5)</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(t))<span class="comment"># 2024501387952</span></span><br><span class="line">t[<span class="number">1</span>] = <span class="number">100</span></span><br><span class="line"><span class="built_in">print</span>(t)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(t))<span class="comment"># TypeError: &#x27;tuple&#x27; object does not support item assignment</span></span><br><span class="line"><span class="comment">#字符串</span></span><br><span class="line">s = <span class="string">&#x27;abc&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(s))<span class="comment">#2925156601504</span></span><br><span class="line">s = <span class="string">&#x27;abcd&#x27;</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(s))<span class="comment">#2925156688648</span></span><br></pre></td></tr></table></figure>
<h2 id="可变对象"><a href="#可变对象" class="headerlink" title="可变对象"></a>可变对象</h2><p>存储空间保存的数据允许被修改，这种数据就是可变类型</p>
<p>常见可变对象类型有：</p>
<p>列表list</p>
<p>字典dict</p>
<p>集合set</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#列表</span></span><br><span class="line">m = [<span class="number">5</span>,<span class="number">9</span>]</span><br><span class="line"><span class="built_in">print</span>(m)<span class="comment">#[5, 9]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(m))<span class="comment">#1749592527808</span></span><br><span class="line">m += [<span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(m)[<span class="number">5</span>, <span class="number">9</span>, <span class="number">6</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">id</span>(m))<span class="comment">#1749592527808</span></span><br><span class="line"><span class="comment">#集合</span></span><br><span class="line"><span class="built_in">set</span> = &#123;<span class="number">1</span>,<span class="number">2</span>,<span class="string">&#x27;123&#x27;</span>&#125;</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">set</span>,<span class="built_in">type</span>(<span class="built_in">set</span>),<span class="built_in">id</span>(<span class="built_in">set</span>))<span class="comment">#&#123;&#x27;123&#x27;, 1, 2&#125; &lt;class &#x27;set&#x27;&gt; 156167376</span></span><br><span class="line"><span class="built_in">set</span>.add(<span class="string">&#x27;34&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="built_in">set</span>,<span class="built_in">type</span>(<span class="built_in">set</span>),<span class="built_in">id</span>(<span class="built_in">set</span>))<span class="comment">#&#123;&#x27;123&#x27;, 1, 2, &#x27;34&#x27;&#125; &lt;class &#x27;set&#x27;&gt; 1561673764416</span></span><br></pre></td></tr></table></figure>
<p>可变对象：内容可变，地址不变</p>
<h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="函数-1"><a href="#函数-1" class="headerlink" title="函数"></a>函数</h3><p>定义：把具有独立功能的的代码块组合成一个个小模块</p>
<p>作用：提高写代码的效率，实现代码复用—流程标准化</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#格式</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">函数名</span>():</span><br><span class="line">	函数体</span><br></pre></td></tr></table></figure>
<h3 id="函数调用"><a href="#函数调用" class="headerlink" title="函数调用"></a>函数调用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;哈哈哈&quot;</span>)</span><br><span class="line">fun()<span class="comment">#哈哈哈</span></span><br></pre></td></tr></table></figure>
<h3 id="函数参数"><a href="#函数参数" class="headerlink" title="函数参数"></a>函数参数</h3><div class="table-container">
<table>
<thead>
<tr>
<th>参数类型</th>
<th style="text-align:center">格式</th>
</tr>
</thead>
<tbody>
<tr>
<td>必选参数</td>
<td style="text-align:center">有几个参数就传几个参数</td>
</tr>
<tr>
<td>默认参数</td>
<td style="text-align:center">给某个参数指定一个默认值</td>
</tr>
<tr>
<td>可变参数</td>
<td style="text-align:center">*args  将实参的位置参数接受，放置在一个元祖中</td>
</tr>
<tr>
<td>关键字参数</td>
<td style="text-align:center">**kwargs 接受所有的关键字参数然后将其换成一个字典赋值给kwargs这个参数</td>
</tr>
<tr>
<td>命名关键字参数</td>
<td style="text-align:center">要限制关键字参数的名字的时候<br></td>
</tr>
</tbody>
</table>
</div>
<h3 id="函数嵌套"><a href="#函数嵌套" class="headerlink" title="函数嵌套"></a>函数嵌套</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">fun</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;哈哈哈&quot;</span>)</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fun2</span>():</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;呵呵&quot;</span>)</span><br><span class="line">    fun()</span><br><span class="line">fun2()<span class="comment">#呵呵 哈哈哈</span></span><br></pre></td></tr></table></figure>
<h3 id="作用域"><a href="#作用域" class="headerlink" title="作用域"></a>作用域</h3><p>定义：就是作用的范围（也叫做名称空间）</p>
<p>按照生效的范围来看，有分成全局作用域与局部作用域</p>
<p>命名空间：本质就是从名称到对象的映射  一一对应——-字典来实现</p>
<p>a = 10 定义这个变量是时，python会申请内存空间存放10，然后将名字a与10绑定关系存放在名称空间中</p>
<p>名称空间： </p>
<p>内置的名称空间：随着python解释器启动而产生，停止而收回  </p>
<p>全局的名称空间：随着所在执行文件，执行结束而结束</p>
<p>局部名称空间：随着函数的调用而产生，结束而收回</p>
<p>全局作用域：包含内置名称空间和全局命名空间</p>
<p>局部作用域：在函数内可以使用</p>
<p>关键词：global：将变量声明为全局变量（可改变）</p>
<p>​        nonlocal：将变量声明为外层变量（外层函数的局部变量，而且不能是全局变量）</p>
<h3 id="匿名函数"><a href="#匿名函数" class="headerlink" title="匿名函数"></a>匿名函数</h3><p>语法：函数名 = lambda 形参：返回值</p>
<p>lamdba 是定义匿名函数的关键字，相当于函数的def</p>
<p>形参的数量按需加</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">func = <span class="keyword">lambda</span> a,b:a+b</span><br><span class="line"><span class="built_in">print</span>(func(<span class="number">1</span>,<span class="number">2</span>)) <span class="comment">#3</span></span><br></pre></td></tr></table></figure>
<h3 id="内置函数"><a href="#内置函数" class="headerlink" title="内置函数"></a>内置函数</h3><div class="table-container">
<table>
<thead>
<tr>
<th>函数</th>
<th>概述</th>
</tr>
</thead>
<tbody>
<tr>
<td>print()</td>
<td>输出</td>
</tr>
<tr>
<td>set()</td>
<td>创建一个无序不重复元素集</td>
</tr>
<tr>
<td>list()</td>
<td>将一个可迭代对象转换成列表</td>
</tr>
<tr>
<td>tuple()</td>
<td>将一个可迭代对象转化为元组</td>
</tr>
<tr>
<td>abs()</td>
<td>返回绝对值</td>
</tr>
<tr>
<td>sum()</td>
<td>求和</td>
</tr>
<tr>
<td>max()</td>
<td>最大值</td>
</tr>
<tr>
<td>min()</td>
<td>最小值</td>
</tr>
<tr>
<td>zip()</td>
<td>将可迭代的对象作为参数，将对象中对应的元素打包成一个个元组</td>
</tr>
<tr>
<td>map()</td>
<td>可以对可迭代对象中的每一个元素进行映射，分别执行function</td>
</tr>
<tr>
<td>reduce()</td>
<td>可迭代对象使其元素不断减少，最终得到一个计算值</td>
</tr>
<tr>
<td>enumerate()</td>
<td>枚举用于将一个可遍历的数据对象组合为一个索引序列，同时列出数据和数据下标，一般用在for循环</td>
</tr>
</tbody>
</table>
</div>
<h3 id="拆包"><a href="#拆包" class="headerlink" title="拆包"></a>拆包</h3><p>定义：对于函数中的多个返回数据，去掉元组，列表或者字典，直接获得里面数据的过程。</p>
<p>​    </p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>





</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">LiuJun</span>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>







  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
